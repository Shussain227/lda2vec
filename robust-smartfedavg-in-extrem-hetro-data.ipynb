{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22e9406",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-15T00:17:18.678558Z",
     "iopub.status.busy": "2025-06-15T00:17:18.678260Z",
     "iopub.status.idle": "2025-06-15T00:17:21.151511Z",
     "shell.execute_reply": "2025-06-15T00:17:21.150719Z"
    },
    "papermill": {
     "duration": 2.480262,
     "end_time": "2025-06-15T00:17:21.153121",
     "exception": false,
     "start_time": "2025-06-15T00:17:18.672859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543a90ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T00:17:21.162741Z",
     "iopub.status.busy": "2025-06-15T00:17:21.162383Z",
     "iopub.status.idle": "2025-06-15T01:12:28.640718Z",
     "shell.execute_reply": "2025-06-15T01:12:28.639743Z"
    },
    "papermill": {
     "duration": 3307.485824,
     "end_time": "2025-06-15T01:12:28.642295",
     "exception": false,
     "start_time": "2025-06-15T00:17:21.156471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💀 STARTING EXTREME QUALITY HETEROGENEITY EXPERIMENT\n",
      "🎯 Goal: Create scenarios where RobustSmartFedAvg ALWAYS wins\n",
      "🛡️ Method: Extreme quality degradation that breaks simple averaging\n",
      "💀 EXTREME QUALITY HETEROGENEITY EXPERIMENT\n",
      "🎯 Goal: Scenarios where RobustSmartFedAvg DOMINATES FedAvg\n",
      "================================================================================\n",
      "💀 Experiment Parameters:\n",
      "   🎯 Learning Rates: [0.005, 0.01]\n",
      "   💀 Extreme Scenarios: ['poison', 'catastrophic', 'byzantine', 'resource']\n",
      "   🤖 Methods: ['FedAvg', 'RobustSmartFedAvg']\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 1/8\n",
      "   Learning Rate: 0.005\n",
      "   Extreme Type: poison\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'poison':\n",
      "   40% pristine, 20% degraded, 40% POISONED (90% wrong labels)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_poison_lr0.005_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:06<00:00, 25.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  PRISTINE: 6 clients\n",
      "  POISON: 6 clients\n",
      "  DEGRADED: 3 clients\n",
      "   💀 Client 0 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 1 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 2 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 3 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 4 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 5 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 6 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 7 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 8 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 9 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 10 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 11 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 12 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 13 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 14 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.050 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   POISON: 6 clients (avg score: 0.050)\n",
      "   PRISTINE: 6 clients (avg score: 0.980)\n",
      "   DEGRADED: 3 clients (avg score: 0.450)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs POISON\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3025\n",
      "     Epoch 2: Loss = 2.3018\n",
      "   ✅ Training complete. Final avg loss: 2.3022\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0272\n",
      "     Epoch 2: Loss = 1.8324\n",
      "   ✅ Training complete. Final avg loss: 1.9298\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2395\n",
      "     Epoch 2: Loss = 2.0182\n",
      "   ✅ Training complete. Final avg loss: 2.1289\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9790\n",
      "     Epoch 2: Loss = 1.6201\n",
      "   ✅ Training complete. Final avg loss: 1.7995\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7204\n",
      "     Epoch 2: Loss = 1.4554\n",
      "   ✅ Training complete. Final avg loss: 1.5879\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7493\n",
      "     Epoch 2: Loss = 1.4561\n",
      "   ✅ Training complete. Final avg loss: 1.6027\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0501\n",
      "     Epoch 2: Loss = 1.8372\n",
      "   ✅ Training complete. Final avg loss: 1.9437\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3029\n",
      "     Epoch 2: Loss = 2.3022\n",
      "   ✅ Training complete. Final avg loss: 2.3026\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 3009, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7982\n",
      "     Epoch 2: Loss = 1.5205\n",
      "   ✅ Training complete. Final avg loss: 1.6593\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9194\n",
      "     Epoch 2: Loss = 1.7963\n",
      "   ✅ Training complete. Final avg loss: 1.8578\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2947, Weight=0.0955, Quality=poison\n",
      "  Client 1: Size=3475, Weight=0.1126, Quality=pristine\n",
      "  Client 2: Size=1278, Weight=0.0414, Quality=pristine\n",
      "  Client 3: Size=1903, Weight=0.0616, Quality=pristine\n",
      "  Client 4: Size=3330, Weight=0.1079, Quality=pristine\n",
      "  Client 5: Size=4162, Weight=0.1348, Quality=pristine\n",
      "  Client 6: Size=2891, Weight=0.0937, Quality=pristine\n",
      "  Client 7: Size=3306, Weight=0.1071, Quality=poison\n",
      "  Client 8: Size=3009, Weight=0.0975, Quality=degraded\n",
      "  Client 9: Size=4567, Weight=0.1480, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 10.04% accuracy, 2.3016 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3037\n",
      "     Epoch 2: Loss = 2.2998\n",
      "   ✅ Training complete. Final avg loss: 2.3018\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3082\n",
      "     Epoch 2: Loss = 2.3011\n",
      "   ✅ Training complete. Final avg loss: 2.3047\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8581\n",
      "     Epoch 2: Loss = 1.7827\n",
      "   ✅ Training complete. Final avg loss: 1.8204\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.2991\n",
      "     Epoch 2: Loss = 2.2967\n",
      "   ✅ Training complete. Final avg loss: 2.2979\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7687\n",
      "     Epoch 2: Loss = 1.5644\n",
      "   ✅ Training complete. Final avg loss: 1.6666\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9379\n",
      "     Epoch 2: Loss = 1.7867\n",
      "   ✅ Training complete. Final avg loss: 1.8623\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9149\n",
      "     Epoch 2: Loss = 1.8215\n",
      "   ✅ Training complete. Final avg loss: 1.8682\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3073\n",
      "     Epoch 2: Loss = 2.3028\n",
      "   ✅ Training complete. Final avg loss: 2.3051\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5967\n",
      "     Epoch 2: Loss = 1.4446\n",
      "   ✅ Training complete. Final avg loss: 1.5206\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5904\n",
      "     Epoch 2: Loss = 1.4490\n",
      "   ✅ Training complete. Final avg loss: 1.5197\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4285, Weight=0.1255, Quality=poison\n",
      "  Client 1: Size=2493, Weight=0.0730, Quality=poison\n",
      "  Client 2: Size=4567, Weight=0.1338, Quality=degraded\n",
      "  Client 3: Size=4092, Weight=0.1198, Quality=poison\n",
      "  Client 4: Size=1903, Weight=0.0557, Quality=pristine\n",
      "  Client 5: Size=3475, Weight=0.1018, Quality=pristine\n",
      "  Client 6: Size=2891, Weight=0.0847, Quality=pristine\n",
      "  Client 7: Size=2947, Weight=0.0863, Quality=poison\n",
      "  Client 8: Size=4162, Weight=0.1219, Quality=pristine\n",
      "  Client 9: Size=3330, Weight=0.0975, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.22% accuracy, 2.2896 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3003\n",
      "     Epoch 2: Loss = 2.2988\n",
      "   ✅ Training complete. Final avg loss: 2.2996\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8704\n",
      "     Epoch 2: Loss = 1.7608\n",
      "   ✅ Training complete. Final avg loss: 1.8156\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 3009, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.6206\n",
      "     Epoch 2: Loss = 1.4915\n",
      "   ✅ Training complete. Final avg loss: 1.5561\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8889\n",
      "     Epoch 2: Loss = 1.8032\n",
      "   ✅ Training complete. Final avg loss: 1.8460\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7253\n",
      "     Epoch 2: Loss = 1.5470\n",
      "   ✅ Training complete. Final avg loss: 1.6361\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3138\n",
      "     Epoch 2: Loss = 2.3069\n",
      "   ✅ Training complete. Final avg loss: 2.3103\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5491\n",
      "     Epoch 2: Loss = 1.4621\n",
      "   ✅ Training complete. Final avg loss: 1.5056\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3155\n",
      "     Epoch 2: Loss = 2.3022\n",
      "   ✅ Training complete. Final avg loss: 2.3088\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3100\n",
      "     Epoch 2: Loss = 2.3025\n",
      "   ✅ Training complete. Final avg loss: 2.3063\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 6349, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9584\n",
      "     Epoch 2: Loss = 1.9029\n",
      "   ✅ Training complete. Final avg loss: 1.9307\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4092, Weight=0.1197, Quality=poison\n",
      "  Client 1: Size=3475, Weight=0.1016, Quality=pristine\n",
      "  Client 2: Size=3009, Weight=0.0880, Quality=degraded\n",
      "  Client 3: Size=2891, Weight=0.0845, Quality=pristine\n",
      "  Client 4: Size=1903, Weight=0.0557, Quality=pristine\n",
      "  Client 5: Size=2947, Weight=0.0862, Quality=poison\n",
      "  Client 6: Size=3330, Weight=0.0974, Quality=pristine\n",
      "  Client 7: Size=1913, Weight=0.0559, Quality=poison\n",
      "  Client 8: Size=4285, Weight=0.1253, Quality=poison\n",
      "  Client 9: Size=6349, Weight=0.1857, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 15.55% accuracy, 2.2840 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3169\n",
      "     Epoch 2: Loss = 2.3091\n",
      "   ✅ Training complete. Final avg loss: 2.3130\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3140\n",
      "     Epoch 2: Loss = 2.3023\n",
      "   ✅ Training complete. Final avg loss: 2.3081\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8590\n",
      "     Epoch 2: Loss = 1.7803\n",
      "   ✅ Training complete. Final avg loss: 1.8197\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5294\n",
      "     Epoch 2: Loss = 1.4235\n",
      "   ✅ Training complete. Final avg loss: 1.4765\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3189\n",
      "     Epoch 2: Loss = 2.3080\n",
      "   ✅ Training complete. Final avg loss: 2.3134\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8325\n",
      "     Epoch 2: Loss = 1.7713\n",
      "   ✅ Training complete. Final avg loss: 1.8019\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8357\n",
      "     Epoch 2: Loss = 1.7435\n",
      "   ✅ Training complete. Final avg loss: 1.7896\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7023\n",
      "     Epoch 2: Loss = 1.5137\n",
      "   ✅ Training complete. Final avg loss: 1.6080\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5536\n",
      "     Epoch 2: Loss = 1.4383\n",
      "   ✅ Training complete. Final avg loss: 1.4959\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3147\n",
      "     Epoch 2: Loss = 2.3043\n",
      "   ✅ Training complete. Final avg loss: 2.3095\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1913, Weight=0.0598, Quality=poison\n",
      "  Client 1: Size=4285, Weight=0.1340, Quality=poison\n",
      "  Client 2: Size=2891, Weight=0.0904, Quality=pristine\n",
      "  Client 3: Size=4162, Weight=0.1302, Quality=pristine\n",
      "  Client 4: Size=2947, Weight=0.0922, Quality=poison\n",
      "  Client 5: Size=4567, Weight=0.1429, Quality=degraded\n",
      "  Client 6: Size=3475, Weight=0.1087, Quality=pristine\n",
      "  Client 7: Size=1903, Weight=0.0595, Quality=pristine\n",
      "  Client 8: Size=3330, Weight=0.1042, Quality=pristine\n",
      "  Client 9: Size=2493, Weight=0.0780, Quality=poison\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.37% accuracy, 2.2847 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1195\n",
      "     Epoch 2: Loss = 1.9367\n",
      "   ✅ Training complete. Final avg loss: 2.0281\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3155\n",
      "     Epoch 2: Loss = 2.3037\n",
      "   ✅ Training complete. Final avg loss: 2.3096\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6457\n",
      "     Epoch 2: Loss = 1.5157\n",
      "   ✅ Training complete. Final avg loss: 1.5807\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3178\n",
      "     Epoch 2: Loss = 2.3093\n",
      "   ✅ Training complete. Final avg loss: 2.3135\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3275\n",
      "     Epoch 2: Loss = 2.3089\n",
      "   ✅ Training complete. Final avg loss: 2.3182\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 6349, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9287\n",
      "     Epoch 2: Loss = 1.8856\n",
      "   ✅ Training complete. Final avg loss: 1.9071\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5443\n",
      "     Epoch 2: Loss = 1.4419\n",
      "   ✅ Training complete. Final avg loss: 1.4931\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3231\n",
      "     Epoch 2: Loss = 2.3098\n",
      "   ✅ Training complete. Final avg loss: 2.3165\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8242\n",
      "     Epoch 2: Loss = 1.7336\n",
      "   ✅ Training complete. Final avg loss: 1.7789\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8382\n",
      "     Epoch 2: Loss = 1.7686\n",
      "   ✅ Training complete. Final avg loss: 1.8034\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1278, Weight=0.0409, Quality=pristine\n",
      "  Client 1: Size=4285, Weight=0.1372, Quality=poison\n",
      "  Client 2: Size=1903, Weight=0.0609, Quality=pristine\n",
      "  Client 3: Size=2493, Weight=0.0798, Quality=poison\n",
      "  Client 4: Size=1913, Weight=0.0613, Quality=poison\n",
      "  Client 5: Size=6349, Weight=0.2033, Quality=degraded\n",
      "  Client 6: Size=3330, Weight=0.1067, Quality=pristine\n",
      "  Client 7: Size=3306, Weight=0.1059, Quality=poison\n",
      "  Client 8: Size=3475, Weight=0.1113, Quality=pristine\n",
      "  Client 9: Size=2891, Weight=0.0926, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 16.98% accuracy, 2.2794 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 6349, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9117\n",
      "     Epoch 2: Loss = 1.8719\n",
      "   ✅ Training complete. Final avg loss: 1.8918\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3118\n",
      "     Epoch 2: Loss = 2.2994\n",
      "   ✅ Training complete. Final avg loss: 2.3056\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0511\n",
      "     Epoch 2: Loss = 1.9265\n",
      "   ✅ Training complete. Final avg loss: 1.9888\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 3009, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.5874\n",
      "     Epoch 2: Loss = 1.5088\n",
      "   ✅ Training complete. Final avg loss: 1.5481\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5380\n",
      "     Epoch 2: Loss = 1.4362\n",
      "   ✅ Training complete. Final avg loss: 1.4871\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3253\n",
      "     Epoch 2: Loss = 2.3075\n",
      "   ✅ Training complete. Final avg loss: 2.3164\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3202\n",
      "     Epoch 2: Loss = 2.3098\n",
      "   ✅ Training complete. Final avg loss: 2.3150\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6624\n",
      "     Epoch 2: Loss = 1.5041\n",
      "   ✅ Training complete. Final avg loss: 1.5833\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3141\n",
      "     Epoch 2: Loss = 2.3025\n",
      "   ✅ Training complete. Final avg loss: 2.3083\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7760\n",
      "     Epoch 2: Loss = 1.7280\n",
      "   ✅ Training complete. Final avg loss: 1.7520\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=6349, Weight=0.1927, Quality=degraded\n",
      "  Client 1: Size=4092, Weight=0.1242, Quality=poison\n",
      "  Client 2: Size=1278, Weight=0.0388, Quality=pristine\n",
      "  Client 3: Size=3009, Weight=0.0913, Quality=degraded\n",
      "  Client 4: Size=3330, Weight=0.1011, Quality=pristine\n",
      "  Client 5: Size=1913, Weight=0.0581, Quality=poison\n",
      "  Client 6: Size=3306, Weight=0.1004, Quality=poison\n",
      "  Client 7: Size=1903, Weight=0.0578, Quality=pristine\n",
      "  Client 8: Size=4285, Weight=0.1301, Quality=poison\n",
      "  Client 9: Size=3475, Weight=0.1055, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 16.37% accuracy, 2.2518 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3185\n",
      "     Epoch 2: Loss = 2.3047\n",
      "   ✅ Training complete. Final avg loss: 2.3116\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5202\n",
      "     Epoch 2: Loss = 1.4264\n",
      "   ✅ Training complete. Final avg loss: 1.4733\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3158\n",
      "     Epoch 2: Loss = 2.3065\n",
      "   ✅ Training complete. Final avg loss: 2.3111\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8207\n",
      "     Epoch 2: Loss = 1.7449\n",
      "   ✅ Training complete. Final avg loss: 1.7828\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8092\n",
      "     Epoch 2: Loss = 1.7417\n",
      "   ✅ Training complete. Final avg loss: 1.7755\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3229\n",
      "     Epoch 2: Loss = 2.3074\n",
      "   ✅ Training complete. Final avg loss: 2.3152\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0564\n",
      "     Epoch 2: Loss = 1.9143\n",
      "   ✅ Training complete. Final avg loss: 1.9854\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3082\n",
      "     Epoch 2: Loss = 2.2987\n",
      "   ✅ Training complete. Final avg loss: 2.3034\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5498\n",
      "     Epoch 2: Loss = 1.3995\n",
      "   ✅ Training complete. Final avg loss: 1.4746\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7742\n",
      "     Epoch 2: Loss = 1.7066\n",
      "   ✅ Training complete. Final avg loss: 1.7404\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1913, Weight=0.0614, Quality=poison\n",
      "  Client 1: Size=3330, Weight=0.1069, Quality=pristine\n",
      "  Client 2: Size=2493, Weight=0.0800, Quality=poison\n",
      "  Client 3: Size=2891, Weight=0.0928, Quality=pristine\n",
      "  Client 4: Size=4567, Weight=0.1466, Quality=degraded\n",
      "  Client 5: Size=2947, Weight=0.0946, Quality=poison\n",
      "  Client 6: Size=1278, Weight=0.0410, Quality=pristine\n",
      "  Client 7: Size=4092, Weight=0.1314, Quality=poison\n",
      "  Client 8: Size=4162, Weight=0.1336, Quality=pristine\n",
      "  Client 9: Size=3475, Weight=0.1116, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.65% accuracy, 2.2411 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3215\n",
      "     Epoch 2: Loss = 2.3047\n",
      "   ✅ Training complete. Final avg loss: 2.3131\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4761\n",
      "     Epoch 2: Loss = 1.3827\n",
      "   ✅ Training complete. Final avg loss: 1.4294\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3174\n",
      "     Epoch 2: Loss = 2.3025\n",
      "   ✅ Training complete. Final avg loss: 2.3099\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7920\n",
      "     Epoch 2: Loss = 1.7247\n",
      "   ✅ Training complete. Final avg loss: 1.7583\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3092\n",
      "     Epoch 2: Loss = 2.2985\n",
      "   ✅ Training complete. Final avg loss: 2.3038\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6447\n",
      "     Epoch 2: Loss = 1.4921\n",
      "   ✅ Training complete. Final avg loss: 1.5684\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3266\n",
      "     Epoch 2: Loss = 2.3056\n",
      "   ✅ Training complete. Final avg loss: 2.3161\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5065\n",
      "     Epoch 2: Loss = 1.4366\n",
      "   ✅ Training complete. Final avg loss: 1.4716\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7853\n",
      "     Epoch 2: Loss = 1.7163\n",
      "   ✅ Training complete. Final avg loss: 1.7508\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7793\n",
      "     Epoch 2: Loss = 1.6692\n",
      "   ✅ Training complete. Final avg loss: 1.7243\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=3306, Weight=0.0946, Quality=poison\n",
      "  Client 1: Size=4162, Weight=0.1191, Quality=pristine\n",
      "  Client 2: Size=4285, Weight=0.1226, Quality=poison\n",
      "  Client 3: Size=2891, Weight=0.0827, Quality=pristine\n",
      "  Client 4: Size=4092, Weight=0.1171, Quality=poison\n",
      "  Client 5: Size=1903, Weight=0.0544, Quality=pristine\n",
      "  Client 6: Size=2947, Weight=0.0843, Quality=poison\n",
      "  Client 7: Size=3330, Weight=0.0953, Quality=pristine\n",
      "  Client 8: Size=4567, Weight=0.1306, Quality=degraded\n",
      "  Client 9: Size=3475, Weight=0.0994, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.59% accuracy, 2.2313 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 20.59%\n",
      "   Best Accuracy: 20.65%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs POISON\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'poison':\n",
      "   Quality threshold: 0.400\n",
      "   Minimum clients ratio: 30.0%\n",
      "   Harm detection threshold: 0.100\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3025\n",
      "     Epoch 2: Loss = 2.3018\n",
      "   ✅ Training complete. Final avg loss: 2.3022\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0272\n",
      "     Epoch 2: Loss = 1.8324\n",
      "   ✅ Training complete. Final avg loss: 1.9298\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2395\n",
      "     Epoch 2: Loss = 2.0182\n",
      "   ✅ Training complete. Final avg loss: 2.1289\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9790\n",
      "     Epoch 2: Loss = 1.6201\n",
      "   ✅ Training complete. Final avg loss: 1.7995\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7204\n",
      "     Epoch 2: Loss = 1.4554\n",
      "   ✅ Training complete. Final avg loss: 1.5879\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7493\n",
      "     Epoch 2: Loss = 1.4560\n",
      "   ✅ Training complete. Final avg loss: 1.6027\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0501\n",
      "     Epoch 2: Loss = 1.8372\n",
      "   ✅ Training complete. Final avg loss: 1.9437\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3029\n",
      "     Epoch 2: Loss = 2.3022\n",
      "   ✅ Training complete. Final avg loss: 2.3026\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 3009, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7982\n",
      "     Epoch 2: Loss = 1.5205\n",
      "   ✅ Training complete. Final avg loss: 1.6593\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9194\n",
      "     Epoch 2: Loss = 1.7962\n",
      "   ✅ Training complete. Final avg loss: 1.8578\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.297, Loss_std=0.034, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.426\n",
      "      Stability: 0.989, Confidence: 0.079\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.264\n",
      "   ❌ Decision: FILTER (Score 0.264 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.370, Loss=1.736, Loss_std=0.833, Entropy=1.851\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.566\n",
      "      Stability: 0.722, Confidence: 0.260\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.705\n",
      "   ✅ Decision: KEEP (Score 0.705 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.286, Loss=1.960, Loss_std=0.757, Entropy=1.933\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.954, Loss: 0.510\n",
      "      Stability: 0.748, Confidence: 0.227\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.679\n",
      "   ✅ Decision: KEEP (Score 0.679 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.502, Loss=1.575, Loss_std=1.068, Entropy=1.660\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.606\n",
      "      Stability: 0.644, Confidence: 0.336\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.555, Loss=1.425, Loss_std=1.032, Entropy=1.508\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.644\n",
      "      Stability: 0.656, Confidence: 0.397\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.732\n",
      "   ✅ Decision: KEEP (Score 0.732 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.486, Loss=1.453, Loss_std=1.052, Entropy=1.387\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.637\n",
      "      Stability: 0.649, Confidence: 0.445\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.255, Loss=1.828, Loss_std=0.685, Entropy=1.845\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.849, Loss: 0.543\n",
      "      Stability: 0.772, Confidence: 0.262\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.670\n",
      "   ✅ Decision: KEEP (Score 0.670 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.077, Loss=2.306, Loss_std=0.035, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.256, Loss: 0.424\n",
      "      Stability: 0.988, Confidence: 0.079\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.246\n",
      "   ❌ Decision: FILTER (Score 0.246 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.534, Loss=1.503, Loss_std=1.286, Entropy=1.404\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.624\n",
      "      Stability: 0.571, Confidence: 0.438\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.663\n",
      "   ✅ Decision: KEEP (Score 0.663 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.339, Loss=1.743, Loss_std=0.859, Entropy=1.807\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.564\n",
      "      Stability: 0.714, Confidence: 0.277\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.652\n",
      "   ✅ Decision: KEEP (Score 0.652 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      5 |  0.980 |     0.738 |    4162 | KEEP     | Score 0.738 ≥ threshold 0.400\n",
      "      2 |      4 |  0.980 |     0.732 |    3330 | KEEP     | Score 0.732 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.710 |    1903 | KEEP     | Score 0.710 ≥ threshold 0.400\n",
      "      4 |      1 |  0.980 |     0.705 |    3475 | KEEP     | Score 0.705 ≥ threshold 0.400\n",
      "      5 |      2 |  0.980 |     0.679 |    1278 | KEEP     | Score 0.679 ≥ threshold 0.400\n",
      "      6 |      6 |  0.980 |     0.670 |    2891 | KEEP     | Score 0.670 ≥ threshold 0.400\n",
      "      7 |      8 |  0.450 |     0.663 |    3009 | KEEP     | Score 0.663 ≥ threshold 0.400\n",
      "      8 |      9 |  0.450 |     0.652 |    4567 | KEEP     | Score 0.652 ≥ threshold 0.400\n",
      "      9 |      0 |  0.050 |     0.264 |    2947 | FILTER   | Score 0.264 < threshold 0.400\n",
      "     10 |      7 |  0.050 |     0.246 |    3306 | FILTER   | Score 0.246 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 8 (IDs: [5, 4, 3, 1, 2, 6, 8, 9])\n",
      "   Filter rate: 20.0%\n",
      "   Average quality score: 0.694\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        5 | 4162 |   0.738 |  0.169 |  0.164 |   0.164\n",
      "        4 | 3330 |   0.732 |  0.135 |  0.159 |   0.157\n",
      "        3 | 1903 |   0.710 |  0.077 |  0.139 |   0.133\n",
      "        1 | 3475 |   0.705 |  0.141 |  0.135 |   0.135\n",
      "        2 | 1278 |   0.679 |  0.052 |  0.112 |   0.106\n",
      "        6 | 2891 |   0.670 |  0.117 |  0.104 |   0.106\n",
      "        8 | 3009 |   0.663 |  0.122 |  0.098 |   0.100\n",
      "        9 | 4567 |   0.652 |  0.186 |  0.089 |   0.098\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 10.10% accuracy, 2.3354 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3076\n",
      "     Epoch 2: Loss = 2.3017\n",
      "   ✅ Training complete. Final avg loss: 2.3046\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3137\n",
      "     Epoch 2: Loss = 2.3017\n",
      "   ✅ Training complete. Final avg loss: 2.3077\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8612\n",
      "     Epoch 2: Loss = 1.7881\n",
      "   ✅ Training complete. Final avg loss: 1.8246\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3007\n",
      "     Epoch 2: Loss = 2.2976\n",
      "   ✅ Training complete. Final avg loss: 2.2992\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7225\n",
      "     Epoch 2: Loss = 1.5532\n",
      "   ✅ Training complete. Final avg loss: 1.6378\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9168\n",
      "     Epoch 2: Loss = 1.7895\n",
      "   ✅ Training complete. Final avg loss: 1.8532\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8805\n",
      "     Epoch 2: Loss = 1.7976\n",
      "   ✅ Training complete. Final avg loss: 1.8390\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3119\n",
      "     Epoch 2: Loss = 2.3070\n",
      "   ✅ Training complete. Final avg loss: 2.3094\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5623\n",
      "     Epoch 2: Loss = 1.4367\n",
      "   ✅ Training complete. Final avg loss: 1.4995\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5697\n",
      "     Epoch 2: Loss = 1.4479\n",
      "   ✅ Training complete. Final avg loss: 1.5088\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.142, Loss=2.293, Loss_std=0.096, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.473, Loss: 0.427\n",
      "      Stability: 0.968, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.279\n",
      "   ❌ Decision: FILTER (Score 0.279 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.113, Loss=2.300, Loss_std=0.072, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.377, Loss: 0.425\n",
      "      Stability: 0.976, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.264\n",
      "   ❌ Decision: FILTER (Score 0.264 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.356, Loss=1.759, Loss_std=0.781, Entropy=1.880\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.560\n",
      "      Stability: 0.740, Confidence: 0.248\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.652\n",
      "   ✅ Decision: KEEP (Score 0.652 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.291, Loss_std=0.136, Entropy=2.293\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.427\n",
      "      Stability: 0.955, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ❌ Decision: FILTER (Score 0.260 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.471, Loss=1.546, Loss_std=0.996, Entropy=1.679\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.613\n",
      "      Stability: 0.668, Confidence: 0.329\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.392, Loss=1.708, Loss_std=1.064, Entropy=1.690\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.573\n",
      "      Stability: 0.645, Confidence: 0.324\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.700\n",
      "   ✅ Decision: KEEP (Score 0.700 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.298, Loss=1.792, Loss_std=0.830, Entropy=1.756\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.994, Loss: 0.552\n",
      "      Stability: 0.723, Confidence: 0.298\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.303, Loss_std=0.080, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.424\n",
      "      Stability: 0.973, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.272\n",
      "   ❌ Decision: FILTER (Score 0.272 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.483, Loss=1.382, Loss_std=0.875, Entropy=1.428\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.655\n",
      "      Stability: 0.708, Confidence: 0.429\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.752\n",
      "   ✅ Decision: KEEP (Score 0.752 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.514, Loss=1.489, Loss_std=1.152, Entropy=1.435\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.628\n",
      "      Stability: 0.616, Confidence: 0.426\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.725\n",
      "   ✅ Decision: KEEP (Score 0.725 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.752 |    4162 | KEEP     | Score 0.752 ≥ threshold 0.400\n",
      "      2 |      9 |  0.980 |     0.725 |    3330 | KEEP     | Score 0.725 ≥ threshold 0.400\n",
      "      3 |      4 |  0.980 |     0.715 |    1903 | KEEP     | Score 0.715 ≥ threshold 0.400\n",
      "      4 |      6 |  0.980 |     0.707 |    2891 | KEEP     | Score 0.707 ≥ threshold 0.400\n",
      "      5 |      5 |  0.980 |     0.700 |    3475 | KEEP     | Score 0.700 ≥ threshold 0.400\n",
      "      6 |      2 |  0.450 |     0.652 |    4567 | KEEP     | Score 0.652 ≥ threshold 0.400\n",
      "      7 |      0 |  0.050 |     0.279 |    4285 | FILTER   | Score 0.279 < threshold 0.400\n",
      "      8 |      7 |  0.050 |     0.272 |    2947 | FILTER   | Score 0.272 < threshold 0.400\n",
      "      9 |      1 |  0.050 |     0.264 |    2493 | FILTER   | Score 0.264 < threshold 0.400\n",
      "     10 |      3 |  0.050 |     0.260 |    4092 | FILTER   | Score 0.260 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [8, 9, 4, 6, 5, 2])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.709\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 4162 |   0.752 |  0.205 |  0.213 |   0.212\n",
      "        9 | 3330 |   0.725 |  0.164 |  0.184 |   0.182\n",
      "        4 | 1903 |   0.715 |  0.094 |  0.174 |   0.166\n",
      "        6 | 2891 |   0.707 |  0.142 |  0.165 |   0.163\n",
      "        5 | 3475 |   0.700 |  0.171 |  0.158 |   0.159\n",
      "        2 | 4567 |   0.652 |  0.225 |  0.107 |   0.118\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 13.90% accuracy, 2.5542 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3213\n",
      "     Epoch 2: Loss = 2.3009\n",
      "   ✅ Training complete. Final avg loss: 2.3111\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8759\n",
      "     Epoch 2: Loss = 1.7579\n",
      "   ✅ Training complete. Final avg loss: 1.8169\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 3009, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.5846\n",
      "     Epoch 2: Loss = 1.4709\n",
      "   ✅ Training complete. Final avg loss: 1.5277\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8356\n",
      "     Epoch 2: Loss = 1.7796\n",
      "   ✅ Training complete. Final avg loss: 1.8076\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6553\n",
      "     Epoch 2: Loss = 1.5279\n",
      "   ✅ Training complete. Final avg loss: 1.5916\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3382\n",
      "     Epoch 2: Loss = 2.3099\n",
      "   ✅ Training complete. Final avg loss: 2.3240\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5255\n",
      "     Epoch 2: Loss = 1.4368\n",
      "   ✅ Training complete. Final avg loss: 1.4811\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3460\n",
      "     Epoch 2: Loss = 2.3096\n",
      "   ✅ Training complete. Final avg loss: 2.3278\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3295\n",
      "     Epoch 2: Loss = 2.3041\n",
      "   ✅ Training complete. Final avg loss: 2.3168\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 6349, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9522\n",
      "     Epoch 2: Loss = 1.8992\n",
      "   ✅ Training complete. Final avg loss: 1.9257\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.285, Loss_std=0.114, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.429\n",
      "      Stability: 0.962, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.387, Loss=1.702, Loss_std=0.848, Entropy=1.807\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.575\n",
      "      Stability: 0.717, Confidence: 0.277\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.709\n",
      "   ✅ Decision: KEEP (Score 0.709 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.603, Loss=1.435, Loss_std=1.305, Entropy=1.416\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.641\n",
      "      Stability: 0.565, Confidence: 0.434\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.664\n",
      "   ✅ Decision: KEEP (Score 0.664 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.317, Loss=1.798, Loss_std=0.845, Entropy=1.808\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.550\n",
      "      Stability: 0.718, Confidence: 0.277\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.703\n",
      "   ✅ Decision: KEEP (Score 0.703 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.512, Loss=1.431, Loss_std=1.071, Entropy=1.584\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.642\n",
      "      Stability: 0.643, Confidence: 0.367\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.723\n",
      "   ✅ Decision: KEEP (Score 0.723 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.103, Loss=2.309, Loss_std=0.094, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.345, Loss: 0.423\n",
      "      Stability: 0.969, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.257\n",
      "   ❌ Decision: FILTER (Score 0.257 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.524, Loss=1.469, Loss_std=1.078, Entropy=1.433\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.633\n",
      "      Stability: 0.641, Confidence: 0.427\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.731\n",
      "   ✅ Decision: KEEP (Score 0.731 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.082, Loss=2.297, Loss_std=0.119, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.272, Loss: 0.426\n",
      "      Stability: 0.960, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.245\n",
      "   ❌ Decision: FILTER (Score 0.245 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.106, Loss=2.302, Loss_std=0.121, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.353, Loss: 0.425\n",
      "      Stability: 0.960, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.258\n",
      "   ❌ Decision: FILTER (Score 0.258 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.291, Loss=1.925, Loss_std=0.838, Entropy=1.863\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.970, Loss: 0.519\n",
      "      Stability: 0.721, Confidence: 0.255\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.632\n",
      "   ✅ Decision: KEEP (Score 0.632 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.731 |    3330 | KEEP     | Score 0.731 ≥ threshold 0.400\n",
      "      2 |      4 |  0.980 |     0.723 |    1903 | KEEP     | Score 0.723 ≥ threshold 0.400\n",
      "      3 |      1 |  0.980 |     0.709 |    3475 | KEEP     | Score 0.709 ≥ threshold 0.400\n",
      "      4 |      3 |  0.980 |     0.703 |    2891 | KEEP     | Score 0.703 ≥ threshold 0.400\n",
      "      5 |      2 |  0.450 |     0.664 |    3009 | KEEP     | Score 0.664 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.632 |    6349 | KEEP     | Score 0.632 ≥ threshold 0.400\n",
      "      7 |      0 |  0.050 |     0.261 |    4092 | FILTER   | Score 0.261 < threshold 0.400\n",
      "      8 |      8 |  0.050 |     0.258 |    4285 | FILTER   | Score 0.258 < threshold 0.400\n",
      "      9 |      5 |  0.050 |     0.257 |    2947 | FILTER   | Score 0.257 < threshold 0.400\n",
      "     10 |      7 |  0.050 |     0.245 |    1913 | FILTER   | Score 0.245 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [6, 4, 1, 3, 2, 9])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.694\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 3330 |   0.731 |  0.159 |  0.205 |   0.201\n",
      "        4 | 1903 |   0.723 |  0.091 |  0.197 |   0.186\n",
      "        1 | 3475 |   0.709 |  0.166 |  0.182 |   0.180\n",
      "        3 | 2891 |   0.703 |  0.138 |  0.177 |   0.173\n",
      "        2 | 3009 |   0.664 |  0.144 |  0.137 |   0.137\n",
      "        9 | 6349 |   0.632 |  0.303 |  0.103 |   0.123\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 16.36% accuracy, 2.7115 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3626\n",
      "     Epoch 2: Loss = 2.3156\n",
      "   ✅ Training complete. Final avg loss: 2.3391\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3346\n",
      "     Epoch 2: Loss = 2.3071\n",
      "   ✅ Training complete. Final avg loss: 2.3208\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8145\n",
      "     Epoch 2: Loss = 1.7723\n",
      "   ✅ Training complete. Final avg loss: 1.7934\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5101\n",
      "     Epoch 2: Loss = 1.4075\n",
      "   ✅ Training complete. Final avg loss: 1.4588\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3559\n",
      "     Epoch 2: Loss = 2.3121\n",
      "   ✅ Training complete. Final avg loss: 2.3340\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8313\n",
      "     Epoch 2: Loss = 1.7754\n",
      "   ✅ Training complete. Final avg loss: 1.8033\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8011\n",
      "     Epoch 2: Loss = 1.7273\n",
      "   ✅ Training complete. Final avg loss: 1.7642\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5858\n",
      "     Epoch 2: Loss = 1.5009\n",
      "   ✅ Training complete. Final avg loss: 1.5433\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5043\n",
      "     Epoch 2: Loss = 1.4283\n",
      "   ✅ Training complete. Final avg loss: 1.4663\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3441\n",
      "     Epoch 2: Loss = 2.3119\n",
      "   ✅ Training complete. Final avg loss: 2.3280\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.298, Loss_std=0.151, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.425\n",
      "      Stability: 0.950, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.270\n",
      "   ❌ Decision: FILTER (Score 0.270 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.302, Loss_std=0.169, Entropy=2.290\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.424\n",
      "      Stability: 0.944, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.272, Loss=1.833, Loss_std=0.803, Entropy=1.791\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.905, Loss: 0.542\n",
      "      Stability: 0.732, Confidence: 0.284\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.680\n",
      "   ✅ Decision: KEEP (Score 0.680 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.325, Loss_std=0.928, Entropy=1.398\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.669\n",
      "      Stability: 0.691, Confidence: 0.441\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.753\n",
      "   ✅ Decision: KEEP (Score 0.753 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.106, Loss=2.302, Loss_std=0.091, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.353, Loss: 0.424\n",
      "      Stability: 0.970, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.259\n",
      "   ❌ Decision: FILTER (Score 0.259 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.401, Loss=1.655, Loss_std=0.968, Entropy=1.666\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.586\n",
      "      Stability: 0.677, Confidence: 0.334\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.659\n",
      "   ✅ Decision: KEEP (Score 0.659 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.389, Loss=1.719, Loss_std=0.907, Entropy=1.766\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.570\n",
      "      Stability: 0.698, Confidence: 0.294\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.522, Loss=1.397, Loss_std=1.162, Entropy=1.409\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.651\n",
      "      Stability: 0.613, Confidence: 0.436\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.731\n",
      "   ✅ Decision: KEEP (Score 0.731 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.531, Loss=1.433, Loss_std=1.167, Entropy=1.357\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.642\n",
      "      Stability: 0.611, Confidence: 0.457\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.732\n",
      "   ✅ Decision: KEEP (Score 0.732 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.118, Loss=2.294, Loss_std=0.133, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.393, Loss: 0.427\n",
      "      Stability: 0.956, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.264\n",
      "   ❌ Decision: FILTER (Score 0.264 < threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.753 |    4162 | KEEP     | Score 0.753 ≥ threshold 0.400\n",
      "      2 |      8 |  0.980 |     0.732 |    3330 | KEEP     | Score 0.732 ≥ threshold 0.400\n",
      "      3 |      7 |  0.980 |     0.731 |    1903 | KEEP     | Score 0.731 ≥ threshold 0.400\n",
      "      4 |      6 |  0.980 |     0.706 |    3475 | KEEP     | Score 0.706 ≥ threshold 0.400\n",
      "      5 |      2 |  0.980 |     0.680 |    2891 | KEEP     | Score 0.680 ≥ threshold 0.400\n",
      "      6 |      5 |  0.450 |     0.659 |    4567 | KEEP     | Score 0.659 ≥ threshold 0.400\n",
      "      7 |      0 |  0.050 |     0.270 |    1913 | FILTER   | Score 0.270 < threshold 0.400\n",
      "      8 |      9 |  0.050 |     0.264 |    2493 | FILTER   | Score 0.264 < threshold 0.400\n",
      "      9 |      1 |  0.050 |     0.261 |    4285 | FILTER   | Score 0.261 < threshold 0.400\n",
      "     10 |      4 |  0.050 |     0.259 |    2947 | FILTER   | Score 0.259 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [3, 8, 7, 6, 2, 5])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.710\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 4162 |   0.753 |  0.205 |  0.214 |   0.213\n",
      "        8 | 3330 |   0.732 |  0.164 |  0.191 |   0.188\n",
      "        7 | 1903 |   0.731 |  0.094 |  0.189 |   0.180\n",
      "        6 | 3475 |   0.706 |  0.171 |  0.162 |   0.163\n",
      "        2 | 2891 |   0.680 |  0.142 |  0.133 |   0.134\n",
      "        5 | 4567 |   0.659 |  0.225 |  0.110 |   0.122\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.98% accuracy, 2.8001 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1426\n",
      "     Epoch 2: Loss = 1.9229\n",
      "   ✅ Training complete. Final avg loss: 2.0328\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3453\n",
      "     Epoch 2: Loss = 2.3053\n",
      "   ✅ Training complete. Final avg loss: 2.3253\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5714\n",
      "     Epoch 2: Loss = 1.5008\n",
      "   ✅ Training complete. Final avg loss: 1.5361\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3621\n",
      "     Epoch 2: Loss = 2.3144\n",
      "   ✅ Training complete. Final avg loss: 2.3382\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3868\n",
      "     Epoch 2: Loss = 2.3166\n",
      "   ✅ Training complete. Final avg loss: 2.3517\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 6349, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9179\n",
      "     Epoch 2: Loss = 1.8814\n",
      "   ✅ Training complete. Final avg loss: 1.8996\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5176\n",
      "     Epoch 2: Loss = 1.4238\n",
      "   ✅ Training complete. Final avg loss: 1.4707\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3579\n",
      "     Epoch 2: Loss = 2.3104\n",
      "   ✅ Training complete. Final avg loss: 2.3342\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8058\n",
      "     Epoch 2: Loss = 1.7295\n",
      "   ✅ Training complete. Final avg loss: 1.7677\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8026\n",
      "     Epoch 2: Loss = 1.7521\n",
      "   ✅ Training complete. Final avg loss: 1.7773\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.315, Loss=1.946, Loss_std=0.773, Entropy=1.940\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.513\n",
      "      Stability: 0.742, Confidence: 0.224\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.691\n",
      "   ✅ Decision: KEEP (Score 0.691 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.303, Loss_std=0.103, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.424\n",
      "      Stability: 0.966, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ❌ Decision: FILTER (Score 0.260 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.462, Loss=1.534, Loss_std=1.138, Entropy=1.523\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.616\n",
      "      Stability: 0.621, Confidence: 0.391\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.717\n",
      "   ✅ Decision: KEEP (Score 0.717 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.091, Loss=2.310, Loss_std=0.108, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.304, Loss: 0.422\n",
      "      Stability: 0.964, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.250\n",
      "   ❌ Decision: FILTER (Score 0.250 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.096, Loss=2.303, Loss_std=0.172, Entropy=2.287\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.321, Loss: 0.424\n",
      "      Stability: 0.943, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.251\n",
      "   ❌ Decision: FILTER (Score 0.251 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.310, Loss=1.862, Loss_std=0.776, Entropy=1.903\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.534\n",
      "      Stability: 0.741, Confidence: 0.239\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.645\n",
      "   ✅ Decision: KEEP (Score 0.645 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.567, Loss=1.375, Loss_std=1.067, Entropy=1.434\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.656\n",
      "      Stability: 0.644, Confidence: 0.426\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.737\n",
      "   ✅ Decision: KEEP (Score 0.737 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.099, Loss=2.309, Loss_std=0.090, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.329, Loss: 0.423\n",
      "      Stability: 0.970, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.255\n",
      "   ❌ Decision: FILTER (Score 0.255 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.385, Loss=1.675, Loss_std=0.912, Entropy=1.751\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.581\n",
      "      Stability: 0.696, Confidence: 0.299\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.709\n",
      "   ✅ Decision: KEEP (Score 0.709 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.312, Loss=1.740, Loss_std=0.788, Entropy=1.756\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.565\n",
      "      Stability: 0.737, Confidence: 0.297\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.737 |    3330 | KEEP     | Score 0.737 ≥ threshold 0.400\n",
      "      2 |      2 |  0.980 |     0.717 |    1903 | KEEP     | Score 0.717 ≥ threshold 0.400\n",
      "      3 |      9 |  0.980 |     0.715 |    2891 | KEEP     | Score 0.715 ≥ threshold 0.400\n",
      "      4 |      8 |  0.980 |     0.709 |    3475 | KEEP     | Score 0.709 ≥ threshold 0.400\n",
      "      5 |      0 |  0.980 |     0.691 |    1278 | KEEP     | Score 0.691 ≥ threshold 0.400\n",
      "      6 |      5 |  0.450 |     0.645 |    6349 | KEEP     | Score 0.645 ≥ threshold 0.400\n",
      "      7 |      1 |  0.050 |     0.260 |    4285 | FILTER   | Score 0.260 < threshold 0.400\n",
      "      8 |      7 |  0.050 |     0.255 |    3306 | FILTER   | Score 0.255 < threshold 0.400\n",
      "      9 |      4 |  0.050 |     0.251 |    1913 | FILTER   | Score 0.251 < threshold 0.400\n",
      "     10 |      3 |  0.050 |     0.250 |    2493 | FILTER   | Score 0.250 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [6, 2, 9, 8, 0, 5])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.702\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 3330 |   0.737 |  0.173 |  0.204 |   0.201\n",
      "        2 | 1903 |   0.717 |  0.099 |  0.182 |   0.174\n",
      "        9 | 2891 |   0.715 |  0.150 |  0.180 |   0.177\n",
      "        8 | 3475 |   0.709 |  0.181 |  0.174 |   0.175\n",
      "        0 | 1278 |   0.691 |  0.066 |  0.155 |   0.146\n",
      "        5 | 6349 |   0.645 |  0.330 |  0.106 |   0.128\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 18.06% accuracy, 2.5753 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 6349, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9019\n",
      "     Epoch 2: Loss = 1.8683\n",
      "   ✅ Training complete. Final avg loss: 1.8851\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3321\n",
      "     Epoch 2: Loss = 2.3058\n",
      "   ✅ Training complete. Final avg loss: 2.3190\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0410\n",
      "     Epoch 2: Loss = 1.9006\n",
      "   ✅ Training complete. Final avg loss: 1.9708\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 3009, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.5621\n",
      "     Epoch 2: Loss = 1.4539\n",
      "   ✅ Training complete. Final avg loss: 1.5080\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4978\n",
      "     Epoch 2: Loss = 1.4302\n",
      "   ✅ Training complete. Final avg loss: 1.4640\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3646\n",
      "     Epoch 2: Loss = 2.3185\n",
      "   ✅ Training complete. Final avg loss: 2.3416\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3521\n",
      "     Epoch 2: Loss = 2.3117\n",
      "   ✅ Training complete. Final avg loss: 2.3319\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5941\n",
      "     Epoch 2: Loss = 1.4912\n",
      "   ✅ Training complete. Final avg loss: 1.5427\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3380\n",
      "     Epoch 2: Loss = 2.3062\n",
      "   ✅ Training complete. Final avg loss: 2.3221\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7540\n",
      "     Epoch 2: Loss = 1.7107\n",
      "   ✅ Training complete. Final avg loss: 1.7324\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.320, Loss=1.833, Loss_std=0.826, Entropy=1.867\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.542\n",
      "      Stability: 0.725, Confidence: 0.253\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.645\n",
      "   ✅ Decision: KEEP (Score 0.645 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.298, Loss_std=0.173, Entropy=2.289\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.426\n",
      "      Stability: 0.942, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ❌ Decision: FILTER (Score 0.266 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.368, Loss=1.876, Loss_std=0.809, Entropy=1.901\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.531\n",
      "      Stability: 0.730, Confidence: 0.240\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.695\n",
      "   ✅ Decision: KEEP (Score 0.695 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.603, Loss=1.395, Loss_std=1.259, Entropy=1.445\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.651\n",
      "      Stability: 0.580, Confidence: 0.422\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.668\n",
      "   ✅ Decision: KEEP (Score 0.668 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.546, Loss=1.410, Loss_std=1.068, Entropy=1.466\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.647\n",
      "      Stability: 0.644, Confidence: 0.414\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.733\n",
      "   ✅ Decision: KEEP (Score 0.733 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.300, Loss_std=0.143, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.425\n",
      "      Stability: 0.952, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.258\n",
      "   ❌ Decision: FILTER (Score 0.258 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.311, Loss_std=0.109, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.422\n",
      "      Stability: 0.964, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.543, Loss=1.352, Loss_std=1.061, Entropy=1.526\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.662\n",
      "      Stability: 0.646, Confidence: 0.390\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.732\n",
      "   ✅ Decision: KEEP (Score 0.732 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.295, Loss_std=0.108, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.426\n",
      "      Stability: 0.964, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.406, Loss=1.716, Loss_std=0.868, Entropy=1.816\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.571\n",
      "      Stability: 0.711, Confidence: 0.274\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.733 |    3330 | KEEP     | Score 0.733 ≥ threshold 0.400\n",
      "      2 |      7 |  0.980 |     0.732 |    1903 | KEEP     | Score 0.732 ≥ threshold 0.400\n",
      "      3 |      9 |  0.980 |     0.706 |    3475 | KEEP     | Score 0.706 ≥ threshold 0.400\n",
      "      4 |      2 |  0.980 |     0.695 |    1278 | KEEP     | Score 0.695 ≥ threshold 0.400\n",
      "      5 |      3 |  0.450 |     0.668 |    3009 | KEEP     | Score 0.668 ≥ threshold 0.400\n",
      "      6 |      0 |  0.450 |     0.645 |    6349 | KEEP     | Score 0.645 ≥ threshold 0.400\n",
      "      7 |      1 |  0.050 |     0.266 |    4092 | FILTER   | Score 0.266 < threshold 0.400\n",
      "      8 |      8 |  0.050 |     0.261 |    4285 | FILTER   | Score 0.261 < threshold 0.400\n",
      "      9 |      6 |  0.050 |     0.261 |    3306 | FILTER   | Score 0.261 < threshold 0.400\n",
      "     10 |      5 |  0.050 |     0.258 |    1913 | FILTER   | Score 0.258 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [4, 7, 9, 2, 3, 0])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.697\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 3330 |   0.733 |  0.172 |  0.207 |   0.203\n",
      "        7 | 1903 |   0.732 |  0.098 |  0.206 |   0.195\n",
      "        9 | 3475 |   0.706 |  0.180 |  0.177 |   0.177\n",
      "        2 | 1278 |   0.695 |  0.066 |  0.165 |   0.155\n",
      "        3 | 3009 |   0.668 |  0.156 |  0.135 |   0.137\n",
      "        0 | 6349 |   0.645 |  0.328 |  0.110 |   0.132\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 16.91% accuracy, 2.5788 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (poison):\n",
      "   Samples: 1913, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3649\n",
      "     Epoch 2: Loss = 2.3127\n",
      "   ✅ Training complete. Final avg loss: 2.3388\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5034\n",
      "     Epoch 2: Loss = 1.4213\n",
      "   ✅ Training complete. Final avg loss: 1.4623\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2493, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3532\n",
      "     Epoch 2: Loss = 2.3133\n",
      "   ✅ Training complete. Final avg loss: 2.3333\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7956\n",
      "     Epoch 2: Loss = 1.7348\n",
      "   ✅ Training complete. Final avg loss: 1.7652\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8104\n",
      "     Epoch 2: Loss = 1.7436\n",
      "   ✅ Training complete. Final avg loss: 1.7770\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3638\n",
      "     Epoch 2: Loss = 2.3139\n",
      "   ✅ Training complete. Final avg loss: 2.3389\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1278, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9994\n",
      "     Epoch 2: Loss = 1.9033\n",
      "   ✅ Training complete. Final avg loss: 1.9513\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3313\n",
      "     Epoch 2: Loss = 2.3034\n",
      "   ✅ Training complete. Final avg loss: 2.3173\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4869\n",
      "     Epoch 2: Loss = 1.3880\n",
      "   ✅ Training complete. Final avg loss: 1.4374\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7346\n",
      "     Epoch 2: Loss = 1.6952\n",
      "   ✅ Training complete. Final avg loss: 1.7149\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.137, Loss=2.287, Loss_std=0.170, Entropy=2.289\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.457, Loss: 0.428\n",
      "      Stability: 0.943, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.273\n",
      "   ❌ Decision: FILTER (Score 0.273 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.524, Loss=1.418, Loss_std=1.176, Entropy=1.343\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.646\n",
      "      Stability: 0.608, Confidence: 0.463\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.733\n",
      "   ✅ Decision: KEEP (Score 0.733 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.096, Loss=2.306, Loss_std=0.140, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.321, Loss: 0.423\n",
      "      Stability: 0.953, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.252\n",
      "   ❌ Decision: FILTER (Score 0.252 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.300, Loss=1.746, Loss_std=0.800, Entropy=1.770\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.563\n",
      "      Stability: 0.733, Confidence: 0.292\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.712\n",
      "   ✅ Decision: KEEP (Score 0.712 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.665, Loss_std=0.770, Entropy=1.862\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.584\n",
      "      Stability: 0.743, Confidence: 0.255\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.659\n",
      "   ✅ Decision: KEEP (Score 0.659 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.091, Loss=2.308, Loss_std=0.084, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.304, Loss: 0.423\n",
      "      Stability: 0.972, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.251\n",
      "   ❌ Decision: FILTER (Score 0.251 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.380, Loss=1.808, Loss_std=0.706, Entropy=1.946\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.548\n",
      "      Stability: 0.765, Confidence: 0.222\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.703\n",
      "   ✅ Decision: KEEP (Score 0.703 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.103, Loss=2.290, Loss_std=0.141, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.345, Loss: 0.427\n",
      "      Stability: 0.953, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.256\n",
      "   ❌ Decision: FILTER (Score 0.256 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.519, Loss=1.369, Loss_std=0.806, Entropy=1.543\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.658\n",
      "      Stability: 0.731, Confidence: 0.383\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.749\n",
      "   ✅ Decision: KEEP (Score 0.749 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.344, Loss=1.714, Loss_std=0.963, Entropy=1.691\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.571\n",
      "      Stability: 0.679, Confidence: 0.324\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.708\n",
      "   ✅ Decision: KEEP (Score 0.708 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.749 |    4162 | KEEP     | Score 0.749 ≥ threshold 0.400\n",
      "      2 |      1 |  0.980 |     0.733 |    3330 | KEEP     | Score 0.733 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.712 |    2891 | KEEP     | Score 0.712 ≥ threshold 0.400\n",
      "      4 |      9 |  0.980 |     0.708 |    3475 | KEEP     | Score 0.708 ≥ threshold 0.400\n",
      "      5 |      6 |  0.980 |     0.703 |    1278 | KEEP     | Score 0.703 ≥ threshold 0.400\n",
      "      6 |      4 |  0.450 |     0.659 |    4567 | KEEP     | Score 0.659 ≥ threshold 0.400\n",
      "      7 |      0 |  0.050 |     0.273 |    1913 | FILTER   | Score 0.273 < threshold 0.400\n",
      "      8 |      7 |  0.050 |     0.256 |    4092 | FILTER   | Score 0.256 < threshold 0.400\n",
      "      9 |      2 |  0.050 |     0.252 |    2493 | FILTER   | Score 0.252 < threshold 0.400\n",
      "     10 |      5 |  0.050 |     0.251 |    2947 | FILTER   | Score 0.251 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [8, 1, 3, 9, 6, 4])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.711\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 4162 |   0.749 |  0.211 |  0.209 |   0.209\n",
      "        1 | 3330 |   0.733 |  0.169 |  0.191 |   0.189\n",
      "        3 | 2891 |   0.712 |  0.147 |  0.168 |   0.166\n",
      "        9 | 3475 |   0.708 |  0.176 |  0.163 |   0.164\n",
      "        6 | 1278 |   0.703 |  0.065 |  0.158 |   0.149\n",
      "        4 | 4567 |   0.659 |  0.232 |  0.110 |   0.122\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 18.37% accuracy, 2.5575 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (poison):\n",
      "   Samples: 3306, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3611\n",
      "     Epoch 2: Loss = 2.3122\n",
      "   ✅ Training complete. Final avg loss: 2.3366\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 4162, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4299\n",
      "     Epoch 2: Loss = 1.3440\n",
      "   ✅ Training complete. Final avg loss: 1.3869\n",
      "🔧 Training Client 7 (poison):\n",
      "   Samples: 4285, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3467\n",
      "     Epoch 2: Loss = 2.3069\n",
      "   ✅ Training complete. Final avg loss: 2.3268\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2891, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7512\n",
      "     Epoch 2: Loss = 1.7038\n",
      "   ✅ Training complete. Final avg loss: 1.7275\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 4092, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3359\n",
      "     Epoch 2: Loss = 2.3025\n",
      "   ✅ Training complete. Final avg loss: 2.3192\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 1903, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6009\n",
      "     Epoch 2: Loss = 1.4706\n",
      "   ✅ Training complete. Final avg loss: 1.5357\n",
      "🔧 Training Client 14 (poison):\n",
      "   Samples: 2947, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3706\n",
      "     Epoch 2: Loss = 2.3123\n",
      "   ✅ Training complete. Final avg loss: 2.3415\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 3330, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4668\n",
      "     Epoch 2: Loss = 1.4249\n",
      "   ✅ Training complete. Final avg loss: 1.4458\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 4567, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7825\n",
      "     Epoch 2: Loss = 1.7124\n",
      "   ✅ Training complete. Final avg loss: 1.7475\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 3475, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7442\n",
      "     Epoch 2: Loss = 1.6574\n",
      "   ✅ Training complete. Final avg loss: 1.7008\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.137, Loss=2.297, Loss_std=0.069, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.457, Loss: 0.426\n",
      "      Stability: 0.977, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.277\n",
      "   ❌ Decision: FILTER (Score 0.277 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.550, Loss=1.308, Loss_std=1.090, Entropy=1.334\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.673\n",
      "      Stability: 0.637, Confidence: 0.466\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.747\n",
      "   ✅ Decision: KEEP (Score 0.747 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.302, Loss_std=0.109, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.401, Loss: 0.425\n",
      "      Stability: 0.964, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ❌ Decision: FILTER (Score 0.266 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.349, Loss=1.673, Loss_std=0.731, Entropy=1.769\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.582\n",
      "      Stability: 0.756, Confidence: 0.293\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.290, Loss_std=0.110, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.428\n",
      "      Stability: 0.963, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ❌ Decision: FILTER (Score 0.260 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.517, Loss=1.413, Loss_std=1.146, Entropy=1.448\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.647\n",
      "      Stability: 0.618, Confidence: 0.421\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.089, Loss=2.309, Loss_std=0.093, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.296, Loss: 0.423\n",
      "      Stability: 0.969, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.250\n",
      "   ❌ Decision: FILTER (Score 0.250 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.577, Loss=1.322, Loss_std=1.154, Entropy=1.325\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.669\n",
      "      Stability: 0.615, Confidence: 0.470\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.742\n",
      "   ✅ Decision: KEEP (Score 0.742 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.710, Loss_std=0.984, Entropy=1.728\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.573\n",
      "      Stability: 0.672, Confidence: 0.309\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.651\n",
      "   ✅ Decision: KEEP (Score 0.651 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.450, Loss=1.596, Loss_std=1.004, Entropy=1.631\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.601\n",
      "      Stability: 0.665, Confidence: 0.347\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      1 |  0.980 |     0.747 |    4162 | KEEP     | Score 0.747 ≥ threshold 0.400\n",
      "      2 |      7 |  0.980 |     0.742 |    3330 | KEEP     | Score 0.742 ≥ threshold 0.400\n",
      "      3 |      5 |  0.980 |     0.728 |    1903 | KEEP     | Score 0.728 ≥ threshold 0.400\n",
      "      4 |      3 |  0.980 |     0.722 |    2891 | KEEP     | Score 0.722 ≥ threshold 0.400\n",
      "      5 |      9 |  0.980 |     0.715 |    3475 | KEEP     | Score 0.715 ≥ threshold 0.400\n",
      "      6 |      8 |  0.450 |     0.651 |    4567 | KEEP     | Score 0.651 ≥ threshold 0.400\n",
      "      7 |      0 |  0.050 |     0.277 |    3306 | FILTER   | Score 0.277 < threshold 0.400\n",
      "      8 |      2 |  0.050 |     0.266 |    4285 | FILTER   | Score 0.266 < threshold 0.400\n",
      "      9 |      4 |  0.050 |     0.260 |    4092 | FILTER   | Score 0.260 < threshold 0.400\n",
      "     10 |      6 |  0.050 |     0.250 |    2947 | FILTER   | Score 0.250 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [1, 7, 5, 3, 9, 8])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.717\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        1 | 4162 |   0.747 |  0.205 |  0.196 |   0.197\n",
      "        7 | 3330 |   0.742 |  0.164 |  0.191 |   0.188\n",
      "        5 | 1903 |   0.728 |  0.094 |  0.178 |   0.169\n",
      "        3 | 2891 |   0.722 |  0.142 |  0.171 |   0.168\n",
      "        9 | 3475 |   0.715 |  0.171 |  0.165 |   0.165\n",
      "        8 | 4567 |   0.651 |  0.225 |  0.100 |   0.112\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 19.24% accuracy, 2.8063 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 19.24%\n",
      "   Best Accuracy: 19.24%\n",
      "   avg_filter_rate: 0.375\n",
      "   max_filter_rate: 0.400\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 2/8\n",
      "   Learning Rate: 0.005\n",
      "   Extreme Type: catastrophic\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'catastrophic':\n",
      "   30% pristine, 20% degraded, 50% CATASTROPHIC (unrecognizable)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_catastrophic_lr0.005_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  PRISTINE: 4 clients\n",
      "  DEGRADED: 3 clients\n",
      "  CATASTROPHIC: 8 clients\n",
      "   💀 Client 0 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 1 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 2 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 3 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 4 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 5 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 6 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 7 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 8 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 9 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 10 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 11 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 12 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 13 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 14 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.020 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   PRISTINE: 4 clients (avg score: 0.980)\n",
      "   CATASTROPHIC: 8 clients (avg score: 0.020)\n",
      "   DEGRADED: 3 clients (avg score: 0.450)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs CATASTROPHIC\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0241\n",
      "     Epoch 2: Loss = 1.9153\n",
      "   ✅ Training complete. Final avg loss: 1.9697\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0535\n",
      "     Epoch 2: Loss = 1.7297\n",
      "   ✅ Training complete. Final avg loss: 1.8916\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1086\n",
      "     Epoch 2: Loss = 1.8155\n",
      "   ✅ Training complete. Final avg loss: 1.9620\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2962\n",
      "     Epoch 2: Loss = 2.2918\n",
      "   ✅ Training complete. Final avg loss: 2.2940\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3050\n",
      "     Epoch 2: Loss = 2.3002\n",
      "   ✅ Training complete. Final avg loss: 2.3026\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2989\n",
      "     Epoch 2: Loss = 2.2919\n",
      "   ✅ Training complete. Final avg loss: 2.2954\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3034\n",
      "     Epoch 2: Loss = 2.2981\n",
      "   ✅ Training complete. Final avg loss: 2.3007\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8069\n",
      "     Epoch 2: Loss = 1.6867\n",
      "   ✅ Training complete. Final avg loss: 1.7468\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1059\n",
      "     Epoch 2: Loss = 1.8992\n",
      "   ✅ Training complete. Final avg loss: 2.0025\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.2201\n",
      "     Epoch 2: Loss = 1.8747\n",
      "   ✅ Training complete. Final avg loss: 2.0474\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=5331, Weight=0.1621, Quality=degraded\n",
      "  Client 1: Size=2013, Weight=0.0612, Quality=pristine\n",
      "  Client 2: Size=1951, Weight=0.0593, Quality=pristine\n",
      "  Client 3: Size=4717, Weight=0.1434, Quality=catastrophic\n",
      "  Client 4: Size=1524, Weight=0.0463, Quality=catastrophic\n",
      "  Client 5: Size=4946, Weight=0.1504, Quality=catastrophic\n",
      "  Client 6: Size=2108, Weight=0.0641, Quality=catastrophic\n",
      "  Client 7: Size=6957, Weight=0.2115, Quality=pristine\n",
      "  Client 8: Size=2133, Weight=0.0649, Quality=degraded\n",
      "  Client 9: Size=1210, Weight=0.0368, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 12.43% accuracy, 2.3054 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3142\n",
      "     Epoch 2: Loss = 2.2931\n",
      "   ✅ Training complete. Final avg loss: 2.3037\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7289\n",
      "     Epoch 2: Loss = 1.6563\n",
      "   ✅ Training complete. Final avg loss: 1.6926\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0308\n",
      "     Epoch 2: Loss = 1.8974\n",
      "   ✅ Training complete. Final avg loss: 1.9641\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1229\n",
      "     Epoch 2: Loss = 1.8372\n",
      "   ✅ Training complete. Final avg loss: 1.9800\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9463\n",
      "     Epoch 2: Loss = 1.8926\n",
      "   ✅ Training complete. Final avg loss: 1.9195\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3018\n",
      "     Epoch 2: Loss = 2.2941\n",
      "   ✅ Training complete. Final avg loss: 2.2979\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7665\n",
      "     Epoch 2: Loss = 1.5535\n",
      "   ✅ Training complete. Final avg loss: 1.6600\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3067\n",
      "     Epoch 2: Loss = 2.3001\n",
      "   ✅ Training complete. Final avg loss: 2.3034\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3062\n",
      "     Epoch 2: Loss = 2.2961\n",
      "   ✅ Training complete. Final avg loss: 2.3012\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8827\n",
      "     Epoch 2: Loss = 1.7075\n",
      "   ✅ Training complete. Final avg loss: 1.7951\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1524, Weight=0.0424, Quality=catastrophic\n",
      "  Client 1: Size=6957, Weight=0.1933, Quality=pristine\n",
      "  Client 2: Size=2133, Weight=0.0593, Quality=degraded\n",
      "  Client 3: Size=1210, Weight=0.0336, Quality=degraded\n",
      "  Client 4: Size=5331, Weight=0.1481, Quality=degraded\n",
      "  Client 5: Size=4717, Weight=0.1311, Quality=catastrophic\n",
      "  Client 6: Size=4764, Weight=0.1324, Quality=pristine\n",
      "  Client 7: Size=5228, Weight=0.1453, Quality=catastrophic\n",
      "  Client 8: Size=2108, Weight=0.0586, Quality=catastrophic\n",
      "  Client 9: Size=2013, Weight=0.0559, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 13.59% accuracy, 2.2562 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9374\n",
      "     Epoch 2: Loss = 1.8032\n",
      "   ✅ Training complete. Final avg loss: 1.8703\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3026\n",
      "     Epoch 2: Loss = 2.2994\n",
      "   ✅ Training complete. Final avg loss: 2.3010\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8418\n",
      "     Epoch 2: Loss = 1.6871\n",
      "   ✅ Training complete. Final avg loss: 1.7645\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9305\n",
      "     Epoch 2: Loss = 1.8745\n",
      "   ✅ Training complete. Final avg loss: 1.9025\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3042\n",
      "     Epoch 2: Loss = 2.2998\n",
      "   ✅ Training complete. Final avg loss: 2.3020\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2983\n",
      "     Epoch 2: Loss = 2.2869\n",
      "   ✅ Training complete. Final avg loss: 2.2926\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3058\n",
      "     Epoch 2: Loss = 2.2964\n",
      "   ✅ Training complete. Final avg loss: 2.3011\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3048\n",
      "     Epoch 2: Loss = 2.3021\n",
      "   ✅ Training complete. Final avg loss: 2.3035\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9689\n",
      "     Epoch 2: Loss = 1.8866\n",
      "   ✅ Training complete. Final avg loss: 1.9277\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3009\n",
      "     Epoch 2: Loss = 2.2930\n",
      "   ✅ Training complete. Final avg loss: 2.2970\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1951, Weight=0.0665, Quality=pristine\n",
      "  Client 1: Size=2108, Weight=0.0718, Quality=catastrophic\n",
      "  Client 2: Size=2013, Weight=0.0686, Quality=pristine\n",
      "  Client 3: Size=5331, Weight=0.1817, Quality=degraded\n",
      "  Client 4: Size=2117, Weight=0.0722, Quality=catastrophic\n",
      "  Client 5: Size=1990, Weight=0.0678, Quality=catastrophic\n",
      "  Client 6: Size=1524, Weight=0.0519, Quality=catastrophic\n",
      "  Client 7: Size=5228, Weight=0.1782, Quality=catastrophic\n",
      "  Client 8: Size=2133, Weight=0.0727, Quality=degraded\n",
      "  Client 9: Size=4946, Weight=0.1686, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 14.31% accuracy, 2.2397 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6653\n",
      "     Epoch 2: Loss = 1.5245\n",
      "   ✅ Training complete. Final avg loss: 1.5949\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7080\n",
      "     Epoch 2: Loss = 1.6383\n",
      "   ✅ Training complete. Final avg loss: 1.6732\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2977\n",
      "     Epoch 2: Loss = 2.2929\n",
      "   ✅ Training complete. Final avg loss: 2.2953\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3001\n",
      "     Epoch 2: Loss = 2.2963\n",
      "   ✅ Training complete. Final avg loss: 2.2982\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9097\n",
      "     Epoch 2: Loss = 1.8688\n",
      "   ✅ Training complete. Final avg loss: 1.8892\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8069\n",
      "     Epoch 2: Loss = 1.6776\n",
      "   ✅ Training complete. Final avg loss: 1.7422\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9917\n",
      "     Epoch 2: Loss = 1.8378\n",
      "   ✅ Training complete. Final avg loss: 1.9147\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9206\n",
      "     Epoch 2: Loss = 1.7888\n",
      "   ✅ Training complete. Final avg loss: 1.8547\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2927\n",
      "     Epoch 2: Loss = 2.2824\n",
      "   ✅ Training complete. Final avg loss: 2.2876\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3046\n",
      "     Epoch 2: Loss = 2.2958\n",
      "   ✅ Training complete. Final avg loss: 2.3002\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4764, Weight=0.1308, Quality=pristine\n",
      "  Client 1: Size=6957, Weight=0.1910, Quality=pristine\n",
      "  Client 2: Size=4946, Weight=0.1358, Quality=catastrophic\n",
      "  Client 3: Size=4717, Weight=0.1295, Quality=catastrophic\n",
      "  Client 4: Size=5331, Weight=0.1464, Quality=degraded\n",
      "  Client 5: Size=2013, Weight=0.0553, Quality=pristine\n",
      "  Client 6: Size=1210, Weight=0.0332, Quality=degraded\n",
      "  Client 7: Size=1951, Weight=0.0536, Quality=pristine\n",
      "  Client 8: Size=3011, Weight=0.0827, Quality=catastrophic\n",
      "  Client 9: Size=1524, Weight=0.0418, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 15.77% accuracy, 2.2272 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9951\n",
      "     Epoch 2: Loss = 1.8196\n",
      "   ✅ Training complete. Final avg loss: 1.9073\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3096\n",
      "     Epoch 2: Loss = 2.2910\n",
      "   ✅ Training complete. Final avg loss: 2.3003\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2949\n",
      "     Epoch 2: Loss = 2.2876\n",
      "   ✅ Training complete. Final avg loss: 2.2912\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3042\n",
      "     Epoch 2: Loss = 2.2982\n",
      "   ✅ Training complete. Final avg loss: 2.3012\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6368\n",
      "     Epoch 2: Loss = 1.5291\n",
      "   ✅ Training complete. Final avg loss: 1.5829\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3134\n",
      "     Epoch 2: Loss = 2.2953\n",
      "   ✅ Training complete. Final avg loss: 2.3044\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8872\n",
      "     Epoch 2: Loss = 1.8568\n",
      "   ✅ Training complete. Final avg loss: 1.8720\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3150\n",
      "     Epoch 2: Loss = 2.3009\n",
      "   ✅ Training complete. Final avg loss: 2.3080\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8843\n",
      "     Epoch 2: Loss = 1.7796\n",
      "   ✅ Training complete. Final avg loss: 1.8319\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3175\n",
      "     Epoch 2: Loss = 2.2997\n",
      "   ✅ Training complete. Final avg loss: 2.3086\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1210, Weight=0.0421, Quality=degraded\n",
      "  Client 1: Size=1990, Weight=0.0693, Quality=catastrophic\n",
      "  Client 2: Size=3011, Weight=0.1048, Quality=catastrophic\n",
      "  Client 3: Size=4717, Weight=0.1642, Quality=catastrophic\n",
      "  Client 4: Size=4764, Weight=0.1659, Quality=pristine\n",
      "  Client 5: Size=2108, Weight=0.0734, Quality=catastrophic\n",
      "  Client 6: Size=5331, Weight=0.1856, Quality=degraded\n",
      "  Client 7: Size=2117, Weight=0.0737, Quality=catastrophic\n",
      "  Client 8: Size=1951, Weight=0.0679, Quality=pristine\n",
      "  Client 9: Size=1524, Weight=0.0531, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 14.99% accuracy, 2.2245 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3019\n",
      "     Epoch 2: Loss = 2.2944\n",
      "   ✅ Training complete. Final avg loss: 2.2981\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9493\n",
      "     Epoch 2: Loss = 1.8270\n",
      "   ✅ Training complete. Final avg loss: 1.8881\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7881\n",
      "     Epoch 2: Loss = 1.6573\n",
      "   ✅ Training complete. Final avg loss: 1.7227\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5896\n",
      "     Epoch 2: Loss = 1.5289\n",
      "   ✅ Training complete. Final avg loss: 1.5593\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9489\n",
      "     Epoch 2: Loss = 1.8754\n",
      "   ✅ Training complete. Final avg loss: 1.9121\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2979\n",
      "     Epoch 2: Loss = 2.2881\n",
      "   ✅ Training complete. Final avg loss: 2.2930\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3073\n",
      "     Epoch 2: Loss = 2.2999\n",
      "   ✅ Training complete. Final avg loss: 2.3036\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8882\n",
      "     Epoch 2: Loss = 1.8525\n",
      "   ✅ Training complete. Final avg loss: 1.8703\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2954\n",
      "     Epoch 2: Loss = 2.2857\n",
      "   ✅ Training complete. Final avg loss: 2.2905\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3041\n",
      "     Epoch 2: Loss = 2.2984\n",
      "   ✅ Training complete. Final avg loss: 2.3012\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4946, Weight=0.1704, Quality=catastrophic\n",
      "  Client 1: Size=1210, Weight=0.0417, Quality=degraded\n",
      "  Client 2: Size=2013, Weight=0.0693, Quality=pristine\n",
      "  Client 3: Size=4764, Weight=0.1641, Quality=pristine\n",
      "  Client 4: Size=2133, Weight=0.0735, Quality=degraded\n",
      "  Client 5: Size=1990, Weight=0.0685, Quality=catastrophic\n",
      "  Client 6: Size=2108, Weight=0.0726, Quality=catastrophic\n",
      "  Client 7: Size=5331, Weight=0.1836, Quality=degraded\n",
      "  Client 8: Size=3011, Weight=0.1037, Quality=catastrophic\n",
      "  Client 9: Size=1524, Weight=0.0525, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 16.01% accuracy, 2.2210 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3004\n",
      "     Epoch 2: Loss = 2.2946\n",
      "   ✅ Training complete. Final avg loss: 2.2975\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8883\n",
      "     Epoch 2: Loss = 1.7641\n",
      "   ✅ Training complete. Final avg loss: 1.8262\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3056\n",
      "     Epoch 2: Loss = 2.2963\n",
      "   ✅ Training complete. Final avg loss: 2.3009\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3053\n",
      "     Epoch 2: Loss = 2.3053\n",
      "   ✅ Training complete. Final avg loss: 2.3053\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9325\n",
      "     Epoch 2: Loss = 1.8326\n",
      "   ✅ Training complete. Final avg loss: 1.8825\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2949\n",
      "     Epoch 2: Loss = 2.2866\n",
      "   ✅ Training complete. Final avg loss: 2.2908\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8845\n",
      "     Epoch 2: Loss = 1.8417\n",
      "   ✅ Training complete. Final avg loss: 1.8631\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3084\n",
      "     Epoch 2: Loss = 2.3028\n",
      "   ✅ Training complete. Final avg loss: 2.3056\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2963\n",
      "     Epoch 2: Loss = 2.2868\n",
      "   ✅ Training complete. Final avg loss: 2.2915\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3054\n",
      "     Epoch 2: Loss = 2.2984\n",
      "   ✅ Training complete. Final avg loss: 2.3019\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4946, Weight=0.1681, Quality=catastrophic\n",
      "  Client 1: Size=1951, Weight=0.0663, Quality=pristine\n",
      "  Client 2: Size=1524, Weight=0.0518, Quality=catastrophic\n",
      "  Client 3: Size=2108, Weight=0.0717, Quality=catastrophic\n",
      "  Client 4: Size=1210, Weight=0.0411, Quality=degraded\n",
      "  Client 5: Size=1990, Weight=0.0677, Quality=catastrophic\n",
      "  Client 6: Size=5331, Weight=0.1812, Quality=degraded\n",
      "  Client 7: Size=5228, Weight=0.1777, Quality=catastrophic\n",
      "  Client 8: Size=3011, Weight=0.1024, Quality=catastrophic\n",
      "  Client 9: Size=2117, Weight=0.0720, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.95% accuracy, 2.1950 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2983\n",
      "     Epoch 2: Loss = 2.2956\n",
      "   ✅ Training complete. Final avg loss: 2.2970\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8657\n",
      "     Epoch 2: Loss = 1.8306\n",
      "   ✅ Training complete. Final avg loss: 1.8481\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2969\n",
      "     Epoch 2: Loss = 2.2930\n",
      "   ✅ Training complete. Final avg loss: 2.2950\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2942\n",
      "     Epoch 2: Loss = 2.2883\n",
      "   ✅ Training complete. Final avg loss: 2.2912\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3049\n",
      "     Epoch 2: Loss = 2.3013\n",
      "   ✅ Training complete. Final avg loss: 2.3031\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9682\n",
      "     Epoch 2: Loss = 1.8677\n",
      "   ✅ Training complete. Final avg loss: 1.9179\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3057\n",
      "     Epoch 2: Loss = 2.2943\n",
      "   ✅ Training complete. Final avg loss: 2.3000\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6117\n",
      "     Epoch 2: Loss = 1.5155\n",
      "   ✅ Training complete. Final avg loss: 1.5636\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9731\n",
      "     Epoch 2: Loss = 1.8260\n",
      "   ✅ Training complete. Final avg loss: 1.8995\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8679\n",
      "     Epoch 2: Loss = 1.7653\n",
      "   ✅ Training complete. Final avg loss: 1.8166\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4717, Weight=0.1537, Quality=catastrophic\n",
      "  Client 1: Size=5331, Weight=0.1737, Quality=degraded\n",
      "  Client 2: Size=4946, Weight=0.1612, Quality=catastrophic\n",
      "  Client 3: Size=1990, Weight=0.0649, Quality=catastrophic\n",
      "  Client 4: Size=2117, Weight=0.0690, Quality=catastrophic\n",
      "  Client 5: Size=2133, Weight=0.0695, Quality=degraded\n",
      "  Client 6: Size=1524, Weight=0.0497, Quality=catastrophic\n",
      "  Client 7: Size=4764, Weight=0.1553, Quality=pristine\n",
      "  Client 8: Size=1210, Weight=0.0394, Quality=degraded\n",
      "  Client 9: Size=1951, Weight=0.0636, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 15.95% accuracy, 2.2361 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 15.95%\n",
      "   Best Accuracy: 17.95%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs CATASTROPHIC\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'catastrophic':\n",
      "   Quality threshold: 0.250\n",
      "   Minimum clients ratio: 40.0%\n",
      "   Harm detection threshold: 0.050\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0241\n",
      "     Epoch 2: Loss = 1.9154\n",
      "   ✅ Training complete. Final avg loss: 1.9697\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0535\n",
      "     Epoch 2: Loss = 1.7297\n",
      "   ✅ Training complete. Final avg loss: 1.8916\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1086\n",
      "     Epoch 2: Loss = 1.8155\n",
      "   ✅ Training complete. Final avg loss: 1.9621\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2962\n",
      "     Epoch 2: Loss = 2.2918\n",
      "   ✅ Training complete. Final avg loss: 2.2940\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3050\n",
      "     Epoch 2: Loss = 2.3002\n",
      "   ✅ Training complete. Final avg loss: 2.3026\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2989\n",
      "     Epoch 2: Loss = 2.2919\n",
      "   ✅ Training complete. Final avg loss: 2.2954\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3034\n",
      "     Epoch 2: Loss = 2.2981\n",
      "   ✅ Training complete. Final avg loss: 2.3007\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8069\n",
      "     Epoch 2: Loss = 1.6867\n",
      "   ✅ Training complete. Final avg loss: 1.7468\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1059\n",
      "     Epoch 2: Loss = 1.8992\n",
      "   ✅ Training complete. Final avg loss: 2.0025\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.2201\n",
      "     Epoch 2: Loss = 1.8747\n",
      "   ✅ Training complete. Final avg loss: 2.0474\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.341, Loss=1.879, Loss_std=0.811, Entropy=1.905\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.530\n",
      "      Stability: 0.730, Confidence: 0.238\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.641\n",
      "   ✅ Decision: KEEP (Score 0.641 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.310, Loss=1.695, Loss_std=0.947, Entropy=1.642\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.576\n",
      "      Stability: 0.684, Confidence: 0.343\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.713\n",
      "   ✅ Decision: KEEP (Score 0.713 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.834, Loss_std=0.793, Entropy=1.819\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.541\n",
      "      Stability: 0.736, Confidence: 0.273\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.154, Loss=2.289, Loss_std=0.158, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.513, Loss: 0.428\n",
      "      Stability: 0.947, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.280\n",
      "   ✅ Decision: KEEP (Score 0.280 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.137, Loss=2.297, Loss_std=0.047, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.457, Loss: 0.426\n",
      "      Stability: 0.984, Confidence: 0.079\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.275\n",
      "   ✅ Decision: KEEP (Score 0.275 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.163, Loss=2.297, Loss_std=0.147, Entropy=2.293\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.545, Loss: 0.426\n",
      "      Stability: 0.951, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.285\n",
      "   ✅ Decision: KEEP (Score 0.285 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.132, Loss=2.298, Loss_std=0.071, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.441, Loss: 0.425\n",
      "      Stability: 0.976, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.271\n",
      "   ✅ Decision: KEEP (Score 0.271 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.373, Loss=1.622, Loss_std=0.564, Entropy=1.746\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.595\n",
      "      Stability: 0.812, Confidence: 0.302\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.739\n",
      "   ✅ Decision: KEEP (Score 0.739 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.375, Loss=1.996, Loss_std=0.967, Entropy=1.854\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.501\n",
      "      Stability: 0.678, Confidence: 0.258\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.627\n",
      "   ✅ Decision: KEEP (Score 0.627 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.368, Loss=1.859, Loss_std=0.916, Entropy=1.852\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.535\n",
      "      Stability: 0.695, Confidence: 0.259\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.638\n",
      "   ✅ Decision: KEEP (Score 0.638 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.739 |    6957 | KEEP     | Score 0.739 ≥ threshold 0.250\n",
      "      2 |      1 |  0.980 |     0.713 |    2013 | KEEP     | Score 0.713 ≥ threshold 0.250\n",
      "      3 |      2 |  0.980 |     0.704 |    1951 | KEEP     | Score 0.704 ≥ threshold 0.250\n",
      "      4 |      0 |  0.450 |     0.641 |    5331 | KEEP     | Score 0.641 ≥ threshold 0.250\n",
      "      5 |      9 |  0.450 |     0.638 |    1210 | KEEP     | Score 0.638 ≥ threshold 0.250\n",
      "      6 |      8 |  0.450 |     0.627 |    2133 | KEEP     | Score 0.627 ≥ threshold 0.250\n",
      "      7 |      5 |  0.020 |     0.285 |    4946 | KEEP     | Score 0.285 ≥ threshold 0.250\n",
      "      8 |      3 |  0.020 |     0.280 |    4717 | KEEP     | Score 0.280 ≥ threshold 0.250\n",
      "      9 |      4 |  0.020 |     0.275 |    1524 | KEEP     | Score 0.275 ≥ threshold 0.250\n",
      "     10 |      6 |  0.020 |     0.271 |    2108 | KEEP     | Score 0.271 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 1, 2, 0, 9, 8, 5, 3, 4, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.517\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 6957 |   0.739 |  0.212 |  0.164 |   0.178\n",
      "        1 | 2013 |   0.713 |  0.061 |  0.157 |   0.128\n",
      "        2 | 1951 |   0.704 |  0.059 |  0.154 |   0.126\n",
      "        0 | 5331 |   0.641 |  0.162 |  0.136 |   0.144\n",
      "        9 | 1210 |   0.638 |  0.037 |  0.135 |   0.106\n",
      "        8 | 2133 |   0.627 |  0.065 |  0.132 |   0.112\n",
      "        5 | 4946 |   0.285 |  0.150 |  0.033 |   0.068\n",
      "        3 | 4717 |   0.280 |  0.143 |  0.031 |   0.065\n",
      "        4 | 1524 |   0.275 |  0.046 |  0.030 |   0.035\n",
      "        6 | 2108 |   0.271 |  0.064 |  0.029 |   0.039\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 10.00% accuracy, 2.3265 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2978\n",
      "     Epoch 2: Loss = 2.2816\n",
      "   ✅ Training complete. Final avg loss: 2.2897\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0607\n",
      "     Epoch 2: Loss = 1.8245\n",
      "   ✅ Training complete. Final avg loss: 1.9426\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9298\n",
      "     Epoch 2: Loss = 1.8067\n",
      "   ✅ Training complete. Final avg loss: 1.8683\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0023\n",
      "     Epoch 2: Loss = 1.8991\n",
      "   ✅ Training complete. Final avg loss: 1.9507\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9491\n",
      "     Epoch 2: Loss = 1.8900\n",
      "   ✅ Training complete. Final avg loss: 1.9196\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3033\n",
      "     Epoch 2: Loss = 2.2941\n",
      "   ✅ Training complete. Final avg loss: 2.2987\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3093\n",
      "     Epoch 2: Loss = 2.2963\n",
      "   ✅ Training complete. Final avg loss: 2.3028\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3070\n",
      "     Epoch 2: Loss = 2.2996\n",
      "   ✅ Training complete. Final avg loss: 2.3033\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7412\n",
      "     Epoch 2: Loss = 1.6621\n",
      "   ✅ Training complete. Final avg loss: 1.7016\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8712\n",
      "     Epoch 2: Loss = 1.7069\n",
      "   ✅ Training complete. Final avg loss: 1.7890\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.175, Loss=2.271, Loss_std=0.252, Entropy=2.274\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.585, Loss: 0.432\n",
      "      Stability: 0.916, Confidence: 0.090\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.289\n",
      "   ✅ Decision: KEEP (Score 0.289 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.373, Loss=1.782, Loss_std=0.885, Entropy=1.841\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.554\n",
      "      Stability: 0.705, Confidence: 0.264\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.646\n",
      "   ✅ Decision: KEEP (Score 0.646 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.368, Loss=1.795, Loss_std=0.799, Entropy=1.785\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.551\n",
      "      Stability: 0.734, Confidence: 0.286\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.709\n",
      "   ✅ Decision: KEEP (Score 0.709 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.440, Loss=1.879, Loss_std=0.909, Entropy=1.920\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.530\n",
      "      Stability: 0.697, Confidence: 0.232\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.633\n",
      "   ✅ Decision: KEEP (Score 0.633 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.356, Loss=1.833, Loss_std=0.823, Entropy=1.871\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.542\n",
      "      Stability: 0.726, Confidence: 0.251\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.645\n",
      "   ✅ Decision: KEEP (Score 0.645 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.154, Loss=2.287, Loss_std=0.182, Entropy=2.287\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.513, Loss: 0.428\n",
      "      Stability: 0.939, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.279\n",
      "   ✅ Decision: KEEP (Score 0.279 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.294, Loss_std=0.138, Entropy=2.293\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.426\n",
      "      Stability: 0.954, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ✅ Decision: KEEP (Score 0.260 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.301, Loss_std=0.086, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.425\n",
      "      Stability: 0.971, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ✅ Decision: KEEP (Score 0.261 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.349, Loss=1.635, Loss_std=0.676, Entropy=1.699\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.591\n",
      "      Stability: 0.775, Confidence: 0.320\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.733\n",
      "   ✅ Decision: KEEP (Score 0.733 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.421, Loss=1.638, Loss_std=0.801, Entropy=1.747\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.591\n",
      "      Stability: 0.733, Confidence: 0.301\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.720\n",
      "   ✅ Decision: KEEP (Score 0.720 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.733 |    6957 | KEEP     | Score 0.733 ≥ threshold 0.250\n",
      "      2 |      9 |  0.980 |     0.720 |    2013 | KEEP     | Score 0.720 ≥ threshold 0.250\n",
      "      3 |      2 |  0.980 |     0.709 |    1951 | KEEP     | Score 0.709 ≥ threshold 0.250\n",
      "      4 |      1 |  0.450 |     0.646 |    1210 | KEEP     | Score 0.646 ≥ threshold 0.250\n",
      "      5 |      4 |  0.450 |     0.645 |    5331 | KEEP     | Score 0.645 ≥ threshold 0.250\n",
      "      6 |      3 |  0.450 |     0.633 |    2133 | KEEP     | Score 0.633 ≥ threshold 0.250\n",
      "      7 |      0 |  0.020 |     0.289 |    3011 | KEEP     | Score 0.289 ≥ threshold 0.250\n",
      "      8 |      5 |  0.020 |     0.279 |    4717 | KEEP     | Score 0.279 ≥ threshold 0.250\n",
      "      9 |      7 |  0.020 |     0.261 |    5228 | KEEP     | Score 0.261 ≥ threshold 0.250\n",
      "     10 |      6 |  0.020 |     0.260 |    2117 | KEEP     | Score 0.260 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [8, 9, 2, 1, 4, 3, 0, 5, 7, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.517\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 6957 |   0.733 |  0.201 |  0.160 |   0.172\n",
      "        9 | 2013 |   0.720 |  0.058 |  0.157 |   0.127\n",
      "        2 | 1951 |   0.709 |  0.056 |  0.153 |   0.124\n",
      "        1 | 1210 |   0.646 |  0.035 |  0.136 |   0.106\n",
      "        4 | 5331 |   0.645 |  0.154 |  0.136 |   0.141\n",
      "        3 | 2133 |   0.633 |  0.062 |  0.132 |   0.111\n",
      "        0 | 3011 |   0.289 |  0.087 |  0.036 |   0.051\n",
      "        5 | 4717 |   0.279 |  0.136 |  0.033 |   0.064\n",
      "        7 | 5228 |   0.261 |  0.151 |  0.028 |   0.065\n",
      "        6 | 2117 |   0.260 |  0.061 |  0.028 |   0.038\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 11.87% accuracy, 2.3334 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3174\n",
      "     Epoch 2: Loss = 2.2988\n",
      "   ✅ Training complete. Final avg loss: 2.3081\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8949\n",
      "     Epoch 2: Loss = 1.7952\n",
      "   ✅ Training complete. Final avg loss: 1.8450\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3102\n",
      "     Epoch 2: Loss = 2.2936\n",
      "   ✅ Training complete. Final avg loss: 2.3019\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7162\n",
      "     Epoch 2: Loss = 1.5378\n",
      "   ✅ Training complete. Final avg loss: 1.6270\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7167\n",
      "     Epoch 2: Loss = 1.6468\n",
      "   ✅ Training complete. Final avg loss: 1.6818\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9695\n",
      "     Epoch 2: Loss = 1.8840\n",
      "   ✅ Training complete. Final avg loss: 1.9268\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3349\n",
      "     Epoch 2: Loss = 2.2970\n",
      "   ✅ Training complete. Final avg loss: 2.3159\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3062\n",
      "     Epoch 2: Loss = 2.2874\n",
      "   ✅ Training complete. Final avg loss: 2.2968\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3201\n",
      "     Epoch 2: Loss = 2.3046\n",
      "   ✅ Training complete. Final avg loss: 2.3123\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3138\n",
      "     Epoch 2: Loss = 2.3010\n",
      "   ✅ Training complete. Final avg loss: 2.3074\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.296, Loss_std=0.131, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.426\n",
      "      Stability: 0.956, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.256\n",
      "   ✅ Decision: KEEP (Score 0.256 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.308, Loss=1.803, Loss_std=0.894, Entropy=1.763\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.549\n",
      "      Stability: 0.702, Confidence: 0.295\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.703\n",
      "   ✅ Decision: KEEP (Score 0.703 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.103, Loss=2.290, Loss_std=0.144, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.345, Loss: 0.428\n",
      "      Stability: 0.952, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.253\n",
      "   ✅ Decision: KEEP (Score 0.253 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.495, Loss=1.519, Loss_std=1.104, Entropy=1.589\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.620\n",
      "      Stability: 0.632, Confidence: 0.365\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.339, Loss=1.570, Loss_std=0.599, Entropy=1.706\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.607\n",
      "      Stability: 0.800, Confidence: 0.318\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.742\n",
      "   ✅ Decision: KEEP (Score 0.742 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.433, Loss=1.876, Loss_std=0.950, Entropy=1.867\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.531\n",
      "      Stability: 0.683, Confidence: 0.253\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.634\n",
      "   ✅ Decision: KEEP (Score 0.634 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.306, Loss_std=0.152, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.423\n",
      "      Stability: 0.949, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.256\n",
      "   ✅ Decision: KEEP (Score 0.256 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.149, Loss=2.293, Loss_std=0.229, Entropy=2.278\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.497, Loss: 0.427\n",
      "      Stability: 0.924, Confidence: 0.089\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.274\n",
      "   ✅ Decision: KEEP (Score 0.274 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.132, Loss=2.297, Loss_std=0.132, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.441, Loss: 0.426\n",
      "      Stability: 0.956, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.269\n",
      "   ✅ Decision: KEEP (Score 0.269 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.139, Loss=2.296, Loss_std=0.085, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.465, Loss: 0.426\n",
      "      Stability: 0.972, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.275\n",
      "   ✅ Decision: KEEP (Score 0.275 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.742 |    6957 | KEEP     | Score 0.742 ≥ threshold 0.250\n",
      "      2 |      3 |  0.980 |     0.715 |    4764 | KEEP     | Score 0.715 ≥ threshold 0.250\n",
      "      3 |      1 |  0.980 |     0.703 |    1951 | KEEP     | Score 0.703 ≥ threshold 0.250\n",
      "      4 |      5 |  0.450 |     0.634 |    2133 | KEEP     | Score 0.634 ≥ threshold 0.250\n",
      "      5 |      9 |  0.020 |     0.275 |    5228 | KEEP     | Score 0.275 ≥ threshold 0.250\n",
      "      6 |      7 |  0.020 |     0.274 |    3011 | KEEP     | Score 0.274 ≥ threshold 0.250\n",
      "      7 |      8 |  0.020 |     0.269 |    2117 | KEEP     | Score 0.269 ≥ threshold 0.250\n",
      "      8 |      6 |  0.020 |     0.256 |    1524 | KEEP     | Score 0.256 ≥ threshold 0.250\n",
      "      9 |      0 |  0.020 |     0.256 |    2108 | KEEP     | Score 0.256 ≥ threshold 0.250\n",
      "     10 |      2 |  0.020 |     0.253 |    4946 | KEEP     | Score 0.253 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 3, 1, 5, 9, 7, 8, 6, 0, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.438\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 6957 |   0.742 |  0.200 |  0.207 |   0.205\n",
      "        3 | 4764 |   0.715 |  0.137 |  0.198 |   0.179\n",
      "        1 | 1951 |   0.703 |  0.056 |  0.193 |   0.152\n",
      "        5 | 2133 |   0.634 |  0.061 |  0.169 |   0.137\n",
      "        9 | 5228 |   0.275 |  0.150 |  0.043 |   0.075\n",
      "        7 | 3011 |   0.274 |  0.087 |  0.043 |   0.056\n",
      "        8 | 2117 |   0.269 |  0.061 |  0.041 |   0.047\n",
      "        6 | 1524 |   0.256 |  0.044 |  0.036 |   0.038\n",
      "        0 | 2108 |   0.256 |  0.061 |  0.036 |   0.044\n",
      "        2 | 4946 |   0.253 |  0.142 |  0.035 |   0.067\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 15.29% accuracy, 2.2690 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3228\n",
      "     Epoch 2: Loss = 2.2966\n",
      "   ✅ Training complete. Final avg loss: 2.3097\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3075\n",
      "     Epoch 2: Loss = 2.2942\n",
      "   ✅ Training complete. Final avg loss: 2.3008\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8891\n",
      "     Epoch 2: Loss = 1.7804\n",
      "   ✅ Training complete. Final avg loss: 1.8347\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3030\n",
      "     Epoch 2: Loss = 2.2841\n",
      "   ✅ Training complete. Final avg loss: 2.2936\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6914\n",
      "     Epoch 2: Loss = 1.6300\n",
      "   ✅ Training complete. Final avg loss: 1.6607\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3178\n",
      "     Epoch 2: Loss = 2.3039\n",
      "   ✅ Training complete. Final avg loss: 2.3108\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3071\n",
      "     Epoch 2: Loss = 2.2864\n",
      "   ✅ Training complete. Final avg loss: 2.2968\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9458\n",
      "     Epoch 2: Loss = 1.8294\n",
      "   ✅ Training complete. Final avg loss: 1.8876\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9207\n",
      "     Epoch 2: Loss = 1.8708\n",
      "   ✅ Training complete. Final avg loss: 1.8957\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3148\n",
      "     Epoch 2: Loss = 2.3021\n",
      "   ✅ Training complete. Final avg loss: 2.3085\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.292, Loss_std=0.158, Entropy=2.290\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.427\n",
      "      Stability: 0.947, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.255\n",
      "   ✅ Decision: KEEP (Score 0.255 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.151, Loss=2.291, Loss_std=0.172, Entropy=2.289\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.505, Loss: 0.427\n",
      "      Stability: 0.943, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.278\n",
      "   ✅ Decision: KEEP (Score 0.278 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.377, Loss=1.747, Loss_std=0.876, Entropy=1.764\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.563\n",
      "      Stability: 0.708, Confidence: 0.295\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.192, Loss=2.273, Loss_std=0.245, Entropy=2.278\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.641, Loss: 0.432\n",
      "      Stability: 0.918, Confidence: 0.089\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.298\n",
      "   ✅ Decision: KEEP (Score 0.298 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.373, Loss=1.599, Loss_std=0.713, Entropy=1.648\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.600\n",
      "      Stability: 0.762, Confidence: 0.341\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.736\n",
      "   ✅ Decision: KEEP (Score 0.736 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.156, Loss=2.278, Loss_std=0.149, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.521, Loss: 0.431\n",
      "      Stability: 0.950, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.282\n",
      "   ✅ Decision: KEEP (Score 0.282 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.161, Loss=2.282, Loss_std=0.236, Entropy=2.278\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.537, Loss: 0.430\n",
      "      Stability: 0.921, Confidence: 0.089\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.281\n",
      "   ✅ Decision: KEEP (Score 0.281 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.401, Loss=1.789, Loss_std=0.842, Entropy=1.866\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.553\n",
      "      Stability: 0.719, Confidence: 0.253\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.356, Loss=1.794, Loss_std=0.792, Entropy=1.882\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.551\n",
      "      Stability: 0.736, Confidence: 0.247\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.296, Loss_std=0.099, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.426\n",
      "      Stability: 0.967, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.257\n",
      "   ✅ Decision: KEEP (Score 0.257 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.736 |    6957 | KEEP     | Score 0.736 ≥ threshold 0.250\n",
      "      2 |      2 |  0.980 |     0.707 |    1951 | KEEP     | Score 0.707 ≥ threshold 0.250\n",
      "      3 |      8 |  0.450 |     0.649 |    5331 | KEEP     | Score 0.649 ≥ threshold 0.250\n",
      "      4 |      7 |  0.450 |     0.647 |    1210 | KEEP     | Score 0.647 ≥ threshold 0.250\n",
      "      5 |      3 |  0.020 |     0.298 |    3011 | KEEP     | Score 0.298 ≥ threshold 0.250\n",
      "      6 |      5 |  0.020 |     0.282 |    2108 | KEEP     | Score 0.282 ≥ threshold 0.250\n",
      "      7 |      6 |  0.020 |     0.281 |    1990 | KEEP     | Score 0.281 ≥ threshold 0.250\n",
      "      8 |      1 |  0.020 |     0.278 |    4946 | KEEP     | Score 0.278 ≥ threshold 0.250\n",
      "      9 |      9 |  0.020 |     0.257 |    5228 | KEEP     | Score 0.257 ≥ threshold 0.250\n",
      "     10 |      0 |  0.020 |     0.255 |    2117 | KEEP     | Score 0.255 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 2, 8, 7, 3, 5, 6, 1, 9, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.439\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 6957 |   0.736 |  0.200 |  0.205 |   0.203\n",
      "        2 | 1951 |   0.707 |  0.056 |  0.194 |   0.153\n",
      "        8 | 5331 |   0.649 |  0.153 |  0.174 |   0.168\n",
      "        7 | 1210 |   0.647 |  0.035 |  0.173 |   0.132\n",
      "        3 | 3011 |   0.298 |  0.086 |  0.050 |   0.061\n",
      "        5 | 2108 |   0.282 |  0.060 |  0.045 |   0.049\n",
      "        6 | 1990 |   0.281 |  0.057 |  0.044 |   0.048\n",
      "        1 | 4946 |   0.278 |  0.142 |  0.043 |   0.073\n",
      "        9 | 5228 |   0.257 |  0.150 |  0.036 |   0.070\n",
      "        0 | 2117 |   0.255 |  0.061 |  0.035 |   0.043\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 13.51% accuracy, 2.2785 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6469\n",
      "     Epoch 2: Loss = 1.5302\n",
      "   ✅ Training complete. Final avg loss: 1.5886\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6702\n",
      "     Epoch 2: Loss = 1.6207\n",
      "   ✅ Training complete. Final avg loss: 1.6455\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3209\n",
      "     Epoch 2: Loss = 2.2922\n",
      "   ✅ Training complete. Final avg loss: 2.3066\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3158\n",
      "     Epoch 2: Loss = 2.3038\n",
      "   ✅ Training complete. Final avg loss: 2.3098\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8504\n",
      "     Epoch 2: Loss = 1.7726\n",
      "   ✅ Training complete. Final avg loss: 1.8115\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3078\n",
      "     Epoch 2: Loss = 2.2951\n",
      "   ✅ Training complete. Final avg loss: 2.3015\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8894\n",
      "     Epoch 2: Loss = 1.8588\n",
      "   ✅ Training complete. Final avg loss: 1.8741\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7925\n",
      "     Epoch 2: Loss = 1.6596\n",
      "   ✅ Training complete. Final avg loss: 1.7261\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3101\n",
      "     Epoch 2: Loss = 2.2974\n",
      "   ✅ Training complete. Final avg loss: 2.3038\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3331\n",
      "     Epoch 2: Loss = 2.2995\n",
      "   ✅ Training complete. Final avg loss: 2.3163\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.502, Loss=1.475, Loss_std=1.219, Entropy=1.440\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.631\n",
      "      Stability: 0.594, Confidence: 0.424\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.720\n",
      "   ✅ Decision: KEEP (Score 0.720 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.370, Loss=1.572, Loss_std=0.753, Entropy=1.635\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.607\n",
      "      Stability: 0.749, Confidence: 0.346\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.735\n",
      "   ✅ Decision: KEEP (Score 0.735 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.154, Loss=2.294, Loss_std=0.260, Entropy=2.272\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.513, Loss: 0.426\n",
      "      Stability: 0.913, Confidence: 0.091\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.276\n",
      "   ✅ Decision: KEEP (Score 0.276 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.135, Loss=2.298, Loss_std=0.109, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.449, Loss: 0.425\n",
      "      Stability: 0.964, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.271\n",
      "   ✅ Decision: KEEP (Score 0.271 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.385, Loss=1.795, Loss_std=0.895, Entropy=1.807\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.551\n",
      "      Stability: 0.702, Confidence: 0.277\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.700\n",
      "   ✅ Decision: KEEP (Score 0.700 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.142, Loss=2.287, Loss_std=0.162, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.473, Loss: 0.428\n",
      "      Stability: 0.946, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.273\n",
      "   ✅ Decision: KEEP (Score 0.273 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.377, Loss=1.779, Loss_std=0.884, Entropy=1.801\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.555\n",
      "      Stability: 0.705, Confidence: 0.280\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.375, Loss=1.662, Loss_std=0.932, Entropy=1.681\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.585\n",
      "      Stability: 0.689, Confidence: 0.327\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.714\n",
      "   ✅ Decision: KEEP (Score 0.714 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.142, Loss=2.291, Loss_std=0.154, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.473, Loss: 0.427\n",
      "      Stability: 0.949, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.273\n",
      "   ✅ Decision: KEEP (Score 0.273 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.142, Loss=2.288, Loss_std=0.183, Entropy=2.286\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.473, Loss: 0.428\n",
      "      Stability: 0.939, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.272\n",
      "   ✅ Decision: KEEP (Score 0.272 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      1 |  0.980 |     0.735 |    6957 | KEEP     | Score 0.735 ≥ threshold 0.250\n",
      "      2 |      0 |  0.980 |     0.720 |    4764 | KEEP     | Score 0.720 ≥ threshold 0.250\n",
      "      3 |      7 |  0.980 |     0.714 |    2013 | KEEP     | Score 0.714 ≥ threshold 0.250\n",
      "      4 |      4 |  0.980 |     0.700 |    1951 | KEEP     | Score 0.700 ≥ threshold 0.250\n",
      "      5 |      6 |  0.450 |     0.649 |    5331 | KEEP     | Score 0.649 ≥ threshold 0.250\n",
      "      6 |      2 |  0.020 |     0.276 |    1990 | KEEP     | Score 0.276 ≥ threshold 0.250\n",
      "      7 |      8 |  0.020 |     0.273 |    4717 | KEEP     | Score 0.273 ≥ threshold 0.250\n",
      "      8 |      5 |  0.020 |     0.273 |    4946 | KEEP     | Score 0.273 ≥ threshold 0.250\n",
      "      9 |      9 |  0.020 |     0.272 |    1524 | KEEP     | Score 0.272 ≥ threshold 0.250\n",
      "     10 |      3 |  0.020 |     0.271 |    5228 | KEEP     | Score 0.271 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [1, 0, 7, 4, 6, 2, 8, 5, 9, 3])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.488\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        1 | 6957 |   0.735 |  0.176 |  0.178 |   0.177\n",
      "        0 | 4764 |   0.720 |  0.121 |  0.173 |   0.157\n",
      "        7 | 2013 |   0.714 |  0.051 |  0.171 |   0.135\n",
      "        4 | 1951 |   0.700 |  0.049 |  0.167 |   0.131\n",
      "        6 | 5331 |   0.649 |  0.135 |  0.151 |   0.146\n",
      "        2 | 1990 |   0.276 |  0.050 |  0.033 |   0.038\n",
      "        8 | 4717 |   0.273 |  0.120 |  0.032 |   0.058\n",
      "        5 | 4946 |   0.273 |  0.125 |  0.032 |   0.060\n",
      "        9 | 1524 |   0.272 |  0.039 |  0.032 |   0.034\n",
      "        3 | 5228 |   0.271 |  0.133 |  0.032 |   0.062\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.15% accuracy, 2.2622 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9738\n",
      "     Epoch 2: Loss = 1.8074\n",
      "   ✅ Training complete. Final avg loss: 1.8906\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3122\n",
      "     Epoch 2: Loss = 2.3018\n",
      "   ✅ Training complete. Final avg loss: 2.3070\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3177\n",
      "     Epoch 2: Loss = 2.3081\n",
      "   ✅ Training complete. Final avg loss: 2.3129\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3298\n",
      "     Epoch 2: Loss = 2.3046\n",
      "   ✅ Training complete. Final avg loss: 2.3172\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3159\n",
      "     Epoch 2: Loss = 2.3030\n",
      "   ✅ Training complete. Final avg loss: 2.3095\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3095\n",
      "     Epoch 2: Loss = 2.2898\n",
      "   ✅ Training complete. Final avg loss: 2.2996\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8780\n",
      "     Epoch 2: Loss = 1.8479\n",
      "   ✅ Training complete. Final avg loss: 1.8629\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6580\n",
      "     Epoch 2: Loss = 1.6027\n",
      "   ✅ Training complete. Final avg loss: 1.6304\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6084\n",
      "     Epoch 2: Loss = 1.5229\n",
      "   ✅ Training complete. Final avg loss: 1.5657\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8309\n",
      "     Epoch 2: Loss = 1.7563\n",
      "   ✅ Training complete. Final avg loss: 1.7936\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.375, Loss=1.788, Loss_std=0.827, Entropy=1.907\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.553\n",
      "      Stability: 0.724, Confidence: 0.237\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.645\n",
      "   ✅ Decision: KEEP (Score 0.645 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.159, Loss=2.290, Loss_std=0.154, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.529, Loss: 0.427\n",
      "      Stability: 0.949, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.282\n",
      "   ✅ Decision: KEEP (Score 0.282 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.298, Loss_std=0.197, Entropy=2.283\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.401, Loss: 0.425\n",
      "      Stability: 0.934, Confidence: 0.087\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ✅ Decision: KEEP (Score 0.260 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.300, Loss_std=0.204, Entropy=2.281\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.425\n",
      "      Stability: 0.932, Confidence: 0.087\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.262\n",
      "   ✅ Decision: KEEP (Score 0.262 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.096, Loss=2.301, Loss_std=0.122, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.321, Loss: 0.425\n",
      "      Stability: 0.959, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.250\n",
      "   ❌ Decision: FILTER (Score 0.250 < threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.188, Loss=2.269, Loss_std=0.276, Entropy=2.271\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.625, Loss: 0.433\n",
      "      Stability: 0.908, Confidence: 0.091\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.294\n",
      "   ✅ Decision: KEEP (Score 0.294 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.337, Loss=1.900, Loss_std=0.852, Entropy=1.867\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.525\n",
      "      Stability: 0.716, Confidence: 0.253\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.640\n",
      "   ✅ Decision: KEEP (Score 0.640 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.590, Loss_std=0.835, Entropy=1.617\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.603\n",
      "      Stability: 0.722, Confidence: 0.353\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.729\n",
      "   ✅ Decision: KEEP (Score 0.729 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.536, Loss=1.456, Loss_std=1.073, Entropy=1.565\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.636\n",
      "      Stability: 0.642, Confidence: 0.374\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.723\n",
      "   ✅ Decision: KEEP (Score 0.723 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.406, Loss=1.667, Loss_std=0.856, Entropy=1.718\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.583\n",
      "      Stability: 0.715, Confidence: 0.313\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.729 |    6957 | KEEP     | Score 0.729 ≥ threshold 0.250\n",
      "      2 |      8 |  0.980 |     0.723 |    4764 | KEEP     | Score 0.723 ≥ threshold 0.250\n",
      "      3 |      9 |  0.980 |     0.716 |    1951 | KEEP     | Score 0.716 ≥ threshold 0.250\n",
      "      4 |      0 |  0.450 |     0.645 |    1210 | KEEP     | Score 0.645 ≥ threshold 0.250\n",
      "      5 |      6 |  0.450 |     0.640 |    5331 | KEEP     | Score 0.640 ≥ threshold 0.250\n",
      "      6 |      5 |  0.020 |     0.294 |    3011 | KEEP     | Score 0.294 ≥ threshold 0.250\n",
      "      7 |      1 |  0.020 |     0.282 |    4717 | KEEP     | Score 0.282 ≥ threshold 0.250\n",
      "      8 |      3 |  0.020 |     0.262 |    2117 | KEEP     | Score 0.262 ≥ threshold 0.250\n",
      "      9 |      2 |  0.020 |     0.260 |    2108 | KEEP     | Score 0.260 ≥ threshold 0.250\n",
      "     10 |      4 |  0.020 |     0.250 |    5228 | FILTER   | Score 0.250 < threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 9 (IDs: [7, 8, 9, 0, 6, 5, 1, 3, 2])\n",
      "   Filter rate: 10.0%\n",
      "   Average quality score: 0.506\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 6957 |   0.729 |  0.216 |  0.183 |   0.193\n",
      "        8 | 4764 |   0.723 |  0.148 |  0.181 |   0.171\n",
      "        9 | 1951 |   0.716 |  0.061 |  0.179 |   0.143\n",
      "        0 | 1210 |   0.645 |  0.038 |  0.156 |   0.120\n",
      "        6 | 5331 |   0.640 |  0.166 |  0.154 |   0.158\n",
      "        5 | 3011 |   0.294 |  0.094 |  0.043 |   0.058\n",
      "        1 | 4717 |   0.282 |  0.147 |  0.039 |   0.072\n",
      "        3 | 2117 |   0.262 |  0.066 |  0.033 |   0.043\n",
      "        2 | 2108 |   0.260 |  0.066 |  0.032 |   0.042\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.71% accuracy, 2.2714 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3237\n",
      "     Epoch 2: Loss = 2.3089\n",
      "   ✅ Training complete. Final avg loss: 2.3163\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3081\n",
      "     Epoch 2: Loss = 2.2948\n",
      "   ✅ Training complete. Final avg loss: 2.3015\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9244\n",
      "     Epoch 2: Loss = 1.8104\n",
      "   ✅ Training complete. Final avg loss: 1.8674\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3217\n",
      "     Epoch 2: Loss = 2.3063\n",
      "   ✅ Training complete. Final avg loss: 2.3140\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3315\n",
      "     Epoch 2: Loss = 2.3040\n",
      "   ✅ Training complete. Final avg loss: 2.3178\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3121\n",
      "     Epoch 2: Loss = 2.2920\n",
      "   ✅ Training complete. Final avg loss: 2.3020\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5742\n",
      "     Epoch 2: Loss = 1.5135\n",
      "   ✅ Training complete. Final avg loss: 1.5439\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3114\n",
      "     Epoch 2: Loss = 2.2938\n",
      "   ✅ Training complete. Final avg loss: 2.3026\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8735\n",
      "     Epoch 2: Loss = 1.8308\n",
      "   ✅ Training complete. Final avg loss: 1.8522\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6379\n",
      "     Epoch 2: Loss = 1.5770\n",
      "   ✅ Training complete. Final avg loss: 1.6075\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.149, Loss=2.286, Loss_std=0.147, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.497, Loss: 0.429\n",
      "      Stability: 0.951, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.278\n",
      "   ✅ Decision: KEEP (Score 0.278 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.135, Loss=2.300, Loss_std=0.139, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.449, Loss: 0.425\n",
      "      Stability: 0.954, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.270\n",
      "   ✅ Decision: KEEP (Score 0.270 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.387, Loss=1.791, Loss_std=0.911, Entropy=1.833\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.552\n",
      "      Stability: 0.696, Confidence: 0.267\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.644\n",
      "   ✅ Decision: KEEP (Score 0.644 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.132, Loss=2.294, Loss_std=0.159, Entropy=2.290\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.441, Loss: 0.426\n",
      "      Stability: 0.947, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.268\n",
      "   ✅ Decision: KEEP (Score 0.268 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.300, Loss_std=0.239, Entropy=2.276\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.425\n",
      "      Stability: 0.920, Confidence: 0.090\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.263\n",
      "   ✅ Decision: KEEP (Score 0.263 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.171, Loss=2.286, Loss_std=0.279, Entropy=2.268\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.569, Loss: 0.429\n",
      "      Stability: 0.907, Confidence: 0.093\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.284\n",
      "   ✅ Decision: KEEP (Score 0.284 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.493, Loss=1.548, Loss_std=1.122, Entropy=1.553\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.613\n",
      "      Stability: 0.626, Confidence: 0.379\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.183, Loss=2.279, Loss_std=0.213, Entropy=2.284\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.609, Loss: 0.430\n",
      "      Stability: 0.929, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.293\n",
      "   ✅ Decision: KEEP (Score 0.293 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.425, Loss=1.750, Loss_std=0.895, Entropy=1.814\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.563\n",
      "      Stability: 0.702, Confidence: 0.274\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.433, Loss=1.484, Loss_std=0.742, Entropy=1.621\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.629\n",
      "      Stability: 0.753, Confidence: 0.352\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.742\n",
      "   ✅ Decision: KEEP (Score 0.742 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      9 |  0.980 |     0.742 |    6957 | KEEP     | Score 0.742 ≥ threshold 0.250\n",
      "      2 |      6 |  0.980 |     0.715 |    4764 | KEEP     | Score 0.715 ≥ threshold 0.250\n",
      "      3 |      8 |  0.450 |     0.649 |    5331 | KEEP     | Score 0.649 ≥ threshold 0.250\n",
      "      4 |      2 |  0.450 |     0.644 |    1210 | KEEP     | Score 0.644 ≥ threshold 0.250\n",
      "      5 |      7 |  0.020 |     0.293 |    3011 | KEEP     | Score 0.293 ≥ threshold 0.250\n",
      "      6 |      5 |  0.020 |     0.284 |    1990 | KEEP     | Score 0.284 ≥ threshold 0.250\n",
      "      7 |      0 |  0.020 |     0.278 |    2117 | KEEP     | Score 0.278 ≥ threshold 0.250\n",
      "      8 |      1 |  0.020 |     0.270 |    4946 | KEEP     | Score 0.270 ≥ threshold 0.250\n",
      "      9 |      3 |  0.020 |     0.268 |    2108 | KEEP     | Score 0.268 ≥ threshold 0.250\n",
      "     10 |      4 |  0.020 |     0.263 |    1524 | KEEP     | Score 0.263 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [9, 6, 8, 2, 7, 5, 0, 1, 3, 4])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.441\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        9 | 6957 |   0.742 |  0.205 |  0.209 |   0.208\n",
      "        6 | 4764 |   0.715 |  0.140 |  0.199 |   0.181\n",
      "        8 | 5331 |   0.649 |  0.157 |  0.175 |   0.170\n",
      "        2 | 1210 |   0.644 |  0.036 |  0.173 |   0.132\n",
      "        7 | 3011 |   0.293 |  0.089 |  0.047 |   0.059\n",
      "        5 | 1990 |   0.284 |  0.059 |  0.044 |   0.048\n",
      "        0 | 2117 |   0.278 |  0.062 |  0.041 |   0.048\n",
      "        1 | 4946 |   0.270 |  0.146 |  0.038 |   0.071\n",
      "        3 | 2108 |   0.268 |  0.062 |  0.038 |   0.045\n",
      "        4 | 1524 |   0.263 |  0.045 |  0.036 |   0.039\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 18.38% accuracy, 2.2714 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9196\n",
      "     Epoch 2: Loss = 1.8451\n",
      "   ✅ Training complete. Final avg loss: 1.8823\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3293\n",
      "     Epoch 2: Loss = 2.3004\n",
      "   ✅ Training complete. Final avg loss: 2.3149\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3075\n",
      "     Epoch 2: Loss = 2.2974\n",
      "   ✅ Training complete. Final avg loss: 2.3025\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9046\n",
      "     Epoch 2: Loss = 1.8193\n",
      "   ✅ Training complete. Final avg loss: 1.8619\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3147\n",
      "     Epoch 2: Loss = 2.2994\n",
      "   ✅ Training complete. Final avg loss: 2.3071\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6120\n",
      "     Epoch 2: Loss = 1.5478\n",
      "   ✅ Training complete. Final avg loss: 1.5799\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8567\n",
      "     Epoch 2: Loss = 1.8136\n",
      "   ✅ Training complete. Final avg loss: 1.8352\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3153\n",
      "     Epoch 2: Loss = 2.3041\n",
      "   ✅ Training complete. Final avg loss: 2.3097\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8475\n",
      "     Epoch 2: Loss = 1.7310\n",
      "   ✅ Training complete. Final avg loss: 1.7892\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3101\n",
      "     Epoch 2: Loss = 2.3027\n",
      "   ✅ Training complete. Final avg loss: 2.3064\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.459, Loss=1.792, Loss_std=0.906, Entropy=1.878\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.552\n",
      "      Stability: 0.698, Confidence: 0.249\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.641\n",
      "   ✅ Decision: KEEP (Score 0.641 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.286, Loss_std=0.188, Entropy=2.284\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.429\n",
      "      Stability: 0.937, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ✅ Decision: KEEP (Score 0.266 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.163, Loss=2.298, Loss_std=0.168, Entropy=2.290\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.545, Loss: 0.426\n",
      "      Stability: 0.944, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.284\n",
      "   ✅ Decision: KEEP (Score 0.284 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.365, Loss=1.811, Loss_std=1.014, Entropy=1.745\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.547\n",
      "      Stability: 0.662, Confidence: 0.302\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.641\n",
      "   ✅ Decision: KEEP (Score 0.641 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.135, Loss=2.301, Loss_std=0.168, Entropy=2.289\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.449, Loss: 0.425\n",
      "      Stability: 0.944, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.269\n",
      "   ✅ Decision: KEEP (Score 0.269 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.476, Loss=1.486, Loss_std=0.846, Entropy=1.597\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.629\n",
      "      Stability: 0.718, Confidence: 0.361\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.736\n",
      "   ✅ Decision: KEEP (Score 0.736 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.430, Loss=1.789, Loss_std=0.974, Entropy=1.786\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.553\n",
      "      Stability: 0.675, Confidence: 0.286\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.643\n",
      "   ✅ Decision: KEEP (Score 0.643 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.299, Loss_std=0.148, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.401, Loss: 0.425\n",
      "      Stability: 0.951, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.262\n",
      "   ✅ Decision: KEEP (Score 0.262 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.394, Loss=1.667, Loss_std=0.765, Entropy=1.819\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.583\n",
      "      Stability: 0.745, Confidence: 0.272\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.101, Loss=2.300, Loss_std=0.156, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.337, Loss: 0.425\n",
      "      Stability: 0.948, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.251\n",
      "   ✅ Decision: KEEP (Score 0.251 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      5 |  0.980 |     0.736 |    6957 | KEEP     | Score 0.736 ≥ threshold 0.250\n",
      "      2 |      8 |  0.980 |     0.716 |    1951 | KEEP     | Score 0.716 ≥ threshold 0.250\n",
      "      3 |      6 |  0.450 |     0.643 |    5331 | KEEP     | Score 0.643 ≥ threshold 0.250\n",
      "      4 |      3 |  0.450 |     0.641 |    1210 | KEEP     | Score 0.641 ≥ threshold 0.250\n",
      "      5 |      0 |  0.450 |     0.641 |    2133 | KEEP     | Score 0.641 ≥ threshold 0.250\n",
      "      6 |      2 |  0.020 |     0.284 |    4946 | KEEP     | Score 0.284 ≥ threshold 0.250\n",
      "      7 |      4 |  0.020 |     0.269 |    4717 | KEEP     | Score 0.269 ≥ threshold 0.250\n",
      "      8 |      1 |  0.020 |     0.266 |    1524 | KEEP     | Score 0.266 ≥ threshold 0.250\n",
      "      9 |      7 |  0.020 |     0.262 |    2117 | KEEP     | Score 0.262 ≥ threshold 0.250\n",
      "     10 |      9 |  0.020 |     0.251 |    5228 | KEEP     | Score 0.251 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [5, 8, 6, 3, 0, 2, 4, 1, 7, 9])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.471\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        5 | 6957 |   0.736 |  0.193 |  0.183 |   0.186\n",
      "        8 | 1951 |   0.716 |  0.054 |  0.177 |   0.140\n",
      "        6 | 5331 |   0.643 |  0.148 |  0.154 |   0.152\n",
      "        3 | 1210 |   0.641 |  0.034 |  0.153 |   0.117\n",
      "        0 | 2133 |   0.641 |  0.059 |  0.153 |   0.125\n",
      "        2 | 4946 |   0.284 |  0.137 |  0.042 |   0.070\n",
      "        4 | 4717 |   0.269 |  0.131 |  0.037 |   0.065\n",
      "        1 | 1524 |   0.266 |  0.042 |  0.036 |   0.038\n",
      "        7 | 2117 |   0.262 |  0.059 |  0.035 |   0.042\n",
      "        9 | 5228 |   0.251 |  0.145 |  0.031 |   0.065\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 19.84% accuracy, 2.2382 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 19.84%\n",
      "   Best Accuracy: 19.84%\n",
      "   avg_filter_rate: 0.012\n",
      "   max_filter_rate: 0.100\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 3/8\n",
      "   Learning Rate: 0.005\n",
      "   Extreme Type: byzantine\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'byzantine':\n",
      "   50% honest, 20% poor quality, 30% BYZANTINE (adversarial)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_byzantine_lr0.005_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  PRISTINE: 7 clients\n",
      "  DEGRADED: 3 clients\n",
      "  BYZANTINE: 5 clients\n",
      "   💀 Client 0 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 1 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 2 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 3 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 4 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 5 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 6 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 7 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 8 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 9 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 10 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 11 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 12 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 13 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 14 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.010 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   BYZANTINE: 5 clients (avg score: 0.010)\n",
      "   PRISTINE: 7 clients (avg score: 0.980)\n",
      "   DEGRADED: 3 clients (avg score: 0.450)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs BYZANTINE\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.9185\n",
      "     Epoch 2: Loss = 1.5612\n",
      "   ✅ Training complete. Final avg loss: 1.7398\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0935\n",
      "     Epoch 2: Loss = 1.8134\n",
      "   ✅ Training complete. Final avg loss: 1.9535\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1139\n",
      "     Epoch 2: Loss = 1.8021\n",
      "   ✅ Training complete. Final avg loss: 1.9580\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6632\n",
      "     Epoch 2: Loss = 1.3285\n",
      "   ✅ Training complete. Final avg loss: 1.4959\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1785\n",
      "     Epoch 2: Loss = 2.1198\n",
      "   ✅ Training complete. Final avg loss: 2.1492\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8983\n",
      "     Epoch 2: Loss = 1.7678\n",
      "   ✅ Training complete. Final avg loss: 1.8331\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7611\n",
      "     Epoch 2: Loss = 1.5565\n",
      "   ✅ Training complete. Final avg loss: 1.6588\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2715\n",
      "     Epoch 2: Loss = 2.1447\n",
      "   ✅ Training complete. Final avg loss: 2.2081\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6481\n",
      "     Epoch 2: Loss = 1.3728\n",
      "   ✅ Training complete. Final avg loss: 1.5105\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0635\n",
      "     Epoch 2: Loss = 1.8029\n",
      "   ✅ Training complete. Final avg loss: 1.9332\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=3686, Weight=0.1035, Quality=byzantine\n",
      "  Client 1: Size=1990, Weight=0.0559, Quality=degraded\n",
      "  Client 2: Size=1753, Weight=0.0492, Quality=pristine\n",
      "  Client 3: Size=3432, Weight=0.0964, Quality=pristine\n",
      "  Client 4: Size=6352, Weight=0.1784, Quality=degraded\n",
      "  Client 5: Size=5934, Weight=0.1666, Quality=pristine\n",
      "  Client 6: Size=4303, Weight=0.1208, Quality=pristine\n",
      "  Client 7: Size=1877, Weight=0.0527, Quality=byzantine\n",
      "  Client 8: Size=4072, Weight=0.1143, Quality=pristine\n",
      "  Client 9: Size=2211, Weight=0.0621, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 11.80% accuracy, 2.3207 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0943\n",
      "     Epoch 2: Loss = 2.0001\n",
      "   ✅ Training complete. Final avg loss: 2.0472\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0599\n",
      "     Epoch 2: Loss = 1.9816\n",
      "   ✅ Training complete. Final avg loss: 2.0208\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8821\n",
      "     Epoch 2: Loss = 1.7583\n",
      "   ✅ Training complete. Final avg loss: 1.8202\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1636\n",
      "     Epoch 2: Loss = 2.0534\n",
      "   ✅ Training complete. Final avg loss: 2.1085\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4713\n",
      "     Epoch 2: Loss = 1.2885\n",
      "   ✅ Training complete. Final avg loss: 1.3799\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9516\n",
      "     Epoch 2: Loss = 1.7793\n",
      "   ✅ Training complete. Final avg loss: 1.8654\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6480\n",
      "     Epoch 2: Loss = 1.5326\n",
      "   ✅ Training complete. Final avg loss: 1.5903\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6795\n",
      "     Epoch 2: Loss = 1.5642\n",
      "   ✅ Training complete. Final avg loss: 1.6218\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8366\n",
      "     Epoch 2: Loss = 1.7467\n",
      "   ✅ Training complete. Final avg loss: 1.7917\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1284\n",
      "     Epoch 2: Loss = 2.0840\n",
      "   ✅ Training complete. Final avg loss: 2.1062\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2419, Weight=0.0645, Quality=byzantine\n",
      "  Client 1: Size=4484, Weight=0.1195, Quality=byzantine\n",
      "  Client 2: Size=2211, Weight=0.0589, Quality=pristine\n",
      "  Client 3: Size=2714, Weight=0.0723, Quality=byzantine\n",
      "  Client 4: Size=3432, Weight=0.0915, Quality=pristine\n",
      "  Client 5: Size=1990, Weight=0.0530, Quality=degraded\n",
      "  Client 6: Size=4303, Weight=0.1147, Quality=pristine\n",
      "  Client 7: Size=3686, Weight=0.0982, Quality=byzantine\n",
      "  Client 8: Size=5934, Weight=0.1581, Quality=pristine\n",
      "  Client 9: Size=6352, Weight=0.1693, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 18.90% accuracy, 2.3419 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1284\n",
      "     Epoch 2: Loss = 2.0565\n",
      "   ✅ Training complete. Final avg loss: 2.0924\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8856\n",
      "     Epoch 2: Loss = 1.7338\n",
      "   ✅ Training complete. Final avg loss: 1.8097\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5488\n",
      "     Epoch 2: Loss = 1.3311\n",
      "   ✅ Training complete. Final avg loss: 1.4400\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5849\n",
      "     Epoch 2: Loss = 1.5140\n",
      "   ✅ Training complete. Final avg loss: 1.5494\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3680\n",
      "     Epoch 2: Loss = 1.2617\n",
      "   ✅ Training complete. Final avg loss: 1.3149\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.7000\n",
      "     Epoch 2: Loss = 1.5609\n",
      "   ✅ Training complete. Final avg loss: 1.6304\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0994\n",
      "     Epoch 2: Loss = 2.0644\n",
      "   ✅ Training complete. Final avg loss: 2.0819\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8910\n",
      "     Epoch 2: Loss = 1.7446\n",
      "   ✅ Training complete. Final avg loss: 1.8178\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1205\n",
      "     Epoch 2: Loss = 2.0150\n",
      "   ✅ Training complete. Final avg loss: 2.0677\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9783\n",
      "     Epoch 2: Loss = 1.7994\n",
      "   ✅ Training complete. Final avg loss: 1.8888\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2714, Weight=0.0804, Quality=byzantine\n",
      "  Client 1: Size=1990, Weight=0.0590, Quality=degraded\n",
      "  Client 2: Size=4072, Weight=0.1207, Quality=pristine\n",
      "  Client 3: Size=4303, Weight=0.1275, Quality=pristine\n",
      "  Client 4: Size=3432, Weight=0.1017, Quality=pristine\n",
      "  Client 5: Size=3686, Weight=0.1092, Quality=byzantine\n",
      "  Client 6: Size=6352, Weight=0.1883, Quality=degraded\n",
      "  Client 7: Size=2868, Weight=0.0850, Quality=pristine\n",
      "  Client 8: Size=2419, Weight=0.0717, Quality=byzantine\n",
      "  Client 9: Size=1905, Weight=0.0565, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 16.13% accuracy, 2.2882 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7922\n",
      "     Epoch 2: Loss = 1.7269\n",
      "   ✅ Training complete. Final avg loss: 1.7595\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1334\n",
      "     Epoch 2: Loss = 2.0099\n",
      "   ✅ Training complete. Final avg loss: 2.0716\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5562\n",
      "     Epoch 2: Loss = 1.4811\n",
      "   ✅ Training complete. Final avg loss: 1.5187\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7919\n",
      "     Epoch 2: Loss = 1.6919\n",
      "   ✅ Training complete. Final avg loss: 1.7419\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6897\n",
      "     Epoch 2: Loss = 1.5609\n",
      "   ✅ Training complete. Final avg loss: 1.6253\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8165\n",
      "     Epoch 2: Loss = 1.6973\n",
      "   ✅ Training complete. Final avg loss: 1.7569\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8185\n",
      "     Epoch 2: Loss = 1.7199\n",
      "   ✅ Training complete. Final avg loss: 1.7692\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3584\n",
      "     Epoch 2: Loss = 1.2424\n",
      "   ✅ Training complete. Final avg loss: 1.3004\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0753\n",
      "     Epoch 2: Loss = 2.0356\n",
      "   ✅ Training complete. Final avg loss: 2.0554\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0588\n",
      "     Epoch 2: Loss = 1.9837\n",
      "   ✅ Training complete. Final avg loss: 2.0213\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2868, Weight=0.0761, Quality=pristine\n",
      "  Client 1: Size=2419, Weight=0.0642, Quality=byzantine\n",
      "  Client 2: Size=4303, Weight=0.1142, Quality=pristine\n",
      "  Client 3: Size=5934, Weight=0.1575, Quality=pristine\n",
      "  Client 4: Size=3686, Weight=0.0978, Quality=byzantine\n",
      "  Client 5: Size=2211, Weight=0.0587, Quality=pristine\n",
      "  Client 6: Size=1990, Weight=0.0528, Quality=degraded\n",
      "  Client 7: Size=3432, Weight=0.0911, Quality=pristine\n",
      "  Client 8: Size=6352, Weight=0.1686, Quality=degraded\n",
      "  Client 9: Size=4484, Weight=0.1190, Quality=byzantine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 22.89% accuracy, 2.2876 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8989\n",
      "     Epoch 2: Loss = 1.7603\n",
      "   ✅ Training complete. Final avg loss: 1.8296\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1495\n",
      "     Epoch 2: Loss = 2.0130\n",
      "   ✅ Training complete. Final avg loss: 2.0812\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3184\n",
      "     Epoch 2: Loss = 1.2004\n",
      "   ✅ Training complete. Final avg loss: 1.2594\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0457\n",
      "     Epoch 2: Loss = 1.9785\n",
      "   ✅ Training complete. Final avg loss: 2.0121\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7981\n",
      "     Epoch 2: Loss = 1.7119\n",
      "   ✅ Training complete. Final avg loss: 1.7550\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8820\n",
      "     Epoch 2: Loss = 1.7666\n",
      "   ✅ Training complete. Final avg loss: 1.8243\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0311\n",
      "     Epoch 2: Loss = 1.9624\n",
      "   ✅ Training complete. Final avg loss: 1.9968\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1923\n",
      "     Epoch 2: Loss = 2.0697\n",
      "   ✅ Training complete. Final avg loss: 2.1310\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8312\n",
      "     Epoch 2: Loss = 1.7086\n",
      "   ✅ Training complete. Final avg loss: 1.7699\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5319\n",
      "     Epoch 2: Loss = 1.4300\n",
      "   ✅ Training complete. Final avg loss: 1.4809\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1753, Weight=0.0559, Quality=pristine\n",
      "  Client 1: Size=2419, Weight=0.0771, Quality=byzantine\n",
      "  Client 2: Size=3432, Weight=0.1094, Quality=pristine\n",
      "  Client 3: Size=4484, Weight=0.1429, Quality=byzantine\n",
      "  Client 4: Size=2868, Weight=0.0914, Quality=pristine\n",
      "  Client 5: Size=1905, Weight=0.0607, Quality=degraded\n",
      "  Client 6: Size=6352, Weight=0.2024, Quality=degraded\n",
      "  Client 7: Size=1877, Weight=0.0598, Quality=byzantine\n",
      "  Client 8: Size=1990, Weight=0.0634, Quality=degraded\n",
      "  Client 9: Size=4303, Weight=0.1371, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 22.73% accuracy, 2.2822 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8190\n",
      "     Epoch 2: Loss = 1.7472\n",
      "   ✅ Training complete. Final avg loss: 1.7831\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1218\n",
      "     Epoch 2: Loss = 2.0289\n",
      "   ✅ Training complete. Final avg loss: 2.0754\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8684\n",
      "     Epoch 2: Loss = 1.7279\n",
      "   ✅ Training complete. Final avg loss: 1.7982\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4239\n",
      "     Epoch 2: Loss = 1.2911\n",
      "   ✅ Training complete. Final avg loss: 1.3575\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9814\n",
      "     Epoch 2: Loss = 1.9288\n",
      "   ✅ Training complete. Final avg loss: 1.9551\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7336\n",
      "     Epoch 2: Loss = 1.6656\n",
      "   ✅ Training complete. Final avg loss: 1.6996\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2050\n",
      "     Epoch 2: Loss = 2.0705\n",
      "   ✅ Training complete. Final avg loss: 2.1377\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2477\n",
      "     Epoch 2: Loss = 1.1167\n",
      "   ✅ Training complete. Final avg loss: 1.1822\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1512\n",
      "     Epoch 2: Loss = 2.0139\n",
      "   ✅ Training complete. Final avg loss: 2.0826\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7800\n",
      "     Epoch 2: Loss = 1.6860\n",
      "   ✅ Training complete. Final avg loss: 1.7330\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1905, Weight=0.0648, Quality=degraded\n",
      "  Client 1: Size=2714, Weight=0.0924, Quality=byzantine\n",
      "  Client 2: Size=1753, Weight=0.0597, Quality=pristine\n",
      "  Client 3: Size=4072, Weight=0.1386, Quality=pristine\n",
      "  Client 4: Size=6352, Weight=0.2162, Quality=degraded\n",
      "  Client 5: Size=2868, Weight=0.0976, Quality=pristine\n",
      "  Client 6: Size=1877, Weight=0.0639, Quality=byzantine\n",
      "  Client 7: Size=3432, Weight=0.1168, Quality=pristine\n",
      "  Client 8: Size=2419, Weight=0.0823, Quality=byzantine\n",
      "  Client 9: Size=1990, Weight=0.0677, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 22.89% accuracy, 2.3513 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7103\n",
      "     Epoch 2: Loss = 1.6391\n",
      "   ✅ Training complete. Final avg loss: 1.6747\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9573\n",
      "     Epoch 2: Loss = 1.9193\n",
      "   ✅ Training complete. Final avg loss: 1.9383\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0559\n",
      "     Epoch 2: Loss = 1.9711\n",
      "   ✅ Training complete. Final avg loss: 2.0135\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4599\n",
      "     Epoch 2: Loss = 1.3648\n",
      "   ✅ Training complete. Final avg loss: 1.4123\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6902\n",
      "     Epoch 2: Loss = 1.5154\n",
      "   ✅ Training complete. Final avg loss: 1.6028\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.7051\n",
      "     Epoch 2: Loss = 1.5412\n",
      "   ✅ Training complete. Final avg loss: 1.6232\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8102\n",
      "     Epoch 2: Loss = 1.6940\n",
      "   ✅ Training complete. Final avg loss: 1.7521\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1202\n",
      "     Epoch 2: Loss = 1.9979\n",
      "   ✅ Training complete. Final avg loss: 2.0591\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6526\n",
      "     Epoch 2: Loss = 1.5697\n",
      "   ✅ Training complete. Final avg loss: 1.6111\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7519\n",
      "     Epoch 2: Loss = 1.6702\n",
      "   ✅ Training complete. Final avg loss: 1.7110\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2868, Weight=0.0790, Quality=pristine\n",
      "  Client 1: Size=6352, Weight=0.1750, Quality=degraded\n",
      "  Client 2: Size=4484, Weight=0.1235, Quality=byzantine\n",
      "  Client 3: Size=4303, Weight=0.1186, Quality=pristine\n",
      "  Client 4: Size=2211, Weight=0.0609, Quality=pristine\n",
      "  Client 5: Size=3686, Weight=0.1016, Quality=byzantine\n",
      "  Client 6: Size=1753, Weight=0.0483, Quality=pristine\n",
      "  Client 7: Size=2714, Weight=0.0748, Quality=byzantine\n",
      "  Client 8: Size=5934, Weight=0.1635, Quality=pristine\n",
      "  Client 9: Size=1990, Weight=0.0548, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 24.39% accuracy, 2.3532 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2332\n",
      "     Epoch 2: Loss = 2.0453\n",
      "   ✅ Training complete. Final avg loss: 2.1393\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6051\n",
      "     Epoch 2: Loss = 1.5542\n",
      "   ✅ Training complete. Final avg loss: 1.5796\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2377\n",
      "     Epoch 2: Loss = 2.0091\n",
      "   ✅ Training complete. Final avg loss: 2.1234\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4058\n",
      "     Epoch 2: Loss = 1.3409\n",
      "   ✅ Training complete. Final avg loss: 1.3734\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1058\n",
      "     Epoch 2: Loss = 1.9812\n",
      "   ✅ Training complete. Final avg loss: 2.0435\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2090\n",
      "     Epoch 2: Loss = 1.0645\n",
      "   ✅ Training complete. Final avg loss: 1.1367\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6575\n",
      "     Epoch 2: Loss = 1.5360\n",
      "   ✅ Training complete. Final avg loss: 1.5967\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9247\n",
      "     Epoch 2: Loss = 1.9069\n",
      "   ✅ Training complete. Final avg loss: 1.9158\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6053\n",
      "     Epoch 2: Loss = 1.4921\n",
      "   ✅ Training complete. Final avg loss: 1.5487\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7537\n",
      "     Epoch 2: Loss = 1.6607\n",
      "   ✅ Training complete. Final avg loss: 1.7072\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1877, Weight=0.0538, Quality=byzantine\n",
      "  Client 1: Size=5934, Weight=0.1699, Quality=pristine\n",
      "  Client 2: Size=2419, Weight=0.0693, Quality=byzantine\n",
      "  Client 3: Size=4303, Weight=0.1232, Quality=pristine\n",
      "  Client 4: Size=2714, Weight=0.0777, Quality=byzantine\n",
      "  Client 5: Size=3432, Weight=0.0983, Quality=pristine\n",
      "  Client 6: Size=3686, Weight=0.1056, Quality=byzantine\n",
      "  Client 7: Size=6352, Weight=0.1819, Quality=degraded\n",
      "  Client 8: Size=2211, Weight=0.0633, Quality=pristine\n",
      "  Client 9: Size=1990, Weight=0.0570, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 23.98% accuracy, 2.5011 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 23.98%\n",
      "   Best Accuracy: 24.39%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs BYZANTINE\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'byzantine':\n",
      "   Quality threshold: 0.400\n",
      "   Minimum clients ratio: 30.0%\n",
      "   Harm detection threshold: 0.100\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.9185\n",
      "     Epoch 2: Loss = 1.5612\n",
      "   ✅ Training complete. Final avg loss: 1.7398\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0935\n",
      "     Epoch 2: Loss = 1.8134\n",
      "   ✅ Training complete. Final avg loss: 1.9535\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1139\n",
      "     Epoch 2: Loss = 1.8021\n",
      "   ✅ Training complete. Final avg loss: 1.9580\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6632\n",
      "     Epoch 2: Loss = 1.3285\n",
      "   ✅ Training complete. Final avg loss: 1.4959\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1785\n",
      "     Epoch 2: Loss = 2.1199\n",
      "   ✅ Training complete. Final avg loss: 2.1492\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8983\n",
      "     Epoch 2: Loss = 1.7678\n",
      "   ✅ Training complete. Final avg loss: 1.8331\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7611\n",
      "     Epoch 2: Loss = 1.5565\n",
      "   ✅ Training complete. Final avg loss: 1.6588\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2715\n",
      "     Epoch 2: Loss = 2.1447\n",
      "   ✅ Training complete. Final avg loss: 2.2081\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6481\n",
      "     Epoch 2: Loss = 1.3728\n",
      "   ✅ Training complete. Final avg loss: 1.5105\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0635\n",
      "     Epoch 2: Loss = 1.8029\n",
      "   ✅ Training complete. Final avg loss: 1.9332\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.457, Loss=1.533, Loss_std=1.001, Entropy=1.533\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.617\n",
      "      Stability: 0.666, Confidence: 0.387\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.629\n",
      "   ✅ Decision: KEEP (Score 0.629 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.332, Loss=1.879, Loss_std=0.790, Entropy=1.947\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.530\n",
      "      Stability: 0.737, Confidence: 0.221\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.640\n",
      "   ✅ Decision: KEEP (Score 0.640 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.298, Loss=1.744, Loss_std=0.714, Entropy=1.848\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.994, Loss: 0.564\n",
      "      Stability: 0.762, Confidence: 0.261\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.712\n",
      "   ✅ Decision: KEEP (Score 0.712 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.526, Loss=1.424, Loss_std=1.345, Entropy=1.231\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.644\n",
      "      Stability: 0.552, Confidence: 0.508\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.224, Loss=2.085, Loss_std=0.552, Entropy=2.100\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.745, Loss: 0.479\n",
      "      Stability: 0.816, Confidence: 0.160\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.566\n",
      "   ✅ Decision: KEEP (Score 0.566 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.322, Loss=1.771, Loss_std=0.688, Entropy=1.861\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.771, Confidence: 0.255\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.713\n",
      "   ✅ Decision: KEEP (Score 0.713 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.452, Loss=1.634, Loss_std=1.074, Entropy=1.549\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.592\n",
      "      Stability: 0.642, Confidence: 0.380\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.714\n",
      "   ✅ Decision: KEEP (Score 0.714 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.212, Loss=2.074, Loss_std=0.516, Entropy=2.107\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.705, Loss: 0.481\n",
      "      Stability: 0.828, Confidence: 0.157\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.514\n",
      "   ✅ Decision: KEEP (Score 0.514 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.517, Loss=1.407, Loss_std=1.253, Entropy=1.273\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.648\n",
      "      Stability: 0.582, Confidence: 0.491\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.733\n",
      "   ✅ Decision: KEEP (Score 0.733 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.293, Loss=1.672, Loss_std=0.799, Entropy=1.713\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.978, Loss: 0.582\n",
      "      Stability: 0.734, Confidence: 0.315\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.733 |    4072 | KEEP     | Score 0.733 ≥ threshold 0.400\n",
      "      2 |      3 |  0.980 |     0.728 |    3432 | KEEP     | Score 0.728 ≥ threshold 0.400\n",
      "      3 |      9 |  0.980 |     0.715 |    2211 | KEEP     | Score 0.715 ≥ threshold 0.400\n",
      "      4 |      6 |  0.980 |     0.714 |    4303 | KEEP     | Score 0.714 ≥ threshold 0.400\n",
      "      5 |      5 |  0.980 |     0.713 |    5934 | KEEP     | Score 0.713 ≥ threshold 0.400\n",
      "      6 |      2 |  0.980 |     0.712 |    1753 | KEEP     | Score 0.712 ≥ threshold 0.400\n",
      "      7 |      1 |  0.450 |     0.640 |    1990 | KEEP     | Score 0.640 ≥ threshold 0.400\n",
      "      8 |      0 |  0.010 |     0.629 |    3686 | KEEP     | Score 0.629 ≥ threshold 0.400\n",
      "      9 |      4 |  0.450 |     0.566 |    6352 | KEEP     | Score 0.566 ≥ threshold 0.400\n",
      "     10 |      7 |  0.010 |     0.514 |    1877 | KEEP     | Score 0.514 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [8, 3, 9, 6, 5, 2, 1, 0, 4, 7])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.666\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 4072 |   0.733 |  0.114 |  0.126 |   0.125\n",
      "        3 | 3432 |   0.728 |  0.096 |  0.125 |   0.122\n",
      "        9 | 2211 |   0.715 |  0.062 |  0.119 |   0.113\n",
      "        6 | 4303 |   0.714 |  0.121 |  0.119 |   0.119\n",
      "        5 | 5934 |   0.713 |  0.167 |  0.118 |   0.123\n",
      "        2 | 1753 |   0.712 |  0.049 |  0.118 |   0.111\n",
      "        1 | 1990 |   0.640 |  0.056 |  0.089 |   0.086\n",
      "        0 | 3686 |   0.629 |  0.104 |  0.085 |   0.087\n",
      "        4 | 6352 |   0.566 |  0.178 |  0.060 |   0.072\n",
      "        7 | 1877 |   0.514 |  0.053 |  0.040 |   0.041\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 10.02% accuracy, 2.3277 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0883\n",
      "     Epoch 2: Loss = 2.0075\n",
      "   ✅ Training complete. Final avg loss: 2.0479\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0621\n",
      "     Epoch 2: Loss = 1.9750\n",
      "   ✅ Training complete. Final avg loss: 2.0185\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8728\n",
      "     Epoch 2: Loss = 1.7535\n",
      "   ✅ Training complete. Final avg loss: 1.8131\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1591\n",
      "     Epoch 2: Loss = 2.0541\n",
      "   ✅ Training complete. Final avg loss: 2.1066\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4661\n",
      "     Epoch 2: Loss = 1.2929\n",
      "   ✅ Training complete. Final avg loss: 1.3795\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9387\n",
      "     Epoch 2: Loss = 1.7758\n",
      "   ✅ Training complete. Final avg loss: 1.8572\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6538\n",
      "     Epoch 2: Loss = 1.5329\n",
      "   ✅ Training complete. Final avg loss: 1.5934\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6861\n",
      "     Epoch 2: Loss = 1.5600\n",
      "   ✅ Training complete. Final avg loss: 1.6230\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8338\n",
      "     Epoch 2: Loss = 1.7552\n",
      "   ✅ Training complete. Final avg loss: 1.7945\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1425\n",
      "     Epoch 2: Loss = 2.0898\n",
      "   ✅ Training complete. Final avg loss: 2.1162\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.322, Loss=1.925, Loss_std=0.683, Entropy=1.990\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.519\n",
      "      Stability: 0.772, Confidence: 0.204\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.598\n",
      "   ✅ Decision: KEEP (Score 0.598 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.226, Loss=1.930, Loss_std=0.556, Entropy=1.965\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.753, Loss: 0.518\n",
      "      Stability: 0.815, Confidence: 0.214\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.543\n",
      "   ✅ Decision: KEEP (Score 0.543 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.382, Loss=1.763, Loss_std=0.823, Entropy=1.800\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.559\n",
      "      Stability: 0.726, Confidence: 0.280\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.708\n",
      "   ✅ Decision: KEEP (Score 0.708 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.248, Loss=1.981, Loss_std=0.559, Entropy=2.024\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.825, Loss: 0.505\n",
      "      Stability: 0.814, Confidence: 0.190\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.555\n",
      "   ✅ Decision: KEEP (Score 0.555 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.565, Loss=1.226, Loss_std=1.329, Entropy=1.066\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.694\n",
      "      Stability: 0.557, Confidence: 0.574\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.753\n",
      "   ✅ Decision: KEEP (Score 0.753 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.392, Loss=1.736, Loss_std=0.982, Entropy=1.754\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.566\n",
      "      Stability: 0.673, Confidence: 0.298\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.461, Loss_std=0.991, Entropy=1.548\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.635\n",
      "      Stability: 0.670, Confidence: 0.381\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.730\n",
      "   ✅ Decision: KEEP (Score 0.730 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.438, Loss=1.603, Loss_std=1.092, Entropy=1.503\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.599\n",
      "      Stability: 0.636, Confidence: 0.399\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.621\n",
      "   ✅ Decision: KEEP (Score 0.621 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.332, Loss=1.724, Loss_std=0.852, Entropy=1.716\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.569\n",
      "      Stability: 0.716, Confidence: 0.314\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.714\n",
      "   ✅ Decision: KEEP (Score 0.714 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.228, Loss=2.089, Loss_std=0.577, Entropy=2.103\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.761, Loss: 0.478\n",
      "      Stability: 0.808, Confidence: 0.159\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.568\n",
      "   ✅ Decision: KEEP (Score 0.568 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.753 |    3432 | KEEP     | Score 0.753 ≥ threshold 0.400\n",
      "      2 |      6 |  0.980 |     0.730 |    4303 | KEEP     | Score 0.730 ≥ threshold 0.400\n",
      "      3 |      8 |  0.980 |     0.714 |    5934 | KEEP     | Score 0.714 ≥ threshold 0.400\n",
      "      4 |      2 |  0.980 |     0.708 |    2211 | KEEP     | Score 0.708 ≥ threshold 0.400\n",
      "      5 |      5 |  0.450 |     0.647 |    1990 | KEEP     | Score 0.647 ≥ threshold 0.400\n",
      "      6 |      7 |  0.010 |     0.621 |    3686 | KEEP     | Score 0.621 ≥ threshold 0.400\n",
      "      7 |      0 |  0.010 |     0.598 |    2419 | KEEP     | Score 0.598 ≥ threshold 0.400\n",
      "      8 |      9 |  0.450 |     0.568 |    6352 | KEEP     | Score 0.568 ≥ threshold 0.400\n",
      "      9 |      3 |  0.010 |     0.555 |    2714 | KEEP     | Score 0.555 ≥ threshold 0.400\n",
      "     10 |      1 |  0.010 |     0.543 |    4484 | KEEP     | Score 0.543 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 6, 8, 2, 5, 7, 0, 9, 3, 1])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.644\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 3432 |   0.753 |  0.091 |  0.154 |   0.148\n",
      "        6 | 4303 |   0.730 |  0.115 |  0.143 |   0.140\n",
      "        8 | 5934 |   0.714 |  0.158 |  0.135 |   0.137\n",
      "        2 | 2211 |   0.708 |  0.059 |  0.132 |   0.125\n",
      "        5 | 1990 |   0.647 |  0.053 |  0.102 |   0.097\n",
      "        7 | 3686 |   0.621 |  0.098 |  0.089 |   0.090\n",
      "        0 | 2419 |   0.598 |  0.064 |  0.077 |   0.076\n",
      "        9 | 6352 |   0.568 |  0.169 |  0.063 |   0.073\n",
      "        3 | 2714 |   0.555 |  0.072 |  0.056 |   0.057\n",
      "        1 | 4484 |   0.543 |  0.119 |  0.050 |   0.057\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.67% accuracy, 2.3576 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1554\n",
      "     Epoch 2: Loss = 2.0552\n",
      "   ✅ Training complete. Final avg loss: 2.1053\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9168\n",
      "     Epoch 2: Loss = 1.7499\n",
      "   ✅ Training complete. Final avg loss: 1.8333\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5120\n",
      "     Epoch 2: Loss = 1.3305\n",
      "   ✅ Training complete. Final avg loss: 1.4212\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5970\n",
      "     Epoch 2: Loss = 1.5190\n",
      "   ✅ Training complete. Final avg loss: 1.5580\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3867\n",
      "     Epoch 2: Loss = 1.2721\n",
      "   ✅ Training complete. Final avg loss: 1.3294\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6893\n",
      "     Epoch 2: Loss = 1.5681\n",
      "   ✅ Training complete. Final avg loss: 1.6287\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1100\n",
      "     Epoch 2: Loss = 2.0682\n",
      "   ✅ Training complete. Final avg loss: 2.0891\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8843\n",
      "     Epoch 2: Loss = 1.7489\n",
      "   ✅ Training complete. Final avg loss: 1.8166\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1048\n",
      "     Epoch 2: Loss = 2.0101\n",
      "   ✅ Training complete. Final avg loss: 2.0574\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9677\n",
      "     Epoch 2: Loss = 1.8055\n",
      "   ✅ Training complete. Final avg loss: 1.8866\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.240, Loss=2.067, Loss_std=0.614, Entropy=2.053\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.801, Loss: 0.483\n",
      "      Stability: 0.795, Confidence: 0.179\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.537\n",
      "   ✅ Decision: KEEP (Score 0.537 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.435, Loss=1.674, Loss_std=0.962, Entropy=1.786\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.581\n",
      "      Stability: 0.679, Confidence: 0.286\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.650\n",
      "   ✅ Decision: KEEP (Score 0.650 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.553, Loss=1.242, Loss_std=1.087, Entropy=1.246\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.689\n",
      "      Stability: 0.638, Confidence: 0.501\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.757\n",
      "   ✅ Decision: KEEP (Score 0.757 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.488, Loss=1.501, Loss_std=1.107, Entropy=1.448\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.625\n",
      "      Stability: 0.631, Confidence: 0.421\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.726\n",
      "   ✅ Decision: KEEP (Score 0.726 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.606, Loss=1.229, Loss_std=1.296, Entropy=1.146\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.693\n",
      "      Stability: 0.568, Confidence: 0.542\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.749\n",
      "   ✅ Decision: KEEP (Score 0.749 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.464, Loss=1.509, Loss_std=0.998, Entropy=1.488\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.623\n",
      "      Stability: 0.667, Confidence: 0.405\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.634\n",
      "   ✅ Decision: KEEP (Score 0.634 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.243, Loss=2.062, Loss_std=0.625, Entropy=2.058\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.809, Loss: 0.485\n",
      "      Stability: 0.792, Confidence: 0.177\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.583\n",
      "   ✅ Decision: KEEP (Score 0.583 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.413, Loss=1.714, Loss_std=1.008, Entropy=1.679\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.572\n",
      "      Stability: 0.664, Confidence: 0.328\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.705\n",
      "   ✅ Decision: KEEP (Score 0.705 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.257, Loss=2.035, Loss_std=0.690, Entropy=2.003\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.857, Loss: 0.491\n",
      "      Stability: 0.770, Confidence: 0.199\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.552\n",
      "   ✅ Decision: KEEP (Score 0.552 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.416, Loss=1.741, Loss_std=0.817, Entropy=1.903\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.565\n",
      "      Stability: 0.728, Confidence: 0.239\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      2 |  0.980 |     0.757 |    4072 | KEEP     | Score 0.757 ≥ threshold 0.400\n",
      "      2 |      4 |  0.980 |     0.749 |    3432 | KEEP     | Score 0.749 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.726 |    4303 | KEEP     | Score 0.726 ≥ threshold 0.400\n",
      "      4 |      7 |  0.980 |     0.705 |    2868 | KEEP     | Score 0.705 ≥ threshold 0.400\n",
      "      5 |      1 |  0.450 |     0.650 |    1990 | KEEP     | Score 0.650 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.649 |    1905 | KEEP     | Score 0.649 ≥ threshold 0.400\n",
      "      7 |      5 |  0.010 |     0.634 |    3686 | KEEP     | Score 0.634 ≥ threshold 0.400\n",
      "      8 |      6 |  0.450 |     0.583 |    6352 | KEEP     | Score 0.583 ≥ threshold 0.400\n",
      "      9 |      8 |  0.010 |     0.552 |    2419 | KEEP     | Score 0.552 ≥ threshold 0.400\n",
      "     10 |      0 |  0.010 |     0.537 |    2714 | KEEP     | Score 0.537 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [2, 4, 3, 7, 1, 9, 5, 6, 8, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.654\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        2 | 4072 |   0.757 |  0.121 |  0.147 |   0.145\n",
      "        4 | 3432 |   0.749 |  0.102 |  0.144 |   0.140\n",
      "        3 | 4303 |   0.726 |  0.128 |  0.133 |   0.133\n",
      "        7 | 2868 |   0.705 |  0.085 |  0.123 |   0.120\n",
      "        1 | 1990 |   0.650 |  0.059 |  0.098 |   0.094\n",
      "        9 | 1905 |   0.649 |  0.056 |  0.098 |   0.093\n",
      "        5 | 3686 |   0.634 |  0.109 |  0.091 |   0.093\n",
      "        6 | 6352 |   0.583 |  0.188 |  0.067 |   0.079\n",
      "        8 | 2419 |   0.552 |  0.072 |  0.053 |   0.055\n",
      "        0 | 2714 |   0.537 |  0.080 |  0.046 |   0.050\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.65% accuracy, 2.3813 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7816\n",
      "     Epoch 2: Loss = 1.7176\n",
      "   ✅ Training complete. Final avg loss: 1.7496\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1517\n",
      "     Epoch 2: Loss = 2.0261\n",
      "   ✅ Training complete. Final avg loss: 2.0889\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5698\n",
      "     Epoch 2: Loss = 1.5004\n",
      "   ✅ Training complete. Final avg loss: 1.5351\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8160\n",
      "     Epoch 2: Loss = 1.7234\n",
      "   ✅ Training complete. Final avg loss: 1.7697\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.7321\n",
      "     Epoch 2: Loss = 1.5672\n",
      "   ✅ Training complete. Final avg loss: 1.6496\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8208\n",
      "     Epoch 2: Loss = 1.7099\n",
      "   ✅ Training complete. Final avg loss: 1.7654\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8190\n",
      "     Epoch 2: Loss = 1.7210\n",
      "   ✅ Training complete. Final avg loss: 1.7700\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3543\n",
      "     Epoch 2: Loss = 1.2502\n",
      "   ✅ Training complete. Final avg loss: 1.3022\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0985\n",
      "     Epoch 2: Loss = 2.0620\n",
      "   ✅ Training complete. Final avg loss: 2.0802\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0610\n",
      "     Epoch 2: Loss = 1.9852\n",
      "   ✅ Training complete. Final avg loss: 2.0231\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.438, Loss=1.621, Loss_std=0.912, Entropy=1.694\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.595\n",
      "      Stability: 0.696, Confidence: 0.323\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.257, Loss=2.013, Loss_std=0.656, Entropy=2.010\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.857, Loss: 0.497\n",
      "      Stability: 0.781, Confidence: 0.196\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.555\n",
      "   ✅ Decision: KEEP (Score 0.555 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.531, Loss=1.474, Loss_std=1.082, Entropy=1.497\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.632\n",
      "      Stability: 0.639, Confidence: 0.401\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.726\n",
      "   ✅ Decision: KEEP (Score 0.726 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.329, Loss=1.666, Loss_std=0.704, Entropy=1.782\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.583\n",
      "      Stability: 0.765, Confidence: 0.287\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.723\n",
      "   ✅ Decision: KEEP (Score 0.723 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.440, Loss=1.650, Loss_std=1.144, Entropy=1.517\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.588\n",
      "      Stability: 0.619, Confidence: 0.393\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.613\n",
      "   ✅ Decision: KEEP (Score 0.613 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.329, Loss=1.766, Loss_std=1.021, Entropy=1.603\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.559\n",
      "      Stability: 0.660, Confidence: 0.359\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.471, Loss=1.678, Loss_std=1.010, Entropy=1.762\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.580\n",
      "      Stability: 0.663, Confidence: 0.295\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.648\n",
      "   ✅ Decision: KEEP (Score 0.648 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.577, Loss=1.306, Loss_std=1.293, Entropy=1.200\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.673\n",
      "      Stability: 0.569, Confidence: 0.520\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.741\n",
      "   ✅ Decision: KEEP (Score 0.741 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.260, Loss=2.054, Loss_std=0.626, Entropy=2.066\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.865, Loss: 0.486\n",
      "      Stability: 0.791, Confidence: 0.174\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.597\n",
      "   ✅ Decision: KEEP (Score 0.597 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.212, Loss=1.939, Loss_std=0.525, Entropy=1.986\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.705, Loss: 0.515\n",
      "      Stability: 0.825, Confidence: 0.206\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.530\n",
      "   ✅ Decision: KEEP (Score 0.530 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.741 |    3432 | KEEP     | Score 0.741 ≥ threshold 0.400\n",
      "      2 |      2 |  0.980 |     0.726 |    4303 | KEEP     | Score 0.726 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.723 |    5934 | KEEP     | Score 0.723 ≥ threshold 0.400\n",
      "      4 |      0 |  0.980 |     0.716 |    2868 | KEEP     | Score 0.716 ≥ threshold 0.400\n",
      "      5 |      5 |  0.980 |     0.707 |    2211 | KEEP     | Score 0.707 ≥ threshold 0.400\n",
      "      6 |      6 |  0.450 |     0.648 |    1990 | KEEP     | Score 0.648 ≥ threshold 0.400\n",
      "      7 |      4 |  0.010 |     0.613 |    3686 | KEEP     | Score 0.613 ≥ threshold 0.400\n",
      "      8 |      8 |  0.450 |     0.597 |    6352 | KEEP     | Score 0.597 ≥ threshold 0.400\n",
      "      9 |      1 |  0.010 |     0.555 |    2419 | KEEP     | Score 0.555 ≥ threshold 0.400\n",
      "     10 |      9 |  0.010 |     0.530 |    4484 | KEEP     | Score 0.530 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 2, 3, 0, 5, 6, 4, 8, 1, 9])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.656\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 3432 |   0.741 |  0.091 |  0.138 |   0.133\n",
      "        2 | 4303 |   0.726 |  0.114 |  0.131 |   0.129\n",
      "        3 | 5934 |   0.723 |  0.157 |  0.130 |   0.133\n",
      "        0 | 2868 |   0.716 |  0.076 |  0.127 |   0.122\n",
      "        5 | 2211 |   0.707 |  0.059 |  0.123 |   0.116\n",
      "        6 | 1990 |   0.648 |  0.053 |  0.097 |   0.092\n",
      "        4 | 3686 |   0.613 |  0.098 |  0.081 |   0.083\n",
      "        8 | 6352 |   0.597 |  0.169 |  0.074 |   0.084\n",
      "        1 | 2419 |   0.555 |  0.064 |  0.056 |   0.056\n",
      "        9 | 4484 |   0.530 |  0.119 |  0.044 |   0.052\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 21.36% accuracy, 2.3287 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9098\n",
      "     Epoch 2: Loss = 1.7663\n",
      "   ✅ Training complete. Final avg loss: 1.8381\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1346\n",
      "     Epoch 2: Loss = 2.0103\n",
      "   ✅ Training complete. Final avg loss: 2.0724\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3146\n",
      "     Epoch 2: Loss = 1.2257\n",
      "   ✅ Training complete. Final avg loss: 1.2701\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0673\n",
      "     Epoch 2: Loss = 1.9869\n",
      "   ✅ Training complete. Final avg loss: 2.0271\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7901\n",
      "     Epoch 2: Loss = 1.7149\n",
      "   ✅ Training complete. Final avg loss: 1.7525\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9058\n",
      "     Epoch 2: Loss = 1.7681\n",
      "   ✅ Training complete. Final avg loss: 1.8370\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0730\n",
      "     Epoch 2: Loss = 2.0309\n",
      "   ✅ Training complete. Final avg loss: 2.0519\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1984\n",
      "     Epoch 2: Loss = 2.0854\n",
      "   ✅ Training complete. Final avg loss: 2.1419\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8115\n",
      "     Epoch 2: Loss = 1.7192\n",
      "   ✅ Training complete. Final avg loss: 1.7653\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5434\n",
      "     Epoch 2: Loss = 1.4763\n",
      "   ✅ Training complete. Final avg loss: 1.5099\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.341, Loss=1.748, Loss_std=0.879, Entropy=1.732\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.563\n",
      "      Stability: 0.707, Confidence: 0.307\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.709\n",
      "   ✅ Decision: KEEP (Score 0.709 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.317, Loss=1.945, Loss_std=0.636, Entropy=2.007\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.514\n",
      "      Stability: 0.788, Confidence: 0.197\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.599\n",
      "   ✅ Decision: KEEP (Score 0.599 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.562, Loss=1.292, Loss_std=1.173, Entropy=1.252\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.677\n",
      "      Stability: 0.609, Confidence: 0.499\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.747\n",
      "   ✅ Decision: KEEP (Score 0.747 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.236, Loss=1.954, Loss_std=0.608, Entropy=1.966\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.785, Loss: 0.511\n",
      "      Stability: 0.797, Confidence: 0.214\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.546\n",
      "   ✅ Decision: KEEP (Score 0.546 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.421, Loss=1.698, Loss_std=0.933, Entropy=1.738\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.576\n",
      "      Stability: 0.689, Confidence: 0.305\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.428, Loss=1.773, Loss_std=1.022, Entropy=1.774\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.659, Confidence: 0.291\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.641\n",
      "   ✅ Decision: KEEP (Score 0.641 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.255, Loss=2.008, Loss_std=0.622, Entropy=2.066\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.849, Loss: 0.498\n",
      "      Stability: 0.793, Confidence: 0.174\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.596\n",
      "   ✅ Decision: KEEP (Score 0.596 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.238, Loss=2.057, Loss_std=0.570, Entropy=2.084\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.793, Loss: 0.486\n",
      "      Stability: 0.810, Confidence: 0.167\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.537\n",
      "   ✅ Decision: KEEP (Score 0.537 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.433, Loss=1.715, Loss_std=0.961, Entropy=1.792\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.571\n",
      "      Stability: 0.680, Confidence: 0.283\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.536, Loss=1.440, Loss_std=0.876, Entropy=1.599\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.640\n",
      "      Stability: 0.708, Confidence: 0.360\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.736\n",
      "   ✅ Decision: KEEP (Score 0.736 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      2 |  0.980 |     0.747 |    3432 | KEEP     | Score 0.747 ≥ threshold 0.400\n",
      "      2 |      9 |  0.980 |     0.736 |    4303 | KEEP     | Score 0.736 ≥ threshold 0.400\n",
      "      3 |      0 |  0.980 |     0.709 |    1753 | KEEP     | Score 0.709 ≥ threshold 0.400\n",
      "      4 |      4 |  0.980 |     0.707 |    2868 | KEEP     | Score 0.707 ≥ threshold 0.400\n",
      "      5 |      8 |  0.450 |     0.647 |    1990 | KEEP     | Score 0.647 ≥ threshold 0.400\n",
      "      6 |      5 |  0.450 |     0.641 |    1905 | KEEP     | Score 0.641 ≥ threshold 0.400\n",
      "      7 |      1 |  0.010 |     0.599 |    2419 | KEEP     | Score 0.599 ≥ threshold 0.400\n",
      "      8 |      6 |  0.450 |     0.596 |    6352 | KEEP     | Score 0.596 ≥ threshold 0.400\n",
      "      9 |      3 |  0.010 |     0.546 |    4484 | KEEP     | Score 0.546 ≥ threshold 0.400\n",
      "     10 |      7 |  0.010 |     0.537 |    1877 | KEEP     | Score 0.537 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [2, 9, 0, 4, 8, 5, 1, 6, 3, 7])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.647\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        2 | 3432 |   0.747 |  0.109 |  0.148 |   0.144\n",
      "        9 | 4303 |   0.736 |  0.137 |  0.143 |   0.142\n",
      "        0 | 1753 |   0.709 |  0.056 |  0.130 |   0.122\n",
      "        4 | 2868 |   0.707 |  0.091 |  0.129 |   0.125\n",
      "        8 | 1990 |   0.647 |  0.063 |  0.100 |   0.097\n",
      "        5 | 1905 |   0.641 |  0.061 |  0.097 |   0.094\n",
      "        1 | 2419 |   0.599 |  0.077 |  0.077 |   0.077\n",
      "        6 | 6352 |   0.596 |  0.202 |  0.076 |   0.089\n",
      "        3 | 4484 |   0.546 |  0.143 |  0.052 |   0.061\n",
      "        7 | 1877 |   0.537 |  0.060 |  0.048 |   0.049\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 19.30% accuracy, 2.3356 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8230\n",
      "     Epoch 2: Loss = 1.7753\n",
      "   ✅ Training complete. Final avg loss: 1.7992\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1483\n",
      "     Epoch 2: Loss = 2.0486\n",
      "   ✅ Training complete. Final avg loss: 2.0985\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8582\n",
      "     Epoch 2: Loss = 1.7674\n",
      "   ✅ Training complete. Final avg loss: 1.8128\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3818\n",
      "     Epoch 2: Loss = 1.3098\n",
      "   ✅ Training complete. Final avg loss: 1.3458\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0536\n",
      "     Epoch 2: Loss = 1.9840\n",
      "   ✅ Training complete. Final avg loss: 2.0188\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7542\n",
      "     Epoch 2: Loss = 1.6996\n",
      "   ✅ Training complete. Final avg loss: 1.7269\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2034\n",
      "     Epoch 2: Loss = 2.0790\n",
      "   ✅ Training complete. Final avg loss: 2.1412\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3197\n",
      "     Epoch 2: Loss = 1.1973\n",
      "   ✅ Training complete. Final avg loss: 1.2585\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1302\n",
      "     Epoch 2: Loss = 2.0068\n",
      "   ✅ Training complete. Final avg loss: 2.0685\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7920\n",
      "     Epoch 2: Loss = 1.7014\n",
      "   ✅ Training complete. Final avg loss: 1.7467\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.471, Loss=1.679, Loss_std=1.028, Entropy=1.730\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.580\n",
      "      Stability: 0.657, Confidence: 0.308\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.192, Loss=2.052, Loss_std=0.507, Entropy=2.068\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.641, Loss: 0.487\n",
      "      Stability: 0.831, Confidence: 0.173\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.502\n",
      "   ✅ Decision: KEEP (Score 0.502 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.317, Loss=1.753, Loss_std=0.870, Entropy=1.766\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.562\n",
      "      Stability: 0.710, Confidence: 0.293\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.478, Loss=1.340, Loss_std=1.188, Entropy=1.222\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.665\n",
      "      Stability: 0.604, Confidence: 0.511\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.746\n",
      "   ✅ Decision: KEEP (Score 0.746 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.329, Loss=1.907, Loss_std=0.680, Entropy=2.010\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.523\n",
      "      Stability: 0.773, Confidence: 0.196\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.642\n",
      "   ✅ Decision: KEEP (Score 0.642 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.404, Loss=1.728, Loss_std=0.961, Entropy=1.727\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.568\n",
      "      Stability: 0.680, Confidence: 0.309\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.195, Loss=2.115, Loss_std=0.571, Entropy=2.102\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.649, Loss: 0.471\n",
      "      Stability: 0.810, Confidence: 0.159\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.493\n",
      "   ✅ Decision: KEEP (Score 0.493 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.625, Loss=1.229, Loss_std=1.225, Entropy=1.237\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.693\n",
      "      Stability: 0.592, Confidence: 0.505\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.748\n",
      "   ✅ Decision: KEEP (Score 0.748 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.291, Loss=1.970, Loss_std=0.705, Entropy=1.969\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.970, Loss: 0.507\n",
      "      Stability: 0.765, Confidence: 0.212\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.587\n",
      "   ✅ Decision: KEEP (Score 0.587 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.435, Loss=1.708, Loss_std=1.048, Entropy=1.713\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.573\n",
      "      Stability: 0.651, Confidence: 0.315\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.748 |    3432 | KEEP     | Score 0.748 ≥ threshold 0.400\n",
      "      2 |      3 |  0.980 |     0.746 |    4072 | KEEP     | Score 0.746 ≥ threshold 0.400\n",
      "      3 |      2 |  0.980 |     0.707 |    1753 | KEEP     | Score 0.707 ≥ threshold 0.400\n",
      "      4 |      5 |  0.980 |     0.704 |    2868 | KEEP     | Score 0.704 ≥ threshold 0.400\n",
      "      5 |      0 |  0.450 |     0.649 |    1905 | KEEP     | Score 0.649 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.647 |    1990 | KEEP     | Score 0.647 ≥ threshold 0.400\n",
      "      7 |      4 |  0.450 |     0.642 |    6352 | KEEP     | Score 0.642 ≥ threshold 0.400\n",
      "      8 |      8 |  0.010 |     0.587 |    2419 | KEEP     | Score 0.587 ≥ threshold 0.400\n",
      "      9 |      1 |  0.010 |     0.502 |    2714 | KEEP     | Score 0.502 ≥ threshold 0.400\n",
      "     10 |      6 |  0.010 |     0.493 |    1877 | KEEP     | Score 0.493 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 3, 2, 5, 0, 9, 4, 8, 1, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.642\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 3432 |   0.748 |  0.117 |  0.142 |   0.140\n",
      "        3 | 4072 |   0.746 |  0.139 |  0.141 |   0.141\n",
      "        2 | 1753 |   0.707 |  0.060 |  0.126 |   0.119\n",
      "        5 | 2868 |   0.704 |  0.098 |  0.125 |   0.122\n",
      "        0 | 1905 |   0.649 |  0.065 |  0.103 |   0.099\n",
      "        9 | 1990 |   0.647 |  0.068 |  0.102 |   0.098\n",
      "        4 | 6352 |   0.642 |  0.216 |  0.100 |   0.111\n",
      "        8 | 2419 |   0.587 |  0.082 |  0.078 |   0.078\n",
      "        1 | 2714 |   0.502 |  0.092 |  0.044 |   0.048\n",
      "        6 | 1877 |   0.493 |  0.064 |  0.040 |   0.042\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 18.70% accuracy, 2.5202 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7337\n",
      "     Epoch 2: Loss = 1.6738\n",
      "   ✅ Training complete. Final avg loss: 1.7037\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0329\n",
      "     Epoch 2: Loss = 1.9532\n",
      "   ✅ Training complete. Final avg loss: 1.9930\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0751\n",
      "     Epoch 2: Loss = 1.9844\n",
      "   ✅ Training complete. Final avg loss: 2.0298\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5335\n",
      "     Epoch 2: Loss = 1.4066\n",
      "   ✅ Training complete. Final avg loss: 1.4701\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7265\n",
      "     Epoch 2: Loss = 1.6168\n",
      "   ✅ Training complete. Final avg loss: 1.6716\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.7092\n",
      "     Epoch 2: Loss = 1.5620\n",
      "   ✅ Training complete. Final avg loss: 1.6356\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8268\n",
      "     Epoch 2: Loss = 1.7466\n",
      "   ✅ Training complete. Final avg loss: 1.7867\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1578\n",
      "     Epoch 2: Loss = 2.0395\n",
      "   ✅ Training complete. Final avg loss: 2.0986\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7434\n",
      "     Epoch 2: Loss = 1.5975\n",
      "   ✅ Training complete. Final avg loss: 1.6705\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7644\n",
      "     Epoch 2: Loss = 1.6962\n",
      "   ✅ Training complete. Final avg loss: 1.7303\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.625, Loss_std=0.723, Entropy=1.815\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.594\n",
      "      Stability: 0.759, Confidence: 0.274\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.325, Loss=1.976, Loss_std=0.728, Entropy=1.992\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.506\n",
      "      Stability: 0.757, Confidence: 0.203\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.636\n",
      "   ✅ Decision: KEEP (Score 0.636 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.200, Loss=1.977, Loss_std=0.557, Entropy=2.012\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.665, Loss: 0.506\n",
      "      Stability: 0.814, Confidence: 0.195\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.513\n",
      "   ✅ Decision: KEEP (Score 0.513 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.560, Loss=1.345, Loss_std=1.116, Entropy=1.372\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.664\n",
      "      Stability: 0.628, Confidence: 0.451\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.740\n",
      "   ✅ Decision: KEEP (Score 0.740 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.514, Loss=1.547, Loss_std=1.001, Entropy=1.605\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.613\n",
      "      Stability: 0.666, Confidence: 0.358\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.720\n",
      "   ✅ Decision: KEEP (Score 0.720 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.483, Loss=1.507, Loss_std=1.011, Entropy=1.506\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.623\n",
      "      Stability: 0.663, Confidence: 0.398\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.632\n",
      "   ✅ Decision: KEEP (Score 0.632 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.308, Loss=1.734, Loss_std=0.845, Entropy=1.753\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.567\n",
      "      Stability: 0.718, Confidence: 0.299\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.711\n",
      "   ✅ Decision: KEEP (Score 0.711 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.216, Loss=2.004, Loss_std=0.478, Entropy=2.077\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.721, Loss: 0.499\n",
      "      Stability: 0.841, Confidence: 0.169\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.528\n",
      "   ✅ Decision: KEEP (Score 0.528 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.406, Loss=1.604, Loss_std=0.906, Entropy=1.602\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.599\n",
      "      Stability: 0.698, Confidence: 0.359\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.725\n",
      "   ✅ Decision: KEEP (Score 0.725 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.680, Loss_std=1.006, Entropy=1.754\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.580\n",
      "      Stability: 0.665, Confidence: 0.298\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.740 |    4303 | KEEP     | Score 0.740 ≥ threshold 0.400\n",
      "      2 |      8 |  0.980 |     0.725 |    5934 | KEEP     | Score 0.725 ≥ threshold 0.400\n",
      "      3 |      0 |  0.980 |     0.722 |    2868 | KEEP     | Score 0.722 ≥ threshold 0.400\n",
      "      4 |      4 |  0.980 |     0.720 |    2211 | KEEP     | Score 0.720 ≥ threshold 0.400\n",
      "      5 |      6 |  0.980 |     0.711 |    1753 | KEEP     | Score 0.711 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.649 |    1990 | KEEP     | Score 0.649 ≥ threshold 0.400\n",
      "      7 |      1 |  0.450 |     0.636 |    6352 | KEEP     | Score 0.636 ≥ threshold 0.400\n",
      "      8 |      5 |  0.010 |     0.632 |    3686 | KEEP     | Score 0.632 ≥ threshold 0.400\n",
      "      9 |      7 |  0.010 |     0.528 |    2714 | KEEP     | Score 0.528 ≥ threshold 0.400\n",
      "     10 |      2 |  0.010 |     0.513 |    4484 | KEEP     | Score 0.513 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [3, 8, 0, 4, 6, 9, 1, 5, 7, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.657\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 4303 |   0.740 |  0.119 |  0.134 |   0.132\n",
      "        8 | 5934 |   0.725 |  0.163 |  0.127 |   0.131\n",
      "        0 | 2868 |   0.722 |  0.079 |  0.126 |   0.122\n",
      "        4 | 2211 |   0.720 |  0.061 |  0.126 |   0.119\n",
      "        6 | 1753 |   0.711 |  0.048 |  0.122 |   0.114\n",
      "        9 | 1990 |   0.649 |  0.055 |  0.096 |   0.092\n",
      "        1 | 6352 |   0.636 |  0.175 |  0.091 |   0.100\n",
      "        5 | 3686 |   0.632 |  0.102 |  0.090 |   0.091\n",
      "        7 | 2714 |   0.528 |  0.075 |  0.047 |   0.050\n",
      "        2 | 4484 |   0.513 |  0.124 |  0.041 |   0.049\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 23.43% accuracy, 2.2732 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1995\n",
      "     Epoch 2: Loss = 2.0641\n",
      "   ✅ Training complete. Final avg loss: 2.1318\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6469\n",
      "     Epoch 2: Loss = 1.5697\n",
      "   ✅ Training complete. Final avg loss: 1.6083\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1625\n",
      "     Epoch 2: Loss = 2.0132\n",
      "   ✅ Training complete. Final avg loss: 2.0879\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4590\n",
      "     Epoch 2: Loss = 1.3658\n",
      "   ✅ Training complete. Final avg loss: 1.4124\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1507\n",
      "     Epoch 2: Loss = 2.0209\n",
      "   ✅ Training complete. Final avg loss: 2.0858\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2603\n",
      "     Epoch 2: Loss = 1.1171\n",
      "   ✅ Training complete. Final avg loss: 1.1887\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6549\n",
      "     Epoch 2: Loss = 1.5450\n",
      "   ✅ Training complete. Final avg loss: 1.6000\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9676\n",
      "     Epoch 2: Loss = 1.9276\n",
      "   ✅ Training complete. Final avg loss: 1.9476\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6528\n",
      "     Epoch 2: Loss = 1.5615\n",
      "   ✅ Training complete. Final avg loss: 1.6072\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7595\n",
      "     Epoch 2: Loss = 1.6860\n",
      "   ✅ Training complete. Final avg loss: 1.7228\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.224, Loss=2.039, Loss_std=0.540, Entropy=2.102\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.745, Loss: 0.490\n",
      "      Stability: 0.820, Confidence: 0.159\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.526\n",
      "   ✅ Decision: KEEP (Score 0.526 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.459, Loss=1.480, Loss_std=0.891, Entropy=1.522\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.630\n",
      "      Stability: 0.703, Confidence: 0.391\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.303, Loss=1.995, Loss_std=0.686, Entropy=2.010\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.501\n",
      "      Stability: 0.771, Confidence: 0.196\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.593\n",
      "   ✅ Decision: KEEP (Score 0.593 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.558, Loss=1.311, Loss_std=1.151, Entropy=1.271\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.672\n",
      "      Stability: 0.616, Confidence: 0.492\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.746\n",
      "   ✅ Decision: KEEP (Score 0.746 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.190, Loss=1.977, Loss_std=0.420, Entropy=2.068\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.633, Loss: 0.506\n",
      "      Stability: 0.860, Confidence: 0.173\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.510\n",
      "   ✅ Decision: KEEP (Score 0.510 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.695, Loss=1.030, Loss_std=1.179, Entropy=1.085\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.742\n",
      "      Stability: 0.607, Confidence: 0.566\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.774\n",
      "   ✅ Decision: KEEP (Score 0.774 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.466, Loss_std=0.995, Entropy=1.517\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.634\n",
      "      Stability: 0.668, Confidence: 0.393\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.635\n",
      "   ✅ Decision: KEEP (Score 0.635 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.281, Loss=1.958, Loss_std=0.799, Entropy=1.942\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.938, Loss: 0.510\n",
      "      Stability: 0.734, Confidence: 0.223\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.618\n",
      "   ✅ Decision: KEEP (Score 0.618 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.411, Loss=1.536, Loss_std=0.973, Entropy=1.535\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.616\n",
      "      Stability: 0.676, Confidence: 0.386\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.464, Loss=1.606, Loss_std=1.091, Entropy=1.636\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.599\n",
      "      Stability: 0.636, Confidence: 0.346\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.655\n",
      "   ✅ Decision: KEEP (Score 0.655 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      5 |  0.980 |     0.774 |    3432 | KEEP     | Score 0.774 ≥ threshold 0.400\n",
      "      2 |      3 |  0.980 |     0.746 |    4303 | KEEP     | Score 0.746 ≥ threshold 0.400\n",
      "      3 |      1 |  0.980 |     0.738 |    5934 | KEEP     | Score 0.738 ≥ threshold 0.400\n",
      "      4 |      8 |  0.980 |     0.728 |    2211 | KEEP     | Score 0.728 ≥ threshold 0.400\n",
      "      5 |      9 |  0.450 |     0.655 |    1990 | KEEP     | Score 0.655 ≥ threshold 0.400\n",
      "      6 |      6 |  0.010 |     0.635 |    3686 | KEEP     | Score 0.635 ≥ threshold 0.400\n",
      "      7 |      7 |  0.450 |     0.618 |    6352 | KEEP     | Score 0.618 ≥ threshold 0.400\n",
      "      8 |      2 |  0.010 |     0.593 |    2419 | KEEP     | Score 0.593 ≥ threshold 0.400\n",
      "      9 |      0 |  0.010 |     0.526 |    1877 | KEEP     | Score 0.526 ≥ threshold 0.400\n",
      "     10 |      4 |  0.010 |     0.510 |    2714 | KEEP     | Score 0.510 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [5, 3, 1, 8, 9, 6, 7, 2, 0, 4])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.652\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        5 | 3432 |   0.774 |  0.098 |  0.150 |   0.145\n",
      "        3 | 4303 |   0.746 |  0.123 |  0.139 |   0.137\n",
      "        1 | 5934 |   0.738 |  0.170 |  0.136 |   0.139\n",
      "        8 | 2211 |   0.728 |  0.063 |  0.131 |   0.125\n",
      "        9 | 1990 |   0.655 |  0.057 |  0.101 |   0.097\n",
      "        6 | 3686 |   0.635 |  0.106 |  0.093 |   0.094\n",
      "        7 | 6352 |   0.618 |  0.182 |  0.086 |   0.096\n",
      "        2 | 2419 |   0.593 |  0.069 |  0.075 |   0.075\n",
      "        0 | 1877 |   0.526 |  0.054 |  0.048 |   0.048\n",
      "        4 | 2714 |   0.510 |  0.078 |  0.041 |   0.045\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 24.09% accuracy, 2.4094 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 24.09%\n",
      "   Best Accuracy: 24.09%\n",
      "   avg_filter_rate: 0.000\n",
      "   max_filter_rate: 0.000\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 4/8\n",
      "   Learning Rate: 0.005\n",
      "   Extreme Type: resource\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'resource':\n",
      "   30% rich (5K+ samples), 40% poor (200 samples), 30% broken (50 bad samples)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_resource_lr0.005_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  POOR: 6 clients\n",
      "  BROKEN: 5 clients\n",
      "  RICH: 4 clients\n",
      "   💀 Client 0 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 1 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 2 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 3 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 4 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 5 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 6 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 7 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 8 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 9 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 10 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 11 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 12 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 13 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 14 (poor): DEFAULT: Pristine data\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.080 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   RICH: 4 clients (avg score: 0.980)\n",
      "   BROKEN: 5 clients (avg score: 0.080)\n",
      "   POOR: 6 clients (avg score: 0.980)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs RESOURCE\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2980\n",
      "     Epoch 2: Loss = 2.2712\n",
      "   ✅ Training complete. Final avg loss: 2.2846\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0507\n",
      "     Epoch 2: Loss = 1.7390\n",
      "   ✅ Training complete. Final avg loss: 1.8949\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1087\n",
      "     Epoch 2: Loss = 1.8117\n",
      "   ✅ Training complete. Final avg loss: 1.9602\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2861\n",
      "     Epoch 2: Loss = 2.2887\n",
      "   ✅ Training complete. Final avg loss: 2.2874\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3177\n",
      "     Epoch 2: Loss = 2.2761\n",
      "   ✅ Training complete. Final avg loss: 2.2969\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3078\n",
      "     Epoch 2: Loss = 2.3077\n",
      "   ✅ Training complete. Final avg loss: 2.3078\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3113\n",
      "     Epoch 2: Loss = 2.3091\n",
      "   ✅ Training complete. Final avg loss: 2.3102\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8065\n",
      "     Epoch 2: Loss = 1.6834\n",
      "   ✅ Training complete. Final avg loss: 1.7449\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3154\n",
      "     Epoch 2: Loss = 2.2824\n",
      "   ✅ Training complete. Final avg loss: 2.2989\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3219\n",
      "     Epoch 2: Loss = 2.2784\n",
      "   ✅ Training complete. Final avg loss: 2.3001\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 200, Weight=0.0168, Quality=poor\n",
      "  Client 1: Size=2013, Weight=0.1696, Quality=rich\n",
      "  Client 2: Size=1951, Weight=0.1644, Quality=rich\n",
      "  Client 3: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 4: Size= 200, Weight=0.0168, Quality=poor\n",
      "  Client 5: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 6: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 7: Size=6957, Weight=0.5861, Quality=rich\n",
      "  Client 8: Size= 200, Weight=0.0168, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0168, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 11.49% accuracy, 2.6693 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6852\n",
      "     Epoch 2: Loss = 1.6457\n",
      "   ✅ Training complete. Final avg loss: 1.6655\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9625\n",
      "     Epoch 2: Loss = 1.8103\n",
      "   ✅ Training complete. Final avg loss: 1.8864\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6734\n",
      "     Epoch 2: Loss = 2.5668\n",
      "   ✅ Training complete. Final avg loss: 2.6201\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4101\n",
      "     Epoch 2: Loss = 2.3242\n",
      "   ✅ Training complete. Final avg loss: 2.3671\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4653\n",
      "     Epoch 2: Loss = 2.4953\n",
      "   ✅ Training complete. Final avg loss: 2.4803\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 3.1371\n",
      "     Epoch 2: Loss = 2.7276\n",
      "   ✅ Training complete. Final avg loss: 2.9324\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8833\n",
      "     Epoch 2: Loss = 1.7092\n",
      "   ✅ Training complete. Final avg loss: 1.7963\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4969\n",
      "     Epoch 2: Loss = 2.5443\n",
      "   ✅ Training complete. Final avg loss: 2.5206\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3885\n",
      "     Epoch 2: Loss = 2.1734\n",
      "   ✅ Training complete. Final avg loss: 2.2809\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8774\n",
      "     Epoch 2: Loss = 2.8784\n",
      "   ✅ Training complete. Final avg loss: 2.8779\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=6957, Weight=0.5936, Quality=rich\n",
      "  Client 1: Size=1951, Weight=0.1665, Quality=rich\n",
      "  Client 2: Size=  50, Weight=0.0043, Quality=broken\n",
      "  Client 3: Size= 200, Weight=0.0171, Quality=poor\n",
      "  Client 4: Size=  50, Weight=0.0043, Quality=broken\n",
      "  Client 5: Size= 200, Weight=0.0171, Quality=poor\n",
      "  Client 6: Size=2013, Weight=0.1717, Quality=rich\n",
      "  Client 7: Size=  50, Weight=0.0043, Quality=broken\n",
      "  Client 8: Size= 200, Weight=0.0171, Quality=poor\n",
      "  Client 9: Size=  50, Weight=0.0043, Quality=broken\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 13.02% accuracy, 2.9309 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8470\n",
      "     Epoch 2: Loss = 1.5431\n",
      "   ✅ Training complete. Final avg loss: 1.6950\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8957\n",
      "     Epoch 2: Loss = 1.7844\n",
      "   ✅ Training complete. Final avg loss: 1.8401\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8115\n",
      "     Epoch 2: Loss = 1.6743\n",
      "   ✅ Training complete. Final avg loss: 1.7429\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.5653\n",
      "     Epoch 2: Loss = 2.2661\n",
      "   ✅ Training complete. Final avg loss: 2.4157\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8580\n",
      "     Epoch 2: Loss = 2.8322\n",
      "   ✅ Training complete. Final avg loss: 2.8451\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6466\n",
      "     Epoch 2: Loss = 1.6172\n",
      "   ✅ Training complete. Final avg loss: 1.6319\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8644\n",
      "     Epoch 2: Loss = 2.7145\n",
      "   ✅ Training complete. Final avg loss: 2.7894\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7798\n",
      "     Epoch 2: Loss = 2.6780\n",
      "   ✅ Training complete. Final avg loss: 2.7289\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3816\n",
      "     Epoch 2: Loss = 2.1646\n",
      "   ✅ Training complete. Final avg loss: 2.2731\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1391\n",
      "     Epoch 2: Loss = 1.9932\n",
      "   ✅ Training complete. Final avg loss: 2.0661\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4764, Weight=0.2899, Quality=rich\n",
      "  Client 1: Size=1951, Weight=0.1187, Quality=rich\n",
      "  Client 2: Size=2013, Weight=0.1225, Quality=rich\n",
      "  Client 3: Size= 200, Weight=0.0122, Quality=poor\n",
      "  Client 4: Size=  50, Weight=0.0030, Quality=broken\n",
      "  Client 5: Size=6957, Weight=0.4233, Quality=rich\n",
      "  Client 6: Size=  50, Weight=0.0030, Quality=broken\n",
      "  Client 7: Size=  50, Weight=0.0030, Quality=broken\n",
      "  Client 8: Size= 200, Weight=0.0122, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0122, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 13.88% accuracy, 2.5165 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8036\n",
      "     Epoch 2: Loss = 1.6506\n",
      "   ✅ Training complete. Final avg loss: 1.7271\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7475\n",
      "     Epoch 2: Loss = 2.6009\n",
      "   ✅ Training complete. Final avg loss: 2.6742\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4146\n",
      "     Epoch 2: Loss = 2.0692\n",
      "   ✅ Training complete. Final avg loss: 2.2419\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1227\n",
      "     Epoch 2: Loss = 1.9298\n",
      "   ✅ Training complete. Final avg loss: 2.0263\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8493\n",
      "     Epoch 2: Loss = 2.6175\n",
      "   ✅ Training complete. Final avg loss: 2.7334\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4116\n",
      "     Epoch 2: Loss = 2.4035\n",
      "   ✅ Training complete. Final avg loss: 2.4075\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2914\n",
      "     Epoch 2: Loss = 2.3531\n",
      "   ✅ Training complete. Final avg loss: 2.3223\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6323\n",
      "     Epoch 2: Loss = 1.5889\n",
      "   ✅ Training complete. Final avg loss: 1.6106\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2597\n",
      "     Epoch 2: Loss = 2.1062\n",
      "   ✅ Training complete. Final avg loss: 2.1830\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3028\n",
      "     Epoch 2: Loss = 1.9386\n",
      "   ✅ Training complete. Final avg loss: 2.1207\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2013, Weight=0.2019, Quality=rich\n",
      "  Client 1: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 2: Size= 200, Weight=0.0201, Quality=poor\n",
      "  Client 3: Size= 200, Weight=0.0201, Quality=poor\n",
      "  Client 4: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 5: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 6: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 7: Size=6957, Weight=0.6978, Quality=rich\n",
      "  Client 8: Size= 200, Weight=0.0201, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0201, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.71% accuracy, 3.2575 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 3.5023\n",
      "     Epoch 2: Loss = 2.5389\n",
      "   ✅ Training complete. Final avg loss: 3.0206\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8135\n",
      "     Epoch 2: Loss = 1.6352\n",
      "   ✅ Training complete. Final avg loss: 1.7244\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.6179\n",
      "     Epoch 2: Loss = 2.2980\n",
      "   ✅ Training complete. Final avg loss: 2.4579\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 3.2101\n",
      "     Epoch 2: Loss = 2.5319\n",
      "   ✅ Training complete. Final avg loss: 2.8710\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2024\n",
      "     Epoch 2: Loss = 1.9583\n",
      "   ✅ Training complete. Final avg loss: 2.0803\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7345\n",
      "     Epoch 2: Loss = 1.5171\n",
      "   ✅ Training complete. Final avg loss: 1.6258\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5686\n",
      "     Epoch 2: Loss = 1.5198\n",
      "   ✅ Training complete. Final avg loss: 1.5442\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.9370\n",
      "     Epoch 2: Loss = 2.8432\n",
      "   ✅ Training complete. Final avg loss: 2.8901\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.0495\n",
      "     Epoch 2: Loss = 2.9296\n",
      "   ✅ Training complete. Final avg loss: 2.9895\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.1065\n",
      "     Epoch 2: Loss = 3.0836\n",
      "   ✅ Training complete. Final avg loss: 3.0951\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 1: Size=2013, Weight=0.1371, Quality=rich\n",
      "  Client 2: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 3: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 4: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 5: Size=4764, Weight=0.3244, Quality=rich\n",
      "  Client 6: Size=6957, Weight=0.4738, Quality=rich\n",
      "  Client 7: Size=  50, Weight=0.0034, Quality=broken\n",
      "  Client 8: Size=  50, Weight=0.0034, Quality=broken\n",
      "  Client 9: Size=  50, Weight=0.0034, Quality=broken\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.83% accuracy, 2.5156 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5600\n",
      "     Epoch 2: Loss = 1.4959\n",
      "   ✅ Training complete. Final avg loss: 1.5279\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1288\n",
      "     Epoch 2: Loss = 1.7809\n",
      "   ✅ Training complete. Final avg loss: 1.9548\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4526\n",
      "     Epoch 2: Loss = 2.3684\n",
      "   ✅ Training complete. Final avg loss: 2.4105\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7197\n",
      "     Epoch 2: Loss = 2.6271\n",
      "   ✅ Training complete. Final avg loss: 2.6734\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6968\n",
      "     Epoch 2: Loss = 2.6141\n",
      "   ✅ Training complete. Final avg loss: 2.6554\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5422\n",
      "     Epoch 2: Loss = 2.5577\n",
      "   ✅ Training complete. Final avg loss: 2.5499\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8567\n",
      "     Epoch 2: Loss = 1.4189\n",
      "   ✅ Training complete. Final avg loss: 1.6378\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5250\n",
      "     Epoch 2: Loss = 1.4572\n",
      "   ✅ Training complete. Final avg loss: 1.4911\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3716\n",
      "     Epoch 2: Loss = 1.9542\n",
      "   ✅ Training complete. Final avg loss: 2.1629\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1986\n",
      "     Epoch 2: Loss = 1.9713\n",
      "   ✅ Training complete. Final avg loss: 2.0850\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4764, Weight=0.3745, Quality=rich\n",
      "  Client 1: Size= 200, Weight=0.0157, Quality=poor\n",
      "  Client 2: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 3: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 4: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 5: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 6: Size= 200, Weight=0.0157, Quality=poor\n",
      "  Client 7: Size=6957, Weight=0.5469, Quality=rich\n",
      "  Client 8: Size= 200, Weight=0.0157, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0157, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.75% accuracy, 2.9897 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1371\n",
      "     Epoch 2: Loss = 1.7708\n",
      "   ✅ Training complete. Final avg loss: 1.9539\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4162\n",
      "     Epoch 2: Loss = 1.9565\n",
      "   ✅ Training complete. Final avg loss: 2.1864\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8532\n",
      "     Epoch 2: Loss = 2.7383\n",
      "   ✅ Training complete. Final avg loss: 2.7958\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1036\n",
      "     Epoch 2: Loss = 1.9765\n",
      "   ✅ Training complete. Final avg loss: 2.0400\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2004\n",
      "     Epoch 2: Loss = 1.9449\n",
      "   ✅ Training complete. Final avg loss: 2.0726\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8388\n",
      "     Epoch 2: Loss = 1.5673\n",
      "   ✅ Training complete. Final avg loss: 1.7030\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8079\n",
      "     Epoch 2: Loss = 1.6375\n",
      "   ✅ Training complete. Final avg loss: 1.7227\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.2719\n",
      "     Epoch 2: Loss = 3.1288\n",
      "   ✅ Training complete. Final avg loss: 3.2004\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8415\n",
      "     Epoch 2: Loss = 1.4253\n",
      "   ✅ Training complete. Final avg loss: 1.6334\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4617\n",
      "     Epoch 2: Loss = 1.4112\n",
      "   ✅ Training complete. Final avg loss: 1.4365\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 1: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 2: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 3: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 4: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 5: Size=2013, Weight=0.1675, Quality=rich\n",
      "  Client 6: Size=1951, Weight=0.1623, Quality=rich\n",
      "  Client 7: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 8: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 9: Size=6957, Weight=0.5787, Quality=rich\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.18% accuracy, 3.3964 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.0449\n",
      "     Epoch 2: Loss = 2.9775\n",
      "   ✅ Training complete. Final avg loss: 3.0112\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5697\n",
      "     Epoch 2: Loss = 1.4216\n",
      "   ✅ Training complete. Final avg loss: 1.4956\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3959\n",
      "     Epoch 2: Loss = 1.9713\n",
      "   ✅ Training complete. Final avg loss: 2.1836\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7191\n",
      "     Epoch 2: Loss = 1.5944\n",
      "   ✅ Training complete. Final avg loss: 1.6568\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0366\n",
      "     Epoch 2: Loss = 1.6994\n",
      "   ✅ Training complete. Final avg loss: 1.8680\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.9943\n",
      "     Epoch 2: Loss = 2.8094\n",
      "   ✅ Training complete. Final avg loss: 2.9018\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.5796\n",
      "     Epoch 2: Loss = 3.3576\n",
      "   ✅ Training complete. Final avg loss: 3.4686\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1084\n",
      "     Epoch 2: Loss = 1.7172\n",
      "   ✅ Training complete. Final avg loss: 1.9128\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 3.0086\n",
      "     Epoch 2: Loss = 2.0566\n",
      "   ✅ Training complete. Final avg loss: 2.5326\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2824\n",
      "     Epoch 2: Loss = 2.0797\n",
      "   ✅ Training complete. Final avg loss: 2.1810\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=  50, Weight=0.0064, Quality=broken\n",
      "  Client 1: Size=4764, Weight=0.6057, Quality=rich\n",
      "  Client 2: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 3: Size=1951, Weight=0.2481, Quality=rich\n",
      "  Client 4: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 5: Size=  50, Weight=0.0064, Quality=broken\n",
      "  Client 6: Size=  50, Weight=0.0064, Quality=broken\n",
      "  Client 7: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 8: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0254, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.20% accuracy, 3.5374 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 20.20%\n",
      "   Best Accuracy: 20.83%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs RESOURCE\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'resource':\n",
      "   Quality threshold: 0.200\n",
      "   Minimum clients ratio: 50.0%\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2980\n",
      "     Epoch 2: Loss = 2.2712\n",
      "   ✅ Training complete. Final avg loss: 2.2846\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0507\n",
      "     Epoch 2: Loss = 1.7390\n",
      "   ✅ Training complete. Final avg loss: 1.8949\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1087\n",
      "     Epoch 2: Loss = 1.8117\n",
      "   ✅ Training complete. Final avg loss: 1.9602\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2861\n",
      "     Epoch 2: Loss = 2.2887\n",
      "   ✅ Training complete. Final avg loss: 2.2874\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3177\n",
      "     Epoch 2: Loss = 2.2761\n",
      "   ✅ Training complete. Final avg loss: 2.2969\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3078\n",
      "     Epoch 2: Loss = 2.3077\n",
      "   ✅ Training complete. Final avg loss: 2.3078\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3113\n",
      "     Epoch 2: Loss = 2.3091\n",
      "   ✅ Training complete. Final avg loss: 2.3102\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8064\n",
      "     Epoch 2: Loss = 1.6834\n",
      "   ✅ Training complete. Final avg loss: 1.7449\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3154\n",
      "     Epoch 2: Loss = 2.2824\n",
      "   ✅ Training complete. Final avg loss: 2.2989\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3219\n",
      "     Epoch 2: Loss = 2.2784\n",
      "   ✅ Training complete. Final avg loss: 2.3001\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.215, Loss=2.247, Loss_std=0.041, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.717, Loss: 0.438\n",
      "      Stability: 0.986, Confidence: 0.080\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.626\n",
      "   ✅ Decision: KEEP (Score 0.626 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.346, Loss=1.697, Loss_std=0.948, Entropy=1.641\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.576\n",
      "      Stability: 0.684, Confidence: 0.344\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.713\n",
      "   ✅ Decision: KEEP (Score 0.713 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.834, Loss_std=0.792, Entropy=1.819\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.542\n",
      "      Stability: 0.736, Confidence: 0.272\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.140, Loss=2.286, Loss_std=0.036, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.467, Loss: 0.429\n",
      "      Stability: 0.988, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.398\n",
      "   ✅ Decision: KEEP (Score 0.398 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=2.243, Loss_std=0.059, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.439\n",
      "      Stability: 0.980, Confidence: 0.080\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.702\n",
      "   ✅ Decision: KEEP (Score 0.702 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.303, Loss_std=0.035, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.424\n",
      "      Stability: 0.988, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.352\n",
      "   ✅ Decision: KEEP (Score 0.352 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.305, Loss_std=0.032, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.424\n",
      "      Stability: 0.989, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.352\n",
      "   ✅ Decision: KEEP (Score 0.352 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.329, Loss=1.622, Loss_std=0.575, Entropy=1.740\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.594\n",
      "      Stability: 0.808, Confidence: 0.304\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=2.249, Loss_std=0.071, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.438\n",
      "      Stability: 0.976, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.700\n",
      "   ✅ Decision: KEEP (Score 0.700 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.440, Loss=2.247, Loss_std=0.047, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.438\n",
      "      Stability: 0.984, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.702\n",
      "   ✅ Decision: KEEP (Score 0.702 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.738 |    6957 | KEEP     | Score 0.738 ≥ threshold 0.200\n",
      "      2 |      1 |  0.980 |     0.713 |    2013 | KEEP     | Score 0.713 ≥ threshold 0.200\n",
      "      3 |      2 |  0.980 |     0.704 |    1951 | KEEP     | Score 0.704 ≥ threshold 0.200\n",
      "      4 |      9 |  0.980 |     0.702 |     200 | KEEP     | Score 0.702 ≥ threshold 0.200\n",
      "      5 |      4 |  0.980 |     0.702 |     200 | KEEP     | Score 0.702 ≥ threshold 0.200\n",
      "      6 |      8 |  0.980 |     0.700 |     200 | KEEP     | Score 0.700 ≥ threshold 0.200\n",
      "      7 |      0 |  0.980 |     0.626 |     200 | KEEP     | Score 0.626 ≥ threshold 0.200\n",
      "      8 |      3 |  0.080 |     0.398 |      50 | KEEP     | Score 0.398 ≥ threshold 0.200\n",
      "      9 |      6 |  0.080 |     0.352 |      50 | KEEP     | Score 0.352 ≥ threshold 0.200\n",
      "     10 |      5 |  0.080 |     0.352 |      50 | KEEP     | Score 0.352 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 1, 2, 9, 4, 8, 0, 3, 6, 5])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.599\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 6957 |   0.738 |  0.586 |  0.140 |   0.319\n",
      "        1 | 2013 |   0.713 |  0.170 |  0.133 |   0.148\n",
      "        2 | 1951 |   0.704 |  0.164 |  0.130 |   0.144\n",
      "        9 |  200 |   0.702 |  0.017 |  0.130 |   0.085\n",
      "        4 |  200 |   0.702 |  0.017 |  0.130 |   0.085\n",
      "        8 |  200 |   0.700 |  0.017 |  0.129 |   0.084\n",
      "        0 |  200 |   0.626 |  0.017 |  0.108 |   0.072\n",
      "        3 |   50 |   0.398 |  0.004 |  0.042 |   0.027\n",
      "        6 |   50 |   0.352 |  0.004 |  0.029 |   0.019\n",
      "        5 |   50 |   0.352 |  0.004 |  0.029 |   0.019\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 10.76% accuracy, 2.3473 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4482\n",
      "     Epoch 2: Loss = 2.4272\n",
      "   ✅ Training complete. Final avg loss: 2.4377\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8769\n",
      "     Epoch 2: Loss = 1.7179\n",
      "   ✅ Training complete. Final avg loss: 1.7974\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3115\n",
      "     Epoch 2: Loss = 2.3243\n",
      "   ✅ Training complete. Final avg loss: 2.3179\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3391\n",
      "     Epoch 2: Loss = 2.3435\n",
      "   ✅ Training complete. Final avg loss: 2.3413\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3234\n",
      "     Epoch 2: Loss = 2.2349\n",
      "   ✅ Training complete. Final avg loss: 2.2792\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4682\n",
      "     Epoch 2: Loss = 2.3288\n",
      "   ✅ Training complete. Final avg loss: 2.3985\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7971\n",
      "     Epoch 2: Loss = 1.5469\n",
      "   ✅ Training complete. Final avg loss: 1.6720\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2775\n",
      "     Epoch 2: Loss = 2.2839\n",
      "   ✅ Training complete. Final avg loss: 2.2807\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1724\n",
      "     Epoch 2: Loss = 2.0897\n",
      "   ✅ Training complete. Final avg loss: 2.1310\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3648\n",
      "     Epoch 2: Loss = 2.3848\n",
      "   ✅ Training complete. Final avg loss: 2.3748\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.405, Loss_std=0.347, Entropy=2.258\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.399\n",
      "      Stability: 0.884, Confidence: 0.097\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.329\n",
      "   ✅ Decision: KEEP (Score 0.329 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.450, Loss=1.622, Loss_std=0.790, Entropy=1.744\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.594\n",
      "      Stability: 0.737, Confidence: 0.302\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.310, Loss_std=0.271, Entropy=2.256\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.422\n",
      "      Stability: 0.910, Confidence: 0.098\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.324\n",
      "   ✅ Decision: KEEP (Score 0.324 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.040, Loss=2.323, Loss_std=0.276, Entropy=2.256\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.133, Loss: 0.419\n",
      "      Stability: 0.908, Confidence: 0.098\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.307\n",
      "   ✅ Decision: KEEP (Score 0.307 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=2.130, Loss_std=0.291, Entropy=2.267\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.467\n",
      "      Stability: 0.903, Confidence: 0.093\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.693\n",
      "   ✅ Decision: KEEP (Score 0.693 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.256, Loss_std=0.145, Entropy=2.286\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.400, Loss: 0.436\n",
      "      Stability: 0.952, Confidence: 0.086\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.534\n",
      "   ✅ Decision: KEEP (Score 0.534 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.495, Loss=1.495, Loss_std=1.115, Entropy=1.511\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.626\n",
      "      Stability: 0.628, Confidence: 0.396\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.721\n",
      "   ✅ Decision: KEEP (Score 0.721 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.220, Loss=2.266, Loss_std=0.388, Entropy=2.249\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.733, Loss: 0.433\n",
      "      Stability: 0.871, Confidence: 0.100\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.441\n",
      "   ✅ Decision: KEEP (Score 0.441 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=2.024, Loss_std=0.309, Entropy=2.223\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.494\n",
      "      Stability: 0.897, Confidence: 0.111\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.701\n",
      "   ✅ Decision: KEEP (Score 0.701 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.361, Loss_std=0.287, Entropy=2.257\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.410\n",
      "      Stability: 0.904, Confidence: 0.097\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.320\n",
      "   ✅ Decision: KEEP (Score 0.320 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      1 |  0.980 |     0.722 |    2013 | KEEP     | Score 0.722 ≥ threshold 0.200\n",
      "      2 |      6 |  0.980 |     0.721 |    4764 | KEEP     | Score 0.721 ≥ threshold 0.200\n",
      "      3 |      8 |  0.980 |     0.701 |     200 | KEEP     | Score 0.701 ≥ threshold 0.200\n",
      "      4 |      4 |  0.980 |     0.693 |     200 | KEEP     | Score 0.693 ≥ threshold 0.200\n",
      "      5 |      5 |  0.980 |     0.534 |     200 | KEEP     | Score 0.534 ≥ threshold 0.200\n",
      "      6 |      7 |  0.080 |     0.441 |      50 | KEEP     | Score 0.441 ≥ threshold 0.200\n",
      "      7 |      0 |  0.080 |     0.329 |      50 | KEEP     | Score 0.329 ≥ threshold 0.200\n",
      "      8 |      2 |  0.080 |     0.324 |      50 | KEEP     | Score 0.324 ≥ threshold 0.200\n",
      "      9 |      9 |  0.080 |     0.320 |      50 | KEEP     | Score 0.320 ≥ threshold 0.200\n",
      "     10 |      3 |  0.080 |     0.307 |      50 | KEEP     | Score 0.307 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [1, 6, 8, 4, 5, 7, 0, 2, 9, 3])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.509\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        1 | 2013 |   0.722 |  0.264 |  0.170 |   0.208\n",
      "        6 | 4764 |   0.721 |  0.625 |  0.170 |   0.352\n",
      "        8 |  200 |   0.701 |  0.026 |  0.163 |   0.109\n",
      "        4 |  200 |   0.693 |  0.026 |  0.161 |   0.107\n",
      "        5 |  200 |   0.534 |  0.026 |  0.108 |   0.075\n",
      "        7 |   50 |   0.441 |  0.007 |  0.077 |   0.049\n",
      "        0 |   50 |   0.329 |  0.007 |  0.040 |   0.027\n",
      "        2 |   50 |   0.324 |  0.007 |  0.039 |   0.026\n",
      "        9 |   50 |   0.320 |  0.007 |  0.037 |   0.025\n",
      "        3 |   50 |   0.307 |  0.007 |  0.033 |   0.022\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 15.22% accuracy, 2.3201 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9232\n",
      "     Epoch 2: Loss = 1.8035\n",
      "   ✅ Training complete. Final avg loss: 1.8634\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3730\n",
      "     Epoch 2: Loss = 2.3864\n",
      "   ✅ Training complete. Final avg loss: 2.3797\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2113\n",
      "     Epoch 2: Loss = 2.0844\n",
      "   ✅ Training complete. Final avg loss: 2.1478\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3964\n",
      "     Epoch 2: Loss = 2.4079\n",
      "   ✅ Training complete. Final avg loss: 2.4021\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2134\n",
      "     Epoch 2: Loss = 2.0352\n",
      "   ✅ Training complete. Final avg loss: 2.1243\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3580\n",
      "     Epoch 2: Loss = 2.1752\n",
      "   ✅ Training complete. Final avg loss: 2.2666\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5036\n",
      "     Epoch 2: Loss = 2.4869\n",
      "   ✅ Training complete. Final avg loss: 2.4952\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.1734\n",
      "     Epoch 2: Loss = 2.2260\n",
      "   ✅ Training complete. Final avg loss: 2.1997\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3833\n",
      "     Epoch 2: Loss = 2.3598\n",
      "   ✅ Training complete. Final avg loss: 2.3716\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6225\n",
      "     Epoch 2: Loss = 1.5292\n",
      "   ✅ Training complete. Final avg loss: 1.5758\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.380, Loss=1.735, Loss_std=0.904, Entropy=1.733\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.566\n",
      "      Stability: 0.699, Confidence: 0.307\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.708\n",
      "   ✅ Decision: KEEP (Score 0.708 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.100, Loss=2.347, Loss_std=0.275, Entropy=2.250\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.333, Loss: 0.413\n",
      "      Stability: 0.908, Confidence: 0.100\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.353\n",
      "   ✅ Decision: KEEP (Score 0.353 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=1.990, Loss_std=0.538, Entropy=2.197\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.503\n",
      "      Stability: 0.821, Confidence: 0.121\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.687\n",
      "   ✅ Decision: KEEP (Score 0.687 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.040, Loss=2.358, Loss_std=0.263, Entropy=2.254\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.133, Loss: 0.410\n",
      "      Stability: 0.912, Confidence: 0.098\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.307\n",
      "   ✅ Decision: KEEP (Score 0.307 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.907, Loss_std=0.324, Entropy=2.202\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.523\n",
      "      Stability: 0.892, Confidence: 0.119\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.708\n",
      "   ✅ Decision: KEEP (Score 0.708 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.455, Loss=2.049, Loss_std=0.223, Entropy=2.266\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.488\n",
      "      Stability: 0.926, Confidence: 0.094\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.703\n",
      "   ✅ Decision: KEEP (Score 0.703 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.471, Loss_std=0.296, Entropy=2.257\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.382\n",
      "      Stability: 0.901, Confidence: 0.097\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.314\n",
      "   ✅ Decision: KEEP (Score 0.314 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.200, Loss=2.166, Loss_std=0.359, Entropy=2.231\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.667, Loss: 0.458\n",
      "      Stability: 0.880, Confidence: 0.107\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.433\n",
      "   ✅ Decision: KEEP (Score 0.433 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.348, Loss_std=0.285, Entropy=2.252\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.413\n",
      "      Stability: 0.905, Confidence: 0.099\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.336\n",
      "   ✅ Decision: KEEP (Score 0.336 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.553, Loss=1.399, Loss_std=1.052, Entropy=1.571\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.650\n",
      "      Stability: 0.649, Confidence: 0.372\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      9 |  0.980 |     0.727 |    4764 | KEEP     | Score 0.727 ≥ threshold 0.200\n",
      "      2 |      4 |  0.980 |     0.708 |     200 | KEEP     | Score 0.708 ≥ threshold 0.200\n",
      "      3 |      0 |  0.980 |     0.708 |    1951 | KEEP     | Score 0.708 ≥ threshold 0.200\n",
      "      4 |      5 |  0.980 |     0.703 |     200 | KEEP     | Score 0.703 ≥ threshold 0.200\n",
      "      5 |      2 |  0.980 |     0.687 |     200 | KEEP     | Score 0.687 ≥ threshold 0.200\n",
      "      6 |      7 |  0.080 |     0.433 |      50 | KEEP     | Score 0.433 ≥ threshold 0.200\n",
      "      7 |      1 |  0.080 |     0.353 |      50 | KEEP     | Score 0.353 ≥ threshold 0.200\n",
      "      8 |      8 |  0.080 |     0.336 |      50 | KEEP     | Score 0.336 ≥ threshold 0.200\n",
      "      9 |      6 |  0.080 |     0.314 |      50 | KEEP     | Score 0.314 ≥ threshold 0.200\n",
      "     10 |      3 |  0.080 |     0.307 |      50 | KEEP     | Score 0.307 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [9, 4, 0, 5, 2, 7, 1, 8, 6, 3])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.528\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        9 | 4764 |   0.727 |  0.630 |  0.162 |   0.349\n",
      "        4 |  200 |   0.708 |  0.026 |  0.156 |   0.104\n",
      "        0 | 1951 |   0.708 |  0.258 |  0.156 |   0.197\n",
      "        5 |  200 |   0.703 |  0.026 |  0.155 |   0.103\n",
      "        2 |  200 |   0.687 |  0.026 |  0.150 |   0.100\n",
      "        7 |   50 |   0.433 |  0.007 |  0.071 |   0.045\n",
      "        1 |   50 |   0.353 |  0.007 |  0.045 |   0.030\n",
      "        8 |   50 |   0.336 |  0.007 |  0.040 |   0.027\n",
      "        6 |   50 |   0.314 |  0.007 |  0.034 |   0.023\n",
      "        3 |   50 |   0.307 |  0.007 |  0.031 |   0.021\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.87% accuracy, 2.5146 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5300\n",
      "     Epoch 2: Loss = 2.5907\n",
      "   ✅ Training complete. Final avg loss: 2.5604\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5689\n",
      "     Epoch 2: Loss = 1.5221\n",
      "   ✅ Training complete. Final avg loss: 1.5455\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0853\n",
      "     Epoch 2: Loss = 1.9810\n",
      "   ✅ Training complete. Final avg loss: 2.0332\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1054\n",
      "     Epoch 2: Loss = 1.9197\n",
      "   ✅ Training complete. Final avg loss: 2.0126\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1734\n",
      "     Epoch 2: Loss = 2.0526\n",
      "   ✅ Training complete. Final avg loss: 2.1130\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8669\n",
      "     Epoch 2: Loss = 1.7932\n",
      "   ✅ Training complete. Final avg loss: 1.8301\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9548\n",
      "     Epoch 2: Loss = 1.5150\n",
      "   ✅ Training complete. Final avg loss: 1.7349\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2295\n",
      "     Epoch 2: Loss = 2.1443\n",
      "   ✅ Training complete. Final avg loss: 2.1869\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4731\n",
      "     Epoch 2: Loss = 2.2190\n",
      "   ✅ Training complete. Final avg loss: 2.3460\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8453\n",
      "     Epoch 2: Loss = 1.6857\n",
      "   ✅ Training complete. Final avg loss: 1.7655\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.000, Loss=2.444, Loss_std=0.479, Entropy=2.176\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.000, Loss: 0.389\n",
      "      Stability: 0.840, Confidence: 0.130\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.263\n",
      "   ✅ Decision: KEEP (Score 0.263 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.538, Loss=1.397, Loss_std=1.157, Entropy=1.447\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.651\n",
      "      Stability: 0.614, Confidence: 0.421\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=1.883, Loss_std=0.810, Entropy=2.019\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.529\n",
      "      Stability: 0.730, Confidence: 0.193\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.686\n",
      "   ✅ Decision: KEEP (Score 0.686 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.455, Loss=1.729, Loss_std=0.585, Entropy=2.042\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.568\n",
      "      Stability: 0.805, Confidence: 0.183\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.989, Loss_std=0.413, Entropy=2.166\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.503\n",
      "      Stability: 0.862, Confidence: 0.133\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.699\n",
      "   ✅ Decision: KEEP (Score 0.699 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.337, Loss=1.773, Loss_std=0.867, Entropy=1.752\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.711, Confidence: 0.299\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.685, Loss=1.309, Loss_std=1.123, Entropy=1.623\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.673\n",
      "      Stability: 0.626, Confidence: 0.351\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.723\n",
      "   ✅ Decision: KEEP (Score 0.723 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.150, Loss_std=0.420, Entropy=2.158\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.400, Loss: 0.462\n",
      "      Stability: 0.860, Confidence: 0.137\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.374\n",
      "   ✅ Decision: KEEP (Score 0.374 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.285, Loss=2.017, Loss_std=0.261, Entropy=2.237\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.950, Loss: 0.496\n",
      "      Stability: 0.913, Confidence: 0.105\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.690\n",
      "   ✅ Decision: KEEP (Score 0.690 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.406, Loss=1.645, Loss_std=0.884, Entropy=1.706\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.589\n",
      "      Stability: 0.705, Confidence: 0.318\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      1 |  0.980 |     0.728 |    4764 | KEEP     | Score 0.728 ≥ threshold 0.200\n",
      "      2 |      6 |  0.980 |     0.723 |     200 | KEEP     | Score 0.723 ≥ threshold 0.200\n",
      "      3 |      9 |  0.980 |     0.716 |    2013 | KEEP     | Score 0.716 ≥ threshold 0.200\n",
      "      4 |      3 |  0.980 |     0.710 |     200 | KEEP     | Score 0.710 ≥ threshold 0.200\n",
      "      5 |      5 |  0.980 |     0.707 |    1951 | KEEP     | Score 0.707 ≥ threshold 0.200\n",
      "      6 |      4 |  0.980 |     0.699 |     200 | KEEP     | Score 0.699 ≥ threshold 0.200\n",
      "      7 |      8 |  0.980 |     0.690 |     200 | KEEP     | Score 0.690 ≥ threshold 0.200\n",
      "      8 |      2 |  0.980 |     0.686 |     200 | KEEP     | Score 0.686 ≥ threshold 0.200\n",
      "      9 |      7 |  0.080 |     0.374 |      50 | KEEP     | Score 0.374 ≥ threshold 0.200\n",
      "     10 |      0 |  0.080 |     0.263 |      50 | KEEP     | Score 0.263 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [1, 6, 9, 3, 5, 4, 8, 2, 7, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.630\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        1 | 4764 |   0.728 |  0.485 |  0.121 |   0.267\n",
      "        6 |  200 |   0.723 |  0.020 |  0.120 |   0.080\n",
      "        9 | 2013 |   0.716 |  0.205 |  0.119 |   0.153\n",
      "        3 |  200 |   0.710 |  0.020 |  0.117 |   0.078\n",
      "        5 | 1951 |   0.707 |  0.199 |  0.117 |   0.149\n",
      "        4 |  200 |   0.699 |  0.020 |  0.115 |   0.077\n",
      "        8 |  200 |   0.690 |  0.020 |  0.113 |   0.076\n",
      "        2 |  200 |   0.686 |  0.020 |  0.112 |   0.075\n",
      "        7 |   50 |   0.374 |  0.005 |  0.045 |   0.029\n",
      "        0 |   50 |   0.263 |  0.005 |  0.021 |   0.015\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.88% accuracy, 2.6330 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5384\n",
      "     Epoch 2: Loss = 2.4880\n",
      "   ✅ Training complete. Final avg loss: 2.5132\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4275\n",
      "     Epoch 2: Loss = 2.3869\n",
      "   ✅ Training complete. Final avg loss: 2.4072\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5508\n",
      "     Epoch 2: Loss = 1.5151\n",
      "   ✅ Training complete. Final avg loss: 1.5330\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6825\n",
      "     Epoch 2: Loss = 2.6147\n",
      "   ✅ Training complete. Final avg loss: 2.6486\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8626\n",
      "     Epoch 2: Loss = 1.7887\n",
      "   ✅ Training complete. Final avg loss: 1.8256\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8855\n",
      "     Epoch 2: Loss = 2.8525\n",
      "   ✅ Training complete. Final avg loss: 2.8690\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7375\n",
      "     Epoch 2: Loss = 1.6471\n",
      "   ✅ Training complete. Final avg loss: 1.6923\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.5142\n",
      "     Epoch 2: Loss = 2.1932\n",
      "   ✅ Training complete. Final avg loss: 2.3537\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8031\n",
      "     Epoch 2: Loss = 1.6674\n",
      "   ✅ Training complete. Final avg loss: 1.7353\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2163\n",
      "     Epoch 2: Loss = 2.1556\n",
      "   ✅ Training complete. Final avg loss: 2.1859\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.020, Loss=2.456, Loss_std=0.482, Entropy=2.131\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.067, Loss: 0.386\n",
      "      Stability: 0.839, Confidence: 0.148\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.280\n",
      "   ✅ Decision: KEEP (Score 0.280 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.376, Loss_std=0.612, Entropy=2.132\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.406\n",
      "      Stability: 0.796, Confidence: 0.147\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.322\n",
      "   ✅ Decision: KEEP (Score 0.322 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.546, Loss=1.413, Loss_std=1.062, Entropy=1.539\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.647\n",
      "      Stability: 0.646, Confidence: 0.384\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.554, Loss_std=0.552, Entropy=2.146\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.361\n",
      "      Stability: 0.816, Confidence: 0.141\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.316\n",
      "   ✅ Decision: KEEP (Score 0.316 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.394, Loss=1.810, Loss_std=0.897, Entropy=1.808\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.548\n",
      "      Stability: 0.701, Confidence: 0.277\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.699\n",
      "   ✅ Decision: KEEP (Score 0.699 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.100, Loss=2.790, Loss_std=0.712, Entropy=2.147\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.333, Loss: 0.303\n",
      "      Stability: 0.763, Confidence: 0.141\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.310\n",
      "   ✅ Decision: KEEP (Score 0.310 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.382, Loss=1.598, Loss_std=0.695, Entropy=1.691\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.601\n",
      "      Stability: 0.768, Confidence: 0.324\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.734\n",
      "   ✅ Decision: KEEP (Score 0.734 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.345, Loss=1.952, Loss_std=0.305, Entropy=2.210\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.512\n",
      "      Stability: 0.898, Confidence: 0.116\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.413, Loss=1.571, Loss_std=0.774, Entropy=1.705\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.607\n",
      "      Stability: 0.742, Confidence: 0.318\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.729\n",
      "   ✅ Decision: KEEP (Score 0.729 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.157, Loss_std=0.536, Entropy=2.108\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.400, Loss: 0.461\n",
      "      Stability: 0.821, Confidence: 0.157\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.369\n",
      "   ✅ Decision: KEEP (Score 0.369 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.734 |    6957 | KEEP     | Score 0.734 ≥ threshold 0.200\n",
      "      2 |      8 |  0.980 |     0.729 |    2013 | KEEP     | Score 0.729 ≥ threshold 0.200\n",
      "      3 |      2 |  0.980 |     0.728 |    4764 | KEEP     | Score 0.728 ≥ threshold 0.200\n",
      "      4 |      7 |  0.980 |     0.706 |     200 | KEEP     | Score 0.706 ≥ threshold 0.200\n",
      "      5 |      4 |  0.980 |     0.699 |    1951 | KEEP     | Score 0.699 ≥ threshold 0.200\n",
      "      6 |      9 |  0.080 |     0.369 |      50 | KEEP     | Score 0.369 ≥ threshold 0.200\n",
      "      7 |      1 |  0.080 |     0.322 |      50 | KEEP     | Score 0.322 ≥ threshold 0.200\n",
      "      8 |      3 |  0.080 |     0.316 |      50 | KEEP     | Score 0.316 ≥ threshold 0.200\n",
      "      9 |      5 |  0.080 |     0.310 |      50 | KEEP     | Score 0.310 ≥ threshold 0.200\n",
      "     10 |      0 |  0.080 |     0.280 |      50 | KEEP     | Score 0.280 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [6, 8, 2, 7, 4, 9, 1, 3, 5, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.519\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 6957 |   0.734 |  0.431 |  0.163 |   0.271\n",
      "        8 | 2013 |   0.729 |  0.125 |  0.162 |   0.147\n",
      "        2 | 4764 |   0.728 |  0.295 |  0.162 |   0.215\n",
      "        7 |  200 |   0.706 |  0.012 |  0.155 |   0.098\n",
      "        4 | 1951 |   0.699 |  0.121 |  0.153 |   0.140\n",
      "        9 |   50 |   0.369 |  0.003 |  0.056 |   0.035\n",
      "        1 |   50 |   0.322 |  0.003 |  0.042 |   0.026\n",
      "        3 |   50 |   0.316 |  0.003 |  0.040 |   0.025\n",
      "        5 |   50 |   0.310 |  0.003 |  0.038 |   0.024\n",
      "        0 |   50 |   0.280 |  0.003 |  0.029 |   0.019\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 15.78% accuracy, 2.4584 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6762\n",
      "     Epoch 2: Loss = 1.6223\n",
      "   ✅ Training complete. Final avg loss: 1.6492\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7552\n",
      "     Epoch 2: Loss = 1.6575\n",
      "   ✅ Training complete. Final avg loss: 1.7064\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3354\n",
      "     Epoch 2: Loss = 1.9625\n",
      "   ✅ Training complete. Final avg loss: 2.1490\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1380\n",
      "     Epoch 2: Loss = 1.9276\n",
      "   ✅ Training complete. Final avg loss: 2.0328\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1254\n",
      "     Epoch 2: Loss = 1.5227\n",
      "   ✅ Training complete. Final avg loss: 1.8240\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2654\n",
      "     Epoch 2: Loss = 2.2422\n",
      "   ✅ Training complete. Final avg loss: 2.2538\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4989\n",
      "     Epoch 2: Loss = 2.3860\n",
      "   ✅ Training complete. Final avg loss: 2.4424\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2866\n",
      "     Epoch 2: Loss = 2.0019\n",
      "   ✅ Training complete. Final avg loss: 2.1442\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8460\n",
      "     Epoch 2: Loss = 1.7706\n",
      "   ✅ Training complete. Final avg loss: 1.8083\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5685\n",
      "     Epoch 2: Loss = 1.5137\n",
      "   ✅ Training complete. Final avg loss: 1.5411\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.442, Loss=1.560, Loss_std=0.775, Entropy=1.645\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.610\n",
      "      Stability: 0.742, Confidence: 0.342\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.734\n",
      "   ✅ Decision: KEEP (Score 0.734 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.450, Loss=1.609, Loss_std=0.935, Entropy=1.708\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.598\n",
      "      Stability: 0.688, Confidence: 0.317\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.714\n",
      "   ✅ Decision: KEEP (Score 0.714 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.400, Loss=1.730, Loss_std=0.455, Entropy=2.070\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.567\n",
      "      Stability: 0.848, Confidence: 0.172\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.718\n",
      "   ✅ Decision: KEEP (Score 0.718 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=1.833, Loss_std=0.783, Entropy=1.998\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.542\n",
      "      Stability: 0.739, Confidence: 0.201\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.692\n",
      "   ✅ Decision: KEEP (Score 0.692 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.675, Loss=1.238, Loss_std=1.102, Entropy=1.511\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.691\n",
      "      Stability: 0.633, Confidence: 0.395\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.737\n",
      "   ✅ Decision: KEEP (Score 0.737 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.220, Loss=2.179, Loss_std=0.632, Entropy=2.103\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.733, Loss: 0.455\n",
      "      Stability: 0.789, Confidence: 0.159\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.439\n",
      "   ✅ Decision: KEEP (Score 0.439 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.375, Loss_std=0.507, Entropy=2.149\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.406\n",
      "      Stability: 0.831, Confidence: 0.140\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.312\n",
      "   ✅ Decision: KEEP (Score 0.312 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.435, Loss=1.778, Loss_std=0.600, Entropy=2.077\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.555\n",
      "      Stability: 0.800, Confidence: 0.169\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.703\n",
      "   ✅ Decision: KEEP (Score 0.703 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.394, Loss=1.677, Loss_std=0.799, Entropy=1.743\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.581\n",
      "      Stability: 0.734, Confidence: 0.303\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.718\n",
      "   ✅ Decision: KEEP (Score 0.718 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.536, Loss=1.457, Loss_std=1.213, Entropy=1.464\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.636\n",
      "      Stability: 0.596, Confidence: 0.415\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.720\n",
      "   ✅ Decision: KEEP (Score 0.720 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.737 |     200 | KEEP     | Score 0.737 ≥ threshold 0.200\n",
      "      2 |      0 |  0.980 |     0.734 |    6957 | KEEP     | Score 0.734 ≥ threshold 0.200\n",
      "      3 |      9 |  0.980 |     0.720 |    4764 | KEEP     | Score 0.720 ≥ threshold 0.200\n",
      "      4 |      8 |  0.980 |     0.718 |    1951 | KEEP     | Score 0.718 ≥ threshold 0.200\n",
      "      5 |      2 |  0.980 |     0.718 |     200 | KEEP     | Score 0.718 ≥ threshold 0.200\n",
      "      6 |      1 |  0.980 |     0.714 |    2013 | KEEP     | Score 0.714 ≥ threshold 0.200\n",
      "      7 |      7 |  0.980 |     0.703 |     200 | KEEP     | Score 0.703 ≥ threshold 0.200\n",
      "      8 |      3 |  0.980 |     0.692 |     200 | KEEP     | Score 0.692 ≥ threshold 0.200\n",
      "      9 |      5 |  0.080 |     0.439 |      50 | KEEP     | Score 0.439 ≥ threshold 0.200\n",
      "     10 |      6 |  0.080 |     0.312 |      50 | KEEP     | Score 0.312 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 0, 9, 8, 2, 1, 7, 3, 5, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.649\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 |  200 |   0.737 |  0.012 |  0.120 |   0.077\n",
      "        0 | 6957 |   0.734 |  0.419 |  0.119 |   0.239\n",
      "        9 | 4764 |   0.720 |  0.287 |  0.116 |   0.185\n",
      "        8 | 1951 |   0.718 |  0.118 |  0.116 |   0.117\n",
      "        2 |  200 |   0.718 |  0.012 |  0.116 |   0.074\n",
      "        1 | 2013 |   0.714 |  0.121 |  0.115 |   0.118\n",
      "        7 |  200 |   0.703 |  0.012 |  0.113 |   0.072\n",
      "        3 |  200 |   0.692 |  0.012 |  0.110 |   0.071\n",
      "        5 |   50 |   0.439 |  0.003 |  0.052 |   0.032\n",
      "        6 |   50 |   0.312 |  0.003 |  0.023 |   0.015\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 16.86% accuracy, 2.5274 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7696\n",
      "     Epoch 2: Loss = 1.6560\n",
      "   ✅ Training complete. Final avg loss: 1.7128\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6611\n",
      "     Epoch 2: Loss = 1.6061\n",
      "   ✅ Training complete. Final avg loss: 1.6336\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6052\n",
      "     Epoch 2: Loss = 2.5368\n",
      "   ✅ Training complete. Final avg loss: 2.5710\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0080\n",
      "     Epoch 2: Loss = 1.4135\n",
      "   ✅ Training complete. Final avg loss: 1.7108\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8369\n",
      "     Epoch 2: Loss = 1.7676\n",
      "   ✅ Training complete. Final avg loss: 1.8022\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4412\n",
      "     Epoch 2: Loss = 2.3882\n",
      "   ✅ Training complete. Final avg loss: 2.4147\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5492\n",
      "     Epoch 2: Loss = 1.5090\n",
      "   ✅ Training complete. Final avg loss: 1.5291\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0805\n",
      "     Epoch 2: Loss = 1.8895\n",
      "   ✅ Training complete. Final avg loss: 1.9850\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6341\n",
      "     Epoch 2: Loss = 2.6460\n",
      "   ✅ Training complete. Final avg loss: 2.6400\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1765\n",
      "     Epoch 2: Loss = 1.9240\n",
      "   ✅ Training complete. Final avg loss: 2.0503\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.394, Loss=1.584, Loss_std=0.895, Entropy=1.665\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.604\n",
      "      Stability: 0.702, Confidence: 0.334\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.351, Loss=1.659, Loss_std=0.909, Entropy=1.626\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.585\n",
      "      Stability: 0.697, Confidence: 0.349\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.719\n",
      "   ✅ Decision: KEEP (Score 0.719 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.475, Loss_std=0.529, Entropy=2.174\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.381\n",
      "      Stability: 0.824, Confidence: 0.130\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.304\n",
      "   ✅ Decision: KEEP (Score 0.304 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.680, Loss=1.197, Loss_std=1.239, Entropy=1.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.701\n",
      "      Stability: 0.587, Confidence: 0.482\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.744\n",
      "   ✅ Decision: KEEP (Score 0.744 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.341, Loss=1.779, Loss_std=0.848, Entropy=1.782\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.555\n",
      "      Stability: 0.717, Confidence: 0.287\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.364, Loss_std=0.504, Entropy=2.158\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.409\n",
      "      Stability: 0.832, Confidence: 0.137\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.312\n",
      "   ✅ Decision: KEEP (Score 0.312 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.488, Loss=1.549, Loss_std=1.102, Entropy=1.579\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.613\n",
      "      Stability: 0.633, Confidence: 0.368\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.480, Loss=1.802, Loss_std=0.823, Entropy=1.944\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.549\n",
      "      Stability: 0.726, Confidence: 0.222\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.695\n",
      "   ✅ Decision: KEEP (Score 0.695 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.493, Loss_std=0.463, Entropy=2.156\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.377\n",
      "      Stability: 0.846, Confidence: 0.138\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.324\n",
      "   ✅ Decision: KEEP (Score 0.324 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.385, Loss=1.773, Loss_std=0.567, Entropy=2.052\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.811, Confidence: 0.179\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.708\n",
      "   ✅ Decision: KEEP (Score 0.708 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.744 |     200 | KEEP     | Score 0.744 ≥ threshold 0.200\n",
      "      2 |      0 |  0.980 |     0.722 |    2013 | KEEP     | Score 0.722 ≥ threshold 0.200\n",
      "      3 |      1 |  0.980 |     0.719 |    6957 | KEEP     | Score 0.719 ≥ threshold 0.200\n",
      "      4 |      6 |  0.980 |     0.715 |    4764 | KEEP     | Score 0.715 ≥ threshold 0.200\n",
      "      5 |      9 |  0.980 |     0.708 |     200 | KEEP     | Score 0.708 ≥ threshold 0.200\n",
      "      6 |      4 |  0.980 |     0.706 |    1951 | KEEP     | Score 0.706 ≥ threshold 0.200\n",
      "      7 |      7 |  0.980 |     0.695 |     200 | KEEP     | Score 0.695 ≥ threshold 0.200\n",
      "      8 |      8 |  0.080 |     0.324 |      50 | KEEP     | Score 0.324 ≥ threshold 0.200\n",
      "      9 |      5 |  0.080 |     0.312 |      50 | KEEP     | Score 0.312 ≥ threshold 0.200\n",
      "     10 |      2 |  0.080 |     0.304 |      50 | KEEP     | Score 0.304 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [3, 0, 1, 6, 9, 4, 7, 8, 5, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.595\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 |  200 |   0.744 |  0.012 |  0.138 |   0.088\n",
      "        0 | 2013 |   0.722 |  0.122 |  0.132 |   0.128\n",
      "        1 | 6957 |   0.719 |  0.423 |  0.132 |   0.248\n",
      "        6 | 4764 |   0.715 |  0.290 |  0.131 |   0.194\n",
      "        9 |  200 |   0.708 |  0.012 |  0.129 |   0.082\n",
      "        4 | 1951 |   0.706 |  0.119 |  0.128 |   0.125\n",
      "        7 |  200 |   0.695 |  0.012 |  0.126 |   0.080\n",
      "        8 |   50 |   0.324 |  0.003 |  0.031 |   0.020\n",
      "        5 |   50 |   0.312 |  0.003 |  0.028 |   0.018\n",
      "        2 |   50 |   0.304 |  0.003 |  0.026 |   0.017\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.04% accuracy, 2.5666 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8310\n",
      "     Epoch 2: Loss = 1.7520\n",
      "   ✅ Training complete. Final avg loss: 1.7915\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1730\n",
      "     Epoch 2: Loss = 2.0368\n",
      "   ✅ Training complete. Final avg loss: 2.1049\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5539\n",
      "     Epoch 2: Loss = 1.4985\n",
      "   ✅ Training complete. Final avg loss: 1.5262\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6449\n",
      "     Epoch 2: Loss = 1.5854\n",
      "   ✅ Training complete. Final avg loss: 1.6152\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5919\n",
      "     Epoch 2: Loss = 2.4836\n",
      "   ✅ Training complete. Final avg loss: 2.5377\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8610\n",
      "     Epoch 2: Loss = 1.4077\n",
      "   ✅ Training complete. Final avg loss: 1.6344\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0407\n",
      "     Epoch 2: Loss = 1.8410\n",
      "   ✅ Training complete. Final avg loss: 1.9408\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2345\n",
      "     Epoch 2: Loss = 2.2433\n",
      "   ✅ Training complete. Final avg loss: 2.2389\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2535\n",
      "     Epoch 2: Loss = 1.9594\n",
      "   ✅ Training complete. Final avg loss: 2.1064\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1068\n",
      "     Epoch 2: Loss = 1.8864\n",
      "   ✅ Training complete. Final avg loss: 1.9966\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.365, Loss=1.773, Loss_std=0.820, Entropy=1.838\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.727, Confidence: 0.265\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.295, Loss=1.927, Loss_std=0.523, Entropy=2.103\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.983, Loss: 0.518\n",
      "      Stability: 0.826, Confidence: 0.159\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.694\n",
      "   ✅ Decision: KEEP (Score 0.694 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.543, Loss=1.407, Loss_std=1.118, Entropy=1.511\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.648\n",
      "      Stability: 0.627, Confidence: 0.396\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.726\n",
      "   ✅ Decision: KEEP (Score 0.726 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.425, Loss=1.490, Loss_std=0.687, Entropy=1.638\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.628\n",
      "      Stability: 0.771, Confidence: 0.345\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.745\n",
      "   ✅ Decision: KEEP (Score 0.745 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.437, Loss_std=0.472, Entropy=2.165\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.391\n",
      "      Stability: 0.843, Confidence: 0.134\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.326\n",
      "   ✅ Decision: KEEP (Score 0.326 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.680, Loss=1.181, Loss_std=1.293, Entropy=1.192\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.705\n",
      "      Stability: 0.569, Confidence: 0.523\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.749\n",
      "   ✅ Decision: KEEP (Score 0.749 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.405, Loss=1.700, Loss_std=0.686, Entropy=1.939\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.575\n",
      "      Stability: 0.771, Confidence: 0.224\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.711\n",
      "   ✅ Decision: KEEP (Score 0.711 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.180, Loss=2.195, Loss_std=0.567, Entropy=2.115\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.600, Loss: 0.451\n",
      "      Stability: 0.811, Confidence: 0.154\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.411\n",
      "   ✅ Decision: KEEP (Score 0.411 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.718, Loss_std=0.690, Entropy=1.994\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.570\n",
      "      Stability: 0.770, Confidence: 0.202\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.480, Loss=1.802, Loss_std=0.820, Entropy=1.945\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.549\n",
      "      Stability: 0.727, Confidence: 0.222\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.695\n",
      "   ✅ Decision: KEEP (Score 0.695 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      5 |  0.980 |     0.749 |     200 | KEEP     | Score 0.749 ≥ threshold 0.200\n",
      "      2 |      3 |  0.980 |     0.745 |    6957 | KEEP     | Score 0.745 ≥ threshold 0.200\n",
      "      3 |      2 |  0.980 |     0.726 |    4764 | KEEP     | Score 0.726 ≥ threshold 0.200\n",
      "      4 |      6 |  0.980 |     0.711 |     200 | KEEP     | Score 0.711 ≥ threshold 0.200\n",
      "      5 |      8 |  0.980 |     0.706 |     200 | KEEP     | Score 0.706 ≥ threshold 0.200\n",
      "      6 |      0 |  0.980 |     0.704 |    1951 | KEEP     | Score 0.704 ≥ threshold 0.200\n",
      "      7 |      9 |  0.980 |     0.695 |     200 | KEEP     | Score 0.695 ≥ threshold 0.200\n",
      "      8 |      1 |  0.980 |     0.694 |     200 | KEEP     | Score 0.694 ≥ threshold 0.200\n",
      "      9 |      7 |  0.080 |     0.411 |      50 | KEEP     | Score 0.411 ≥ threshold 0.200\n",
      "     10 |      4 |  0.080 |     0.326 |      50 | KEEP     | Score 0.326 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [5, 3, 2, 6, 8, 0, 9, 1, 7, 4])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.647\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        5 |  200 |   0.749 |  0.014 |  0.124 |   0.080\n",
      "        3 | 6957 |   0.745 |  0.471 |  0.123 |   0.262\n",
      "        2 | 4764 |   0.726 |  0.323 |  0.119 |   0.200\n",
      "        6 |  200 |   0.711 |  0.014 |  0.115 |   0.075\n",
      "        8 |  200 |   0.706 |  0.014 |  0.114 |   0.074\n",
      "        0 | 1951 |   0.704 |  0.132 |  0.114 |   0.121\n",
      "        9 |  200 |   0.695 |  0.014 |  0.111 |   0.072\n",
      "        1 |  200 |   0.694 |  0.014 |  0.111 |   0.072\n",
      "        7 |   50 |   0.411 |  0.003 |  0.044 |   0.028\n",
      "        4 |   50 |   0.326 |  0.003 |  0.024 |   0.016\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 18.49% accuracy, 2.6681 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 18.49%\n",
      "   Best Accuracy: 18.49%\n",
      "   avg_filter_rate: 0.000\n",
      "   max_filter_rate: 0.000\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 5/8\n",
      "   Learning Rate: 0.01\n",
      "   Extreme Type: poison\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'poison':\n",
      "   40% pristine, 20% degraded, 40% POISONED (90% wrong labels)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_poison_lr0.01_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  POISON: 6 clients\n",
      "  PRISTINE: 6 clients\n",
      "  DEGRADED: 3 clients\n",
      "   💀 Client 0 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 1 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 2 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 3 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 4 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 5 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 6 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 7 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 8 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 9 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 10 (poison): POISON: 95% wrong labels (attack simulation)\n",
      "   💀 Client 11 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 12 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 13 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 14 (pristine): PRISTINE: No corruption\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.050 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   DEGRADED: 3 clients (avg score: 0.450)\n",
      "   POISON: 6 clients (avg score: 0.050)\n",
      "   PRISTINE: 6 clients (avg score: 0.980)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs POISON\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 5: POISON (score: 0.050)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0143\n",
      "     Epoch 2: Loss = 1.7996\n",
      "   ✅ Training complete. Final avg loss: 1.9069\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3026\n",
      "     Epoch 2: Loss = 2.3005\n",
      "   ✅ Training complete. Final avg loss: 2.3016\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3015\n",
      "     Epoch 2: Loss = 2.2979\n",
      "   ✅ Training complete. Final avg loss: 2.2997\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0454\n",
      "     Epoch 2: Loss = 1.9025\n",
      "   ✅ Training complete. Final avg loss: 1.9740\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8124\n",
      "     Epoch 2: Loss = 1.4874\n",
      "   ✅ Training complete. Final avg loss: 1.6499\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7826\n",
      "     Epoch 2: Loss = 1.5998\n",
      "   ✅ Training complete. Final avg loss: 1.6912\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4336\n",
      "     Epoch 2: Loss = 1.1443\n",
      "   ✅ Training complete. Final avg loss: 1.2889\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9693\n",
      "     Epoch 2: Loss = 1.8736\n",
      "   ✅ Training complete. Final avg loss: 1.9214\n",
      "🔧 Training Client 5 (poison):\n",
      "   Samples: 5173, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3005\n",
      "     Epoch 2: Loss = 2.2991\n",
      "   ✅ Training complete. Final avg loss: 2.2998\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3029\n",
      "     Epoch 2: Loss = 2.3028\n",
      "   ✅ Training complete. Final avg loss: 2.3028\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1695, Weight=0.0461, Quality=pristine\n",
      "  Client 1: Size=5254, Weight=0.1430, Quality=poison\n",
      "  Client 2: Size=2334, Weight=0.0635, Quality=poison\n",
      "  Client 3: Size=9373, Weight=0.2551, Quality=degraded\n",
      "  Client 4: Size=1865, Weight=0.0507, Quality=pristine\n",
      "  Client 5: Size=2437, Weight=0.0663, Quality=pristine\n",
      "  Client 6: Size=2926, Weight=0.0796, Quality=pristine\n",
      "  Client 7: Size=3563, Weight=0.0970, Quality=degraded\n",
      "  Client 8: Size=5173, Weight=0.1408, Quality=poison\n",
      "  Client 9: Size=2129, Weight=0.0579, Quality=poison\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.49% accuracy, 2.2647 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9833\n",
      "     Epoch 2: Loss = 1.8744\n",
      "   ✅ Training complete. Final avg loss: 1.9288\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3054\n",
      "     Epoch 2: Loss = 2.3016\n",
      "   ✅ Training complete. Final avg loss: 2.3035\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3083\n",
      "     Epoch 2: Loss = 2.3036\n",
      "   ✅ Training complete. Final avg loss: 2.3059\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3015\n",
      "     Epoch 2: Loss = 2.2988\n",
      "   ✅ Training complete. Final avg loss: 2.3001\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9486\n",
      "     Epoch 2: Loss = 1.8475\n",
      "   ✅ Training complete. Final avg loss: 1.8980\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3043\n",
      "     Epoch 2: Loss = 2.3011\n",
      "   ✅ Training complete. Final avg loss: 2.3027\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3634\n",
      "     Epoch 2: Loss = 1.1337\n",
      "   ✅ Training complete. Final avg loss: 1.2485\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9390\n",
      "     Epoch 2: Loss = 1.7660\n",
      "   ✅ Training complete. Final avg loss: 1.8525\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7171\n",
      "     Epoch 2: Loss = 1.5501\n",
      "   ✅ Training complete. Final avg loss: 1.6336\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7121\n",
      "     Epoch 2: Loss = 1.4691\n",
      "   ✅ Training complete. Final avg loss: 1.5906\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4984, Weight=0.1381, Quality=pristine\n",
      "  Client 1: Size=2212, Weight=0.0613, Quality=poison\n",
      "  Client 2: Size=2129, Weight=0.0590, Quality=poison\n",
      "  Client 3: Size=3221, Weight=0.0892, Quality=poison\n",
      "  Client 4: Size=9373, Weight=0.2597, Quality=degraded\n",
      "  Client 5: Size=5254, Weight=0.1456, Quality=poison\n",
      "  Client 6: Size=2926, Weight=0.0811, Quality=pristine\n",
      "  Client 7: Size=1695, Weight=0.0470, Quality=pristine\n",
      "  Client 8: Size=2437, Weight=0.0675, Quality=pristine\n",
      "  Client 9: Size=1865, Weight=0.0517, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 20.93% accuracy, 2.1548 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 5: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3033\n",
      "     Epoch 2: Loss = 2.2996\n",
      "   ✅ Training complete. Final avg loss: 2.3014\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3091\n",
      "     Epoch 2: Loss = 2.3019\n",
      "   ✅ Training complete. Final avg loss: 2.3055\n",
      "🔧 Training Client 5 (poison):\n",
      "   Samples: 5173, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3079\n",
      "     Epoch 2: Loss = 2.3003\n",
      "   ✅ Training complete. Final avg loss: 2.3041\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2737\n",
      "     Epoch 2: Loss = 1.0766\n",
      "   ✅ Training complete. Final avg loss: 1.1752\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8871\n",
      "     Epoch 2: Loss = 1.8242\n",
      "   ✅ Training complete. Final avg loss: 1.8556\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8568\n",
      "     Epoch 2: Loss = 1.6602\n",
      "   ✅ Training complete. Final avg loss: 1.7585\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5897\n",
      "     Epoch 2: Loss = 1.3724\n",
      "   ✅ Training complete. Final avg loss: 1.4811\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0472\n",
      "     Epoch 2: Loss = 1.8376\n",
      "   ✅ Training complete. Final avg loss: 1.9424\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8827\n",
      "     Epoch 2: Loss = 1.7905\n",
      "   ✅ Training complete. Final avg loss: 1.8366\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 2305, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9809\n",
      "     Epoch 2: Loss = 1.8153\n",
      "   ✅ Training complete. Final avg loss: 1.8981\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=3221, Weight=0.0863, Quality=poison\n",
      "  Client 1: Size=5254, Weight=0.1408, Quality=poison\n",
      "  Client 2: Size=5173, Weight=0.1386, Quality=poison\n",
      "  Client 3: Size=2926, Weight=0.0784, Quality=pristine\n",
      "  Client 4: Size=9373, Weight=0.2511, Quality=degraded\n",
      "  Client 5: Size=1695, Weight=0.0454, Quality=pristine\n",
      "  Client 6: Size=1865, Weight=0.0500, Quality=pristine\n",
      "  Client 7: Size= 529, Weight=0.0142, Quality=pristine\n",
      "  Client 8: Size=4984, Weight=0.1335, Quality=pristine\n",
      "  Client 9: Size=2305, Weight=0.0618, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 23.58% accuracy, 2.0962 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9359\n",
      "     Epoch 2: Loss = 1.7468\n",
      "   ✅ Training complete. Final avg loss: 1.8414\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8274\n",
      "     Epoch 2: Loss = 1.7522\n",
      "   ✅ Training complete. Final avg loss: 1.7898\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2131\n",
      "     Epoch 2: Loss = 1.0249\n",
      "   ✅ Training complete. Final avg loss: 1.1190\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5446\n",
      "     Epoch 2: Loss = 1.3626\n",
      "   ✅ Training complete. Final avg loss: 1.4536\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7642\n",
      "     Epoch 2: Loss = 1.5955\n",
      "   ✅ Training complete. Final avg loss: 1.6798\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3284\n",
      "     Epoch 2: Loss = 2.3041\n",
      "   ✅ Training complete. Final avg loss: 2.3163\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3125\n",
      "     Epoch 2: Loss = 2.3018\n",
      "   ✅ Training complete. Final avg loss: 2.3072\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8527\n",
      "     Epoch 2: Loss = 1.7982\n",
      "   ✅ Training complete. Final avg loss: 1.8255\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4793\n",
      "     Epoch 2: Loss = 1.3375\n",
      "   ✅ Training complete. Final avg loss: 1.4084\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3209\n",
      "     Epoch 2: Loss = 2.3027\n",
      "   ✅ Training complete. Final avg loss: 2.3118\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 529, Weight=0.0158, Quality=pristine\n",
      "  Client 1: Size=4984, Weight=0.1492, Quality=pristine\n",
      "  Client 2: Size=2926, Weight=0.0876, Quality=pristine\n",
      "  Client 3: Size=2437, Weight=0.0730, Quality=pristine\n",
      "  Client 4: Size=1695, Weight=0.0507, Quality=pristine\n",
      "  Client 5: Size=2129, Weight=0.0637, Quality=poison\n",
      "  Client 6: Size=5254, Weight=0.1573, Quality=poison\n",
      "  Client 7: Size=9373, Weight=0.2806, Quality=degraded\n",
      "  Client 8: Size=1865, Weight=0.0558, Quality=pristine\n",
      "  Client 9: Size=2212, Weight=0.0662, Quality=poison\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 24.76% accuracy, 2.1257 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3307\n",
      "     Epoch 2: Loss = 2.3008\n",
      "   ✅ Training complete. Final avg loss: 2.3158\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7835\n",
      "     Epoch 2: Loss = 1.7133\n",
      "   ✅ Training complete. Final avg loss: 1.7484\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8109\n",
      "     Epoch 2: Loss = 1.7665\n",
      "   ✅ Training complete. Final avg loss: 1.7887\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3307\n",
      "     Epoch 2: Loss = 2.3032\n",
      "   ✅ Training complete. Final avg loss: 2.3170\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8666\n",
      "     Epoch 2: Loss = 1.6612\n",
      "   ✅ Training complete. Final avg loss: 1.7639\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 2305, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8630\n",
      "     Epoch 2: Loss = 1.7813\n",
      "   ✅ Training complete. Final avg loss: 1.8222\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4076\n",
      "     Epoch 2: Loss = 1.2962\n",
      "   ✅ Training complete. Final avg loss: 1.3519\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8143\n",
      "     Epoch 2: Loss = 1.7444\n",
      "   ✅ Training complete. Final avg loss: 1.7794\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3176\n",
      "     Epoch 2: Loss = 2.3012\n",
      "   ✅ Training complete. Final avg loss: 2.3094\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1524\n",
      "     Epoch 2: Loss = 0.9847\n",
      "   ✅ Training complete. Final avg loss: 1.0686\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2334, Weight=0.0660, Quality=poison\n",
      "  Client 1: Size=4984, Weight=0.1410, Quality=pristine\n",
      "  Client 2: Size=9373, Weight=0.2652, Quality=degraded\n",
      "  Client 3: Size=2212, Weight=0.0626, Quality=poison\n",
      "  Client 4: Size= 529, Weight=0.0150, Quality=pristine\n",
      "  Client 5: Size=2305, Weight=0.0652, Quality=degraded\n",
      "  Client 6: Size=1865, Weight=0.0528, Quality=pristine\n",
      "  Client 7: Size=3563, Weight=0.1008, Quality=degraded\n",
      "  Client 8: Size=5254, Weight=0.1486, Quality=poison\n",
      "  Client 9: Size=2926, Weight=0.0828, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 26.45% accuracy, 2.1163 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 5: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 2305, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8417\n",
      "     Epoch 2: Loss = 1.7469\n",
      "   ✅ Training complete. Final avg loss: 1.7943\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3153\n",
      "     Epoch 2: Loss = 2.2993\n",
      "   ✅ Training complete. Final avg loss: 2.3073\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3327\n",
      "     Epoch 2: Loss = 2.3009\n",
      "   ✅ Training complete. Final avg loss: 2.3168\n",
      "🔧 Training Client 5 (poison):\n",
      "   Samples: 5173, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3183\n",
      "     Epoch 2: Loss = 2.3011\n",
      "   ✅ Training complete. Final avg loss: 2.3097\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4273\n",
      "     Epoch 2: Loss = 1.2569\n",
      "   ✅ Training complete. Final avg loss: 1.3421\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7911\n",
      "     Epoch 2: Loss = 1.6417\n",
      "   ✅ Training complete. Final avg loss: 1.7164\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7844\n",
      "     Epoch 2: Loss = 1.7204\n",
      "   ✅ Training complete. Final avg loss: 1.7524\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7844\n",
      "     Epoch 2: Loss = 1.7282\n",
      "   ✅ Training complete. Final avg loss: 1.7563\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7519\n",
      "     Epoch 2: Loss = 1.6533\n",
      "   ✅ Training complete. Final avg loss: 1.7026\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3200\n",
      "     Epoch 2: Loss = 2.3018\n",
      "   ✅ Training complete. Final avg loss: 2.3109\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2305, Weight=0.0597, Quality=degraded\n",
      "  Client 1: Size=3221, Weight=0.0834, Quality=poison\n",
      "  Client 2: Size=2334, Weight=0.0605, Quality=poison\n",
      "  Client 3: Size=5173, Weight=0.1340, Quality=poison\n",
      "  Client 4: Size=1865, Weight=0.0483, Quality=pristine\n",
      "  Client 5: Size= 529, Weight=0.0137, Quality=pristine\n",
      "  Client 6: Size=3563, Weight=0.0923, Quality=degraded\n",
      "  Client 7: Size=9373, Weight=0.2428, Quality=degraded\n",
      "  Client 8: Size=4984, Weight=0.1291, Quality=pristine\n",
      "  Client 9: Size=5254, Weight=0.1361, Quality=poison\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 28.18% accuracy, 2.0213 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8008\n",
      "     Epoch 2: Loss = 1.6208\n",
      "   ✅ Training complete. Final avg loss: 1.7108\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4228\n",
      "     Epoch 2: Loss = 1.2596\n",
      "   ✅ Training complete. Final avg loss: 1.3412\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3242\n",
      "     Epoch 2: Loss = 2.3022\n",
      "   ✅ Training complete. Final avg loss: 2.3132\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.0981\n",
      "     Epoch 2: Loss = 0.8935\n",
      "   ✅ Training complete. Final avg loss: 0.9958\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3321\n",
      "     Epoch 2: Loss = 2.3051\n",
      "   ✅ Training complete. Final avg loss: 2.3186\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6733\n",
      "     Epoch 2: Loss = 1.5172\n",
      "   ✅ Training complete. Final avg loss: 1.5952\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3237\n",
      "     Epoch 2: Loss = 2.3025\n",
      "   ✅ Training complete. Final avg loss: 2.3131\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3115\n",
      "     Epoch 2: Loss = 2.2983\n",
      "   ✅ Training complete. Final avg loss: 2.3049\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4089\n",
      "     Epoch 2: Loss = 1.2601\n",
      "   ✅ Training complete. Final avg loss: 1.3345\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3119\n",
      "     Epoch 2: Loss = 2.3018\n",
      "   ✅ Training complete. Final avg loss: 2.3068\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 529, Weight=0.0215, Quality=pristine\n",
      "  Client 1: Size=1865, Weight=0.0758, Quality=pristine\n",
      "  Client 2: Size=2212, Weight=0.0899, Quality=poison\n",
      "  Client 3: Size=2926, Weight=0.1189, Quality=pristine\n",
      "  Client 4: Size=2129, Weight=0.0865, Quality=poison\n",
      "  Client 5: Size=1695, Weight=0.0689, Quality=pristine\n",
      "  Client 6: Size=2334, Weight=0.0949, Quality=poison\n",
      "  Client 7: Size=3221, Weight=0.1309, Quality=poison\n",
      "  Client 8: Size=2437, Weight=0.0991, Quality=pristine\n",
      "  Client 9: Size=5254, Weight=0.2136, Quality=poison\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 27.04% accuracy, 2.0285 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7823\n",
      "     Epoch 2: Loss = 1.6861\n",
      "   ✅ Training complete. Final avg loss: 1.7342\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4332\n",
      "     Epoch 2: Loss = 1.2535\n",
      "   ✅ Training complete. Final avg loss: 1.3434\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7050\n",
      "     Epoch 2: Loss = 1.5933\n",
      "   ✅ Training complete. Final avg loss: 1.6492\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.0941\n",
      "     Epoch 2: Loss = 0.8719\n",
      "   ✅ Training complete. Final avg loss: 0.9830\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3028\n",
      "     Epoch 2: Loss = 2.2977\n",
      "   ✅ Training complete. Final avg loss: 2.3002\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7562\n",
      "     Epoch 2: Loss = 1.6898\n",
      "   ✅ Training complete. Final avg loss: 1.7230\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7180\n",
      "     Epoch 2: Loss = 1.5146\n",
      "   ✅ Training complete. Final avg loss: 1.6163\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4610\n",
      "     Epoch 2: Loss = 1.2636\n",
      "   ✅ Training complete. Final avg loss: 1.3623\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3150\n",
      "     Epoch 2: Loss = 2.3038\n",
      "   ✅ Training complete. Final avg loss: 2.3094\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3058\n",
      "     Epoch 2: Loss = 2.3007\n",
      "   ✅ Training complete. Final avg loss: 2.3033\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   poison scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=3563, Weight=0.0951, Quality=degraded\n",
      "  Client 1: Size=2437, Weight=0.0651, Quality=pristine\n",
      "  Client 2: Size=4984, Weight=0.1331, Quality=pristine\n",
      "  Client 3: Size=2926, Weight=0.0781, Quality=pristine\n",
      "  Client 4: Size=3221, Weight=0.0860, Quality=poison\n",
      "  Client 5: Size=9373, Weight=0.2503, Quality=degraded\n",
      "  Client 6: Size=1695, Weight=0.0453, Quality=pristine\n",
      "  Client 7: Size=1865, Weight=0.0498, Quality=pristine\n",
      "  Client 8: Size=2129, Weight=0.0569, Quality=poison\n",
      "  Client 9: Size=5254, Weight=0.1403, Quality=poison\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 25.63% accuracy, 2.4128 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 25.63%\n",
      "   Best Accuracy: 28.18%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs POISON\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'poison':\n",
      "   Quality threshold: 0.400\n",
      "   Minimum clients ratio: 30.0%\n",
      "   Harm detection threshold: 0.100\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 5: POISON (score: 0.050)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0143\n",
      "     Epoch 2: Loss = 1.7996\n",
      "   ✅ Training complete. Final avg loss: 1.9069\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3026\n",
      "     Epoch 2: Loss = 2.3005\n",
      "   ✅ Training complete. Final avg loss: 2.3016\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3015\n",
      "     Epoch 2: Loss = 2.2979\n",
      "   ✅ Training complete. Final avg loss: 2.2997\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0454\n",
      "     Epoch 2: Loss = 1.9032\n",
      "   ✅ Training complete. Final avg loss: 1.9743\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8124\n",
      "     Epoch 2: Loss = 1.4874\n",
      "   ✅ Training complete. Final avg loss: 1.6499\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7826\n",
      "     Epoch 2: Loss = 1.5998\n",
      "   ✅ Training complete. Final avg loss: 1.6912\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4336\n",
      "     Epoch 2: Loss = 1.1443\n",
      "   ✅ Training complete. Final avg loss: 1.2889\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9693\n",
      "     Epoch 2: Loss = 1.8736\n",
      "   ✅ Training complete. Final avg loss: 1.9214\n",
      "🔧 Training Client 5 (poison):\n",
      "   Samples: 5173, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3005\n",
      "     Epoch 2: Loss = 2.2991\n",
      "   ✅ Training complete. Final avg loss: 2.2998\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3029\n",
      "     Epoch 2: Loss = 2.3028\n",
      "   ✅ Training complete. Final avg loss: 2.3028\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.349, Loss=1.792, Loss_std=0.879, Entropy=1.796\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.552\n",
      "      Stability: 0.707, Confidence: 0.281\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.702\n",
      "   ✅ Decision: KEEP (Score 0.702 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.118, Loss=2.301, Loss_std=0.061, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.393, Loss: 0.425\n",
      "      Stability: 0.980, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.267\n",
      "   ❌ Decision: FILTER (Score 0.267 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.091, Loss=2.295, Loss_std=0.076, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.304, Loss: 0.426\n",
      "      Stability: 0.975, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.252\n",
      "   ❌ Decision: FILTER (Score 0.252 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.392, Loss=1.877, Loss_std=0.945, Entropy=1.888\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.531\n",
      "      Stability: 0.685, Confidence: 0.245\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.633\n",
      "   ✅ Decision: KEEP (Score 0.633 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.567, Loss=1.442, Loss_std=1.137, Entropy=1.433\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.639\n",
      "      Stability: 0.621, Confidence: 0.427\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.457, Loss=1.613, Loss_std=0.913, Entropy=1.665\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.597\n",
      "      Stability: 0.696, Confidence: 0.334\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.719\n",
      "   ✅ Decision: KEEP (Score 0.719 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.599, Loss=1.135, Loss_std=1.103, Entropy=1.176\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.716\n",
      "      Stability: 0.632, Confidence: 0.530\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.767\n",
      "   ✅ Decision: KEEP (Score 0.767 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.363, Loss=1.862, Loss_std=0.842, Entropy=1.877\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.534\n",
      "      Stability: 0.719, Confidence: 0.249\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.642\n",
      "   ✅ Decision: KEEP (Score 0.642 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.296, Loss_std=0.078, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.426\n",
      "      Stability: 0.974, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.262\n",
      "   ❌ Decision: FILTER (Score 0.262 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.301, Loss_std=0.044, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.425\n",
      "      Stability: 0.985, Confidence: 0.079\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ❌ Decision: FILTER (Score 0.266 < threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.767 |    2926 | KEEP     | Score 0.767 ≥ threshold 0.400\n",
      "      2 |      4 |  0.980 |     0.728 |    1865 | KEEP     | Score 0.728 ≥ threshold 0.400\n",
      "      3 |      5 |  0.980 |     0.719 |    2437 | KEEP     | Score 0.719 ≥ threshold 0.400\n",
      "      4 |      0 |  0.980 |     0.702 |    1695 | KEEP     | Score 0.702 ≥ threshold 0.400\n",
      "      5 |      7 |  0.450 |     0.642 |    3563 | KEEP     | Score 0.642 ≥ threshold 0.400\n",
      "      6 |      3 |  0.450 |     0.633 |    9373 | KEEP     | Score 0.633 ≥ threshold 0.400\n",
      "      7 |      1 |  0.050 |     0.267 |    5254 | FILTER   | Score 0.267 < threshold 0.400\n",
      "      8 |      9 |  0.050 |     0.266 |    2129 | FILTER   | Score 0.266 < threshold 0.400\n",
      "      9 |      8 |  0.050 |     0.262 |    5173 | FILTER   | Score 0.262 < threshold 0.400\n",
      "     10 |      2 |  0.050 |     0.252 |    2334 | FILTER   | Score 0.252 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [6, 4, 5, 0, 7, 3])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.698\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 2926 |   0.767 |  0.134 |  0.235 |   0.225\n",
      "        4 | 1865 |   0.728 |  0.085 |  0.197 |   0.186\n",
      "        5 | 2437 |   0.719 |  0.111 |  0.187 |   0.180\n",
      "        0 | 1695 |   0.702 |  0.078 |  0.170 |   0.161\n",
      "        7 | 3563 |   0.642 |  0.163 |  0.110 |   0.115\n",
      "        3 | 9373 |   0.633 |  0.429 |  0.101 |   0.133\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 11.43% accuracy, 2.3199 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9955\n",
      "     Epoch 2: Loss = 1.9208\n",
      "   ✅ Training complete. Final avg loss: 1.9582\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3126\n",
      "     Epoch 2: Loss = 2.3020\n",
      "   ✅ Training complete. Final avg loss: 2.3073\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3172\n",
      "     Epoch 2: Loss = 2.3059\n",
      "   ✅ Training complete. Final avg loss: 2.3116\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3038\n",
      "     Epoch 2: Loss = 2.2991\n",
      "   ✅ Training complete. Final avg loss: 2.3014\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9918\n",
      "     Epoch 2: Loss = 1.8651\n",
      "   ✅ Training complete. Final avg loss: 1.9285\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3091\n",
      "     Epoch 2: Loss = 2.3023\n",
      "   ✅ Training complete. Final avg loss: 2.3057\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2640\n",
      "     Epoch 2: Loss = 1.1210\n",
      "   ✅ Training complete. Final avg loss: 1.1925\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8833\n",
      "     Epoch 2: Loss = 1.7737\n",
      "   ✅ Training complete. Final avg loss: 1.8285\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6686\n",
      "     Epoch 2: Loss = 1.5654\n",
      "   ✅ Training complete. Final avg loss: 1.6170\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6491\n",
      "     Epoch 2: Loss = 1.4778\n",
      "   ✅ Training complete. Final avg loss: 1.5635\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.267, Loss=1.901, Loss_std=0.766, Entropy=1.889\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.889, Loss: 0.525\n",
      "      Stability: 0.745, Confidence: 0.244\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.668\n",
      "   ✅ Decision: KEEP (Score 0.668 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.301, Loss_std=0.090, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.425\n",
      "      Stability: 0.970, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.270\n",
      "   ❌ Decision: FILTER (Score 0.270 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.301, Loss_std=0.056, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.425\n",
      "      Stability: 0.981, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.271\n",
      "   ❌ Decision: FILTER (Score 0.271 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.299, Loss_std=0.113, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.425\n",
      "      Stability: 0.962, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.406, Loss=1.780, Loss_std=0.844, Entropy=1.919\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.555\n",
      "      Stability: 0.719, Confidence: 0.232\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.643\n",
      "   ✅ Decision: KEEP (Score 0.643 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.106, Loss=2.296, Loss_std=0.058, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.353, Loss: 0.426\n",
      "      Stability: 0.981, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.637, Loss=1.099, Loss_std=1.293, Entropy=1.006\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.725\n",
      "      Stability: 0.569, Confidence: 0.598\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.767\n",
      "   ✅ Decision: KEEP (Score 0.767 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.413, Loss=1.701, Loss_std=0.769, Entropy=1.871\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.575\n",
      "      Stability: 0.744, Confidence: 0.252\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.524, Loss=1.528, Loss_std=0.845, Entropy=1.693\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.618\n",
      "      Stability: 0.718, Confidence: 0.323\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.550, Loss=1.429, Loss_std=1.082, Entropy=1.453\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.643\n",
      "      Stability: 0.639, Confidence: 0.419\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.732\n",
      "   ✅ Decision: KEEP (Score 0.732 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.767 |    2926 | KEEP     | Score 0.767 ≥ threshold 0.400\n",
      "      2 |      9 |  0.980 |     0.732 |    1865 | KEEP     | Score 0.732 ≥ threshold 0.400\n",
      "      3 |      8 |  0.980 |     0.727 |    2437 | KEEP     | Score 0.727 ≥ threshold 0.400\n",
      "      4 |      7 |  0.980 |     0.710 |    1695 | KEEP     | Score 0.710 ≥ threshold 0.400\n",
      "      5 |      0 |  0.980 |     0.668 |    4984 | KEEP     | Score 0.668 ≥ threshold 0.400\n",
      "      6 |      4 |  0.450 |     0.643 |    9373 | KEEP     | Score 0.643 ≥ threshold 0.400\n",
      "      7 |      2 |  0.050 |     0.271 |    2129 | FILTER   | Score 0.271 < threshold 0.400\n",
      "      8 |      1 |  0.050 |     0.270 |    2212 | FILTER   | Score 0.270 < threshold 0.400\n",
      "      9 |      3 |  0.050 |     0.261 |    3221 | FILTER   | Score 0.261 < threshold 0.400\n",
      "     10 |      5 |  0.050 |     0.261 |    5254 | FILTER   | Score 0.261 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [6, 9, 8, 7, 0, 4])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.708\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 2926 |   0.767 |  0.126 |  0.227 |   0.216\n",
      "        9 | 1865 |   0.732 |  0.080 |  0.191 |   0.180\n",
      "        8 | 2437 |   0.727 |  0.105 |  0.186 |   0.178\n",
      "        7 | 1695 |   0.710 |  0.073 |  0.169 |   0.159\n",
      "        0 | 4984 |   0.668 |  0.214 |  0.126 |   0.135\n",
      "        4 | 9373 |   0.643 |  0.403 |  0.101 |   0.132\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 16.88% accuracy, 2.2984 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 5: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3118\n",
      "     Epoch 2: Loss = 2.3017\n",
      "   ✅ Training complete. Final avg loss: 2.3068\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3155\n",
      "     Epoch 2: Loss = 2.3030\n",
      "   ✅ Training complete. Final avg loss: 2.3092\n",
      "🔧 Training Client 5 (poison):\n",
      "   Samples: 5173, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3129\n",
      "     Epoch 2: Loss = 2.3008\n",
      "   ✅ Training complete. Final avg loss: 2.3069\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2047\n",
      "     Epoch 2: Loss = 1.0958\n",
      "   ✅ Training complete. Final avg loss: 1.1502\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9305\n",
      "     Epoch 2: Loss = 1.8499\n",
      "   ✅ Training complete. Final avg loss: 1.8902\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8161\n",
      "     Epoch 2: Loss = 1.7052\n",
      "   ✅ Training complete. Final avg loss: 1.7606\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5411\n",
      "     Epoch 2: Loss = 1.4080\n",
      "   ✅ Training complete. Final avg loss: 1.4746\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0373\n",
      "     Epoch 2: Loss = 1.8602\n",
      "   ✅ Training complete. Final avg loss: 1.9487\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9320\n",
      "     Epoch 2: Loss = 1.8365\n",
      "   ✅ Training complete. Final avg loss: 1.8842\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 2305, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0147\n",
      "     Epoch 2: Loss = 1.8939\n",
      "   ✅ Training complete. Final avg loss: 1.9543\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.094, Loss=2.295, Loss_std=0.118, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.312, Loss: 0.426\n",
      "      Stability: 0.961, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.252\n",
      "   ❌ Decision: FILTER (Score 0.252 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.297, Loss_std=0.057, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.426\n",
      "      Stability: 0.981, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ❌ Decision: FILTER (Score 0.266 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.298, Loss_std=0.108, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.425\n",
      "      Stability: 0.964, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ❌ Decision: FILTER (Score 0.260 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.591, Loss=1.112, Loss_std=0.977, Entropy=1.283\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.722\n",
      "      Stability: 0.674, Confidence: 0.487\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.770\n",
      "   ✅ Decision: KEEP (Score 0.770 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.380, Loss=1.822, Loss_std=0.971, Entropy=1.819\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.545\n",
      "      Stability: 0.676, Confidence: 0.272\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.639\n",
      "   ✅ Decision: KEEP (Score 0.639 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.433, Loss=1.610, Loss_std=0.934, Entropy=1.650\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.597\n",
      "      Stability: 0.689, Confidence: 0.340\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.719\n",
      "   ✅ Decision: KEEP (Score 0.719 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.572, Loss=1.400, Loss_std=1.363, Entropy=1.160\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.650\n",
      "      Stability: 0.546, Confidence: 0.536\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.734\n",
      "   ✅ Decision: KEEP (Score 0.734 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.488, Loss=1.773, Loss_std=0.885, Entropy=1.915\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.705, Confidence: 0.234\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.694\n",
      "   ✅ Decision: KEEP (Score 0.694 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.327, Loss=1.799, Loss_std=0.674, Entropy=1.892\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.550\n",
      "      Stability: 0.775, Confidence: 0.243\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.358, Loss=1.834, Loss_std=0.879, Entropy=1.858\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.542\n",
      "      Stability: 0.707, Confidence: 0.257\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.642\n",
      "   ✅ Decision: KEEP (Score 0.642 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.770 |    2926 | KEEP     | Score 0.770 ≥ threshold 0.400\n",
      "      2 |      6 |  0.980 |     0.734 |    1865 | KEEP     | Score 0.734 ≥ threshold 0.400\n",
      "      3 |      5 |  0.980 |     0.719 |    1695 | KEEP     | Score 0.719 ≥ threshold 0.400\n",
      "      4 |      8 |  0.980 |     0.710 |    4984 | KEEP     | Score 0.710 ≥ threshold 0.400\n",
      "      5 |      7 |  0.980 |     0.694 |     529 | KEEP     | Score 0.694 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.642 |    2305 | KEEP     | Score 0.642 ≥ threshold 0.400\n",
      "      7 |      4 |  0.450 |     0.639 |    9373 | KEEP     | Score 0.639 ≥ threshold 0.400\n",
      "      8 |      1 |  0.050 |     0.266 |    5254 | FILTER   | Score 0.266 < threshold 0.400\n",
      "      9 |      2 |  0.050 |     0.260 |    5173 | FILTER   | Score 0.260 < threshold 0.400\n",
      "     10 |      0 |  0.050 |     0.252 |    3221 | FILTER   | Score 0.252 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 7 (IDs: [3, 6, 5, 8, 7, 9, 4])\n",
      "   Filter rate: 30.0%\n",
      "   Average quality score: 0.701\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 2926 |   0.770 |  0.124 |  0.203 |   0.195\n",
      "        6 | 1865 |   0.734 |  0.079 |  0.172 |   0.162\n",
      "        5 | 1695 |   0.719 |  0.072 |  0.158 |   0.150\n",
      "        8 | 4984 |   0.710 |  0.210 |  0.151 |   0.157\n",
      "        7 |  529 |   0.694 |  0.022 |  0.137 |   0.125\n",
      "        9 | 2305 |   0.642 |  0.097 |  0.091 |   0.092\n",
      "        4 | 9373 |   0.639 |  0.396 |  0.088 |   0.119\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 20.17% accuracy, 2.2778 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8729\n",
      "     Epoch 2: Loss = 1.7449\n",
      "   ✅ Training complete. Final avg loss: 1.8089\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8608\n",
      "     Epoch 2: Loss = 1.7842\n",
      "   ✅ Training complete. Final avg loss: 1.8225\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1581\n",
      "     Epoch 2: Loss = 1.0580\n",
      "   ✅ Training complete. Final avg loss: 1.1081\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5416\n",
      "     Epoch 2: Loss = 1.3796\n",
      "   ✅ Training complete. Final avg loss: 1.4606\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7509\n",
      "     Epoch 2: Loss = 1.6429\n",
      "   ✅ Training complete. Final avg loss: 1.6969\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3514\n",
      "     Epoch 2: Loss = 2.3081\n",
      "   ✅ Training complete. Final avg loss: 2.3298\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3245\n",
      "     Epoch 2: Loss = 2.3034\n",
      "   ✅ Training complete. Final avg loss: 2.3140\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8944\n",
      "     Epoch 2: Loss = 1.8293\n",
      "   ✅ Training complete. Final avg loss: 1.8619\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4400\n",
      "     Epoch 2: Loss = 1.3330\n",
      "   ✅ Training complete. Final avg loss: 1.3865\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3423\n",
      "     Epoch 2: Loss = 2.3065\n",
      "   ✅ Training complete. Final avg loss: 2.3244\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.476, Loss=1.725, Loss_std=0.899, Entropy=1.893\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.569\n",
      "      Stability: 0.700, Confidence: 0.243\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.697\n",
      "   ✅ Decision: KEEP (Score 0.697 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.322, Loss=1.757, Loss_std=0.756, Entropy=1.795\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.561\n",
      "      Stability: 0.748, Confidence: 0.282\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.713\n",
      "   ✅ Decision: KEEP (Score 0.713 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.673, Loss=1.004, Loss_std=1.125, Entropy=1.111\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.749\n",
      "      Stability: 0.625, Confidence: 0.556\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.777\n",
      "   ✅ Decision: KEEP (Score 0.777 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.402, Loss_std=1.144, Entropy=1.356\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.649\n",
      "      Stability: 0.619, Confidence: 0.457\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.736\n",
      "   ✅ Decision: KEEP (Score 0.736 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.387, Loss=1.558, Loss_std=0.926, Entropy=1.650\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.610\n",
      "      Stability: 0.691, Confidence: 0.340\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.305, Loss_std=0.079, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.424\n",
      "      Stability: 0.974, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.265\n",
      "   ❌ Decision: FILTER (Score 0.265 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.132, Loss=2.301, Loss_std=0.100, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.441, Loss: 0.425\n",
      "      Stability: 0.967, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.273\n",
      "   ❌ Decision: FILTER (Score 0.273 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.392, Loss=1.809, Loss_std=1.057, Entropy=1.747\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.548\n",
      "      Stability: 0.648, Confidence: 0.301\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.638\n",
      "   ✅ Decision: KEEP (Score 0.638 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.572, Loss=1.307, Loss_std=1.302, Entropy=1.174\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.673\n",
      "      Stability: 0.566, Confidence: 0.530\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.742\n",
      "   ✅ Decision: KEEP (Score 0.742 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.309, Loss_std=0.115, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.423\n",
      "      Stability: 0.962, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ❌ Decision: FILTER (Score 0.260 < threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      2 |  0.980 |     0.777 |    2926 | KEEP     | Score 0.777 ≥ threshold 0.400\n",
      "      2 |      8 |  0.980 |     0.742 |    1865 | KEEP     | Score 0.742 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.736 |    2437 | KEEP     | Score 0.736 ≥ threshold 0.400\n",
      "      4 |      4 |  0.980 |     0.722 |    1695 | KEEP     | Score 0.722 ≥ threshold 0.400\n",
      "      5 |      1 |  0.980 |     0.713 |    4984 | KEEP     | Score 0.713 ≥ threshold 0.400\n",
      "      6 |      0 |  0.980 |     0.697 |     529 | KEEP     | Score 0.697 ≥ threshold 0.400\n",
      "      7 |      7 |  0.450 |     0.638 |    9373 | KEEP     | Score 0.638 ≥ threshold 0.400\n",
      "      8 |      6 |  0.050 |     0.273 |    5254 | FILTER   | Score 0.273 < threshold 0.400\n",
      "      9 |      5 |  0.050 |     0.265 |    2129 | FILTER   | Score 0.265 < threshold 0.400\n",
      "     10 |      9 |  0.050 |     0.260 |    2212 | FILTER   | Score 0.260 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 7 (IDs: [2, 8, 3, 4, 1, 0, 7])\n",
      "   Filter rate: 30.0%\n",
      "   Average quality score: 0.718\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        2 | 2926 |   0.777 |  0.123 |  0.190 |   0.183\n",
      "        8 | 1865 |   0.742 |  0.078 |  0.162 |   0.154\n",
      "        3 | 2437 |   0.736 |  0.102 |  0.157 |   0.151\n",
      "        4 | 1695 |   0.722 |  0.071 |  0.146 |   0.139\n",
      "        1 | 4984 |   0.713 |  0.209 |  0.139 |   0.146\n",
      "        0 |  529 |   0.697 |  0.022 |  0.126 |   0.116\n",
      "        7 | 9373 |   0.638 |  0.394 |  0.079 |   0.111\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 22.05% accuracy, 2.4676 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3861\n",
      "     Epoch 2: Loss = 2.3045\n",
      "   ✅ Training complete. Final avg loss: 2.3453\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8095\n",
      "     Epoch 2: Loss = 1.7401\n",
      "   ✅ Training complete. Final avg loss: 1.7748\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8523\n",
      "     Epoch 2: Loss = 1.8013\n",
      "   ✅ Training complete. Final avg loss: 1.8268\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3904\n",
      "     Epoch 2: Loss = 2.3067\n",
      "   ✅ Training complete. Final avg loss: 2.3485\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7770\n",
      "     Epoch 2: Loss = 1.6802\n",
      "   ✅ Training complete. Final avg loss: 1.7286\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 2305, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8847\n",
      "     Epoch 2: Loss = 1.8158\n",
      "   ✅ Training complete. Final avg loss: 1.8502\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4021\n",
      "     Epoch 2: Loss = 1.3079\n",
      "   ✅ Training complete. Final avg loss: 1.3550\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8006\n",
      "     Epoch 2: Loss = 1.7616\n",
      "   ✅ Training complete. Final avg loss: 1.7811\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3401\n",
      "     Epoch 2: Loss = 2.3037\n",
      "   ✅ Training complete. Final avg loss: 2.3219\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1194\n",
      "     Epoch 2: Loss = 0.9944\n",
      "   ✅ Training complete. Final avg loss: 1.0569\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.106, Loss=2.301, Loss_std=0.143, Entropy=2.293\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.353, Loss: 0.425\n",
      "      Stability: 0.952, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.257\n",
      "   ❌ Decision: FILTER (Score 0.257 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.430, Loss=1.675, Loss_std=0.947, Entropy=1.673\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.581\n",
      "      Stability: 0.684, Confidence: 0.331\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.712\n",
      "   ✅ Decision: KEEP (Score 0.712 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.404, Loss=1.767, Loss_std=0.839, Entropy=1.914\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.558\n",
      "      Stability: 0.720, Confidence: 0.234\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.645\n",
      "   ✅ Decision: KEEP (Score 0.645 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.091, Loss=2.299, Loss_std=0.098, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.304, Loss: 0.425\n",
      "      Stability: 0.967, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.251\n",
      "   ❌ Decision: FILTER (Score 0.251 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.507, Loss=1.625, Loss_std=1.011, Entropy=1.736\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.594\n",
      "      Stability: 0.663, Confidence: 0.306\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.411, Loss=1.757, Loss_std=0.981, Entropy=1.751\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.561\n",
      "      Stability: 0.673, Confidence: 0.300\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.543, Loss=1.341, Loss_std=1.127, Entropy=1.312\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.665\n",
      "      Stability: 0.624, Confidence: 0.475\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.744\n",
      "   ✅ Decision: KEEP (Score 0.744 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.409, Loss=1.654, Loss_std=1.021, Entropy=1.641\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.586\n",
      "      Stability: 0.660, Confidence: 0.344\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.657\n",
      "   ✅ Decision: KEEP (Score 0.657 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.303, Loss_std=0.069, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.424\n",
      "      Stability: 0.977, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.263\n",
      "   ❌ Decision: FILTER (Score 0.263 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.704, Loss=0.898, Loss_std=1.132, Entropy=0.945\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.776\n",
      "      Stability: 0.623, Confidence: 0.622\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.795\n",
      "   ✅ Decision: KEEP (Score 0.795 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      9 |  0.980 |     0.795 |    2926 | KEEP     | Score 0.795 ≥ threshold 0.400\n",
      "      2 |      6 |  0.980 |     0.744 |    1865 | KEEP     | Score 0.744 ≥ threshold 0.400\n",
      "      3 |      1 |  0.980 |     0.712 |    4984 | KEEP     | Score 0.712 ≥ threshold 0.400\n",
      "      4 |      4 |  0.980 |     0.706 |     529 | KEEP     | Score 0.706 ≥ threshold 0.400\n",
      "      5 |      7 |  0.450 |     0.657 |    3563 | KEEP     | Score 0.657 ≥ threshold 0.400\n",
      "      6 |      5 |  0.450 |     0.647 |    2305 | KEEP     | Score 0.647 ≥ threshold 0.400\n",
      "      7 |      2 |  0.450 |     0.645 |    9373 | KEEP     | Score 0.645 ≥ threshold 0.400\n",
      "      8 |      8 |  0.050 |     0.263 |    5254 | FILTER   | Score 0.263 < threshold 0.400\n",
      "      9 |      0 |  0.050 |     0.257 |    2334 | FILTER   | Score 0.257 < threshold 0.400\n",
      "     10 |      3 |  0.050 |     0.251 |    2212 | FILTER   | Score 0.251 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 7 (IDs: [9, 6, 1, 4, 7, 5, 2])\n",
      "   Filter rate: 30.0%\n",
      "   Average quality score: 0.701\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        9 | 2926 |   0.795 |  0.115 |  0.229 |   0.217\n",
      "        6 | 1865 |   0.744 |  0.073 |  0.182 |   0.171\n",
      "        1 | 4984 |   0.712 |  0.195 |  0.154 |   0.158\n",
      "        4 |  529 |   0.706 |  0.021 |  0.148 |   0.135\n",
      "        7 | 3563 |   0.657 |  0.139 |  0.103 |   0.107\n",
      "        5 | 2305 |   0.647 |  0.090 |  0.093 |   0.093\n",
      "        2 | 9373 |   0.645 |  0.367 |  0.092 |   0.119\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 23.08% accuracy, 2.4940 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 5: POISON (score: 0.050)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 2305, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8408\n",
      "     Epoch 2: Loss = 1.7829\n",
      "   ✅ Training complete. Final avg loss: 1.8119\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3590\n",
      "     Epoch 2: Loss = 2.3007\n",
      "   ✅ Training complete. Final avg loss: 2.3298\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.4263\n",
      "     Epoch 2: Loss = 2.3038\n",
      "   ✅ Training complete. Final avg loss: 2.3651\n",
      "🔧 Training Client 5 (poison):\n",
      "   Samples: 5173, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3468\n",
      "     Epoch 2: Loss = 2.3012\n",
      "   ✅ Training complete. Final avg loss: 2.3240\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3488\n",
      "     Epoch 2: Loss = 1.2896\n",
      "   ✅ Training complete. Final avg loss: 1.3192\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7877\n",
      "     Epoch 2: Loss = 1.6857\n",
      "   ✅ Training complete. Final avg loss: 1.7367\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7872\n",
      "     Epoch 2: Loss = 1.7313\n",
      "   ✅ Training complete. Final avg loss: 1.7593\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8436\n",
      "     Epoch 2: Loss = 1.7858\n",
      "   ✅ Training complete. Final avg loss: 1.8147\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7630\n",
      "     Epoch 2: Loss = 1.6954\n",
      "   ✅ Training complete. Final avg loss: 1.7292\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3508\n",
      "     Epoch 2: Loss = 2.3032\n",
      "   ✅ Training complete. Final avg loss: 2.3270\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.375, Loss=1.804, Loss_std=0.989, Entropy=1.753\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.549\n",
      "      Stability: 0.670, Confidence: 0.299\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.643\n",
      "   ✅ Decision: KEEP (Score 0.643 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.113, Loss=2.299, Loss_std=0.101, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.377, Loss: 0.425\n",
      "      Stability: 0.966, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.263\n",
      "   ❌ Decision: FILTER (Score 0.263 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.291, Loss_std=0.128, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.427\n",
      "      Stability: 0.957, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.271\n",
      "   ❌ Decision: FILTER (Score 0.271 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.118, Loss=2.293, Loss_std=0.090, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.393, Loss: 0.427\n",
      "      Stability: 0.970, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ❌ Decision: FILTER (Score 0.266 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.579, Loss=1.246, Loss_std=1.118, Entropy=1.245\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.689\n",
      "      Stability: 0.627, Confidence: 0.502\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.754\n",
      "   ✅ Decision: KEEP (Score 0.754 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.495, Loss=1.606, Loss_std=0.963, Entropy=1.738\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.598\n",
      "      Stability: 0.679, Confidence: 0.305\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.416, Loss=1.726, Loss_std=1.000, Entropy=1.748\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.568\n",
      "      Stability: 0.667, Confidence: 0.301\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.387, Loss=1.773, Loss_std=0.949, Entropy=1.831\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.557\n",
      "      Stability: 0.684, Confidence: 0.268\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.642\n",
      "   ✅ Decision: KEEP (Score 0.642 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.385, Loss=1.695, Loss_std=0.713, Entropy=1.839\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.576\n",
      "      Stability: 0.762, Confidence: 0.264\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.717\n",
      "   ✅ Decision: KEEP (Score 0.717 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.297, Loss_std=0.053, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.426\n",
      "      Stability: 0.982, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ❌ Decision: FILTER (Score 0.266 < threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.754 |    1865 | KEEP     | Score 0.754 ≥ threshold 0.400\n",
      "      2 |      8 |  0.980 |     0.717 |    4984 | KEEP     | Score 0.717 ≥ threshold 0.400\n",
      "      3 |      5 |  0.980 |     0.710 |     529 | KEEP     | Score 0.710 ≥ threshold 0.400\n",
      "      4 |      6 |  0.450 |     0.647 |    3563 | KEEP     | Score 0.647 ≥ threshold 0.400\n",
      "      5 |      0 |  0.450 |     0.643 |    2305 | KEEP     | Score 0.643 ≥ threshold 0.400\n",
      "      6 |      7 |  0.450 |     0.642 |    9373 | KEEP     | Score 0.642 ≥ threshold 0.400\n",
      "      7 |      2 |  0.050 |     0.271 |    2334 | FILTER   | Score 0.271 < threshold 0.400\n",
      "      8 |      9 |  0.050 |     0.266 |    5254 | FILTER   | Score 0.266 < threshold 0.400\n",
      "      9 |      3 |  0.050 |     0.266 |    5173 | FILTER   | Score 0.266 < threshold 0.400\n",
      "     10 |      1 |  0.050 |     0.263 |    3221 | FILTER   | Score 0.263 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 6 (IDs: [4, 8, 5, 6, 0, 7])\n",
      "   Filter rate: 40.0%\n",
      "   Average quality score: 0.686\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 1865 |   0.754 |  0.082 |  0.247 |   0.230\n",
      "        8 | 4984 |   0.717 |  0.220 |  0.203 |   0.205\n",
      "        5 |  529 |   0.710 |  0.023 |  0.195 |   0.178\n",
      "        6 | 3563 |   0.647 |  0.158 |  0.122 |   0.125\n",
      "        0 | 2305 |   0.643 |  0.102 |  0.117 |   0.116\n",
      "        7 | 9373 |   0.642 |  0.414 |  0.116 |   0.146\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 24.88% accuracy, 2.4273 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 1: POISON (score: 0.050)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 9: POISON (score: 0.050)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 529, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6513\n",
      "     Epoch 2: Loss = 1.6148\n",
      "   ✅ Training complete. Final avg loss: 1.6331\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3306\n",
      "     Epoch 2: Loss = 1.2355\n",
      "   ✅ Training complete. Final avg loss: 1.2830\n",
      "🔧 Training Client 1 (poison):\n",
      "   Samples: 2212, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.4000\n",
      "     Epoch 2: Loss = 2.3069\n",
      "   ✅ Training complete. Final avg loss: 2.3534\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.0790\n",
      "     Epoch 2: Loss = 0.9271\n",
      "   ✅ Training complete. Final avg loss: 1.0031\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.4168\n",
      "     Epoch 2: Loss = 2.3091\n",
      "   ✅ Training complete. Final avg loss: 2.3630\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6556\n",
      "     Epoch 2: Loss = 1.5540\n",
      "   ✅ Training complete. Final avg loss: 1.6048\n",
      "🔧 Training Client 9 (poison):\n",
      "   Samples: 2334, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.4063\n",
      "     Epoch 2: Loss = 2.3029\n",
      "   ✅ Training complete. Final avg loss: 2.3546\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3625\n",
      "     Epoch 2: Loss = 2.3007\n",
      "   ✅ Training complete. Final avg loss: 2.3316\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4005\n",
      "     Epoch 2: Loss = 1.2833\n",
      "   ✅ Training complete. Final avg loss: 1.3419\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3480\n",
      "     Epoch 2: Loss = 2.3036\n",
      "   ✅ Training complete. Final avg loss: 2.3258\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.524, Loss=1.552, Loss_std=0.925, Entropy=1.745\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.612\n",
      "      Stability: 0.692, Confidence: 0.302\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.608, Loss=1.192, Loss_std=1.278, Entropy=1.059\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.702\n",
      "      Stability: 0.574, Confidence: 0.576\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.759\n",
      "   ✅ Decision: KEEP (Score 0.759 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.295, Loss_std=0.104, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.401, Loss: 0.426\n",
      "      Stability: 0.965, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.267\n",
      "   ❌ Decision: FILTER (Score 0.267 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.649, Loss=1.041, Loss_std=1.255, Entropy=0.951\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.740\n",
      "      Stability: 0.582, Confidence: 0.620\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.777\n",
      "   ✅ Decision: KEEP (Score 0.777 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.297, Loss_std=0.068, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.426\n",
      "      Stability: 0.977, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.271\n",
      "   ❌ Decision: FILTER (Score 0.271 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.464, Loss=1.481, Loss_std=0.978, Entropy=1.503\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.630\n",
      "      Stability: 0.674, Confidence: 0.399\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.733\n",
      "   ✅ Decision: KEEP (Score 0.733 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.304, Loss_std=0.134, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.424\n",
      "      Stability: 0.955, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.262\n",
      "   ❌ Decision: FILTER (Score 0.262 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.298, Loss_std=0.108, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.425\n",
      "      Stability: 0.964, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.589, Loss=1.223, Loss_std=0.967, Entropy=1.389\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.694\n",
      "      Stability: 0.678, Confidence: 0.444\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.757\n",
      "   ✅ Decision: KEEP (Score 0.757 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.096, Loss=2.299, Loss_std=0.097, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.321, Loss: 0.425\n",
      "      Stability: 0.968, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.254\n",
      "   ❌ Decision: FILTER (Score 0.254 < threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.777 |    2926 | KEEP     | Score 0.777 ≥ threshold 0.400\n",
      "      2 |      1 |  0.980 |     0.759 |    1865 | KEEP     | Score 0.759 ≥ threshold 0.400\n",
      "      3 |      8 |  0.980 |     0.757 |    2437 | KEEP     | Score 0.757 ≥ threshold 0.400\n",
      "      4 |      5 |  0.980 |     0.733 |    1695 | KEEP     | Score 0.733 ≥ threshold 0.400\n",
      "      5 |      0 |  0.980 |     0.716 |     529 | KEEP     | Score 0.716 ≥ threshold 0.400\n",
      "      6 |      4 |  0.050 |     0.271 |    2129 | FILTER   | Score 0.271 < threshold 0.400\n",
      "      7 |      2 |  0.050 |     0.267 |    2212 | FILTER   | Score 0.267 < threshold 0.400\n",
      "      8 |      6 |  0.050 |     0.262 |    2334 | FILTER   | Score 0.262 < threshold 0.400\n",
      "      9 |      7 |  0.050 |     0.261 |    3221 | FILTER   | Score 0.261 < threshold 0.400\n",
      "     10 |      9 |  0.050 |     0.254 |    5254 | FILTER   | Score 0.254 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 5 (IDs: [3, 1, 8, 5, 0])\n",
      "   Filter rate: 50.0%\n",
      "   Average quality score: 0.748\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 2926 |   0.777 |  0.310 |  0.243 |   0.250\n",
      "        1 | 1865 |   0.759 |  0.197 |  0.216 |   0.214\n",
      "        8 | 2437 |   0.757 |  0.258 |  0.213 |   0.217\n",
      "        5 | 1695 |   0.733 |  0.179 |  0.177 |   0.177\n",
      "        0 |  529 |   0.716 |  0.056 |  0.151 |   0.141\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 23.48% accuracy, 2.6625 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: DEGRADED (score: 0.450)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: POISON (score: 0.050)\n",
      "   Client 2: DEGRADED (score: 0.450)\n",
      "   Client 14: PRISTINE (score: 0.980)\n",
      "   Client 13: PRISTINE (score: 0.980)\n",
      "   Client 8: POISON (score: 0.050)\n",
      "   Client 6: POISON (score: 0.050)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (degraded):\n",
      "   Samples: 3563, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7416\n",
      "     Epoch 2: Loss = 1.6941\n",
      "   ✅ Training complete. Final avg loss: 1.7179\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 2437, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3485\n",
      "     Epoch 2: Loss = 1.2747\n",
      "   ✅ Training complete. Final avg loss: 1.3116\n",
      "🔧 Training Client 7 (pristine):\n",
      "   Samples: 4984, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7036\n",
      "     Epoch 2: Loss = 1.6142\n",
      "   ✅ Training complete. Final avg loss: 1.6589\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 2926, Quality: 0.980\n",
      "     Epoch 1: Loss = 0.9724\n",
      "     Epoch 2: Loss = 0.8750\n",
      "   ✅ Training complete. Final avg loss: 0.9237\n",
      "🔧 Training Client 10 (poison):\n",
      "   Samples: 3221, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3906\n",
      "     Epoch 2: Loss = 2.2998\n",
      "   ✅ Training complete. Final avg loss: 2.3452\n",
      "🔧 Training Client 2 (degraded):\n",
      "   Samples: 9373, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8006\n",
      "     Epoch 2: Loss = 1.7345\n",
      "   ✅ Training complete. Final avg loss: 1.7675\n",
      "🔧 Training Client 14 (pristine):\n",
      "   Samples: 1695, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6171\n",
      "     Epoch 2: Loss = 1.5253\n",
      "   ✅ Training complete. Final avg loss: 1.5712\n",
      "🔧 Training Client 13 (pristine):\n",
      "   Samples: 1865, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3283\n",
      "     Epoch 2: Loss = 1.2389\n",
      "   ✅ Training complete. Final avg loss: 1.2836\n",
      "🔧 Training Client 8 (poison):\n",
      "   Samples: 2129, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.4805\n",
      "     Epoch 2: Loss = 2.3090\n",
      "   ✅ Training complete. Final avg loss: 2.3947\n",
      "🔧 Training Client 6 (poison):\n",
      "   Samples: 5254, Quality: 0.050\n",
      "     Epoch 1: Loss = 2.3685\n",
      "     Epoch 2: Loss = 2.3024\n",
      "   ✅ Training complete. Final avg loss: 2.3354\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.655, Loss_std=1.069, Entropy=1.589\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.586\n",
      "      Stability: 0.644, Confidence: 0.364\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.657\n",
      "   ✅ Decision: KEEP (Score 0.657 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.538, Loss=1.282, Loss_std=1.118, Entropy=1.241\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.679\n",
      "      Stability: 0.627, Confidence: 0.504\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.753\n",
      "   ✅ Decision: KEEP (Score 0.753 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.488, Loss=1.522, Loss_std=0.860, Entropy=1.672\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.619\n",
      "      Stability: 0.713, Confidence: 0.331\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.772, Loss=0.728, Loss_std=1.115, Entropy=0.785\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.818\n",
      "      Stability: 0.628, Confidence: 0.686\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.817\n",
      "   ✅ Decision: KEEP (Score 0.817 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.293, Loss_std=0.118, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.427\n",
      "      Stability: 0.961, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ❌ Decision: FILTER (Score 0.261 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.702, Loss_std=1.020, Entropy=1.754\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.575\n",
      "      Stability: 0.660, Confidence: 0.298\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.646\n",
      "   ✅ Decision: KEEP (Score 0.646 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.472, Loss_std=0.981, Entropy=1.445\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.632\n",
      "      Stability: 0.673, Confidence: 0.422\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.606, Loss=1.202, Loss_std=1.082, Entropy=1.254\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.699\n",
      "      Stability: 0.639, Confidence: 0.499\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.759\n",
      "   ✅ Decision: KEEP (Score 0.759 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.123, Loss=2.303, Loss_std=0.070, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.409, Loss: 0.424\n",
      "      Stability: 0.977, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.269\n",
      "   ❌ Decision: FILTER (Score 0.269 < threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.050)\n",
      "   📊 Metrics: Acc=0.087, Loss=2.299, Loss_std=0.060, Entropy=2.301\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.288, Loss: 0.425\n",
      "      Stability: 0.980, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.250\n",
      "   ❌ Decision: FILTER (Score 0.250 < threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.817 |    2926 | KEEP     | Score 0.817 ≥ threshold 0.400\n",
      "      2 |      7 |  0.980 |     0.759 |    1865 | KEEP     | Score 0.759 ≥ threshold 0.400\n",
      "      3 |      1 |  0.980 |     0.753 |    2437 | KEEP     | Score 0.753 ≥ threshold 0.400\n",
      "      4 |      6 |  0.980 |     0.738 |    1695 | KEEP     | Score 0.738 ≥ threshold 0.400\n",
      "      5 |      2 |  0.980 |     0.727 |    4984 | KEEP     | Score 0.727 ≥ threshold 0.400\n",
      "      6 |      0 |  0.450 |     0.657 |    3563 | KEEP     | Score 0.657 ≥ threshold 0.400\n",
      "      7 |      5 |  0.450 |     0.646 |    9373 | KEEP     | Score 0.646 ≥ threshold 0.400\n",
      "      8 |      8 |  0.050 |     0.269 |    2129 | FILTER   | Score 0.269 < threshold 0.400\n",
      "      9 |      4 |  0.050 |     0.261 |    3221 | FILTER   | Score 0.261 < threshold 0.400\n",
      "     10 |      9 |  0.050 |     0.250 |    5254 | FILTER   | Score 0.250 < threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 7 (IDs: [3, 7, 1, 6, 2, 0, 5])\n",
      "   Filter rate: 30.0%\n",
      "   Average quality score: 0.728\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for poison\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: poison\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 2926 |   0.817 |  0.109 |  0.213 |   0.202\n",
      "        7 | 1865 |   0.759 |  0.069 |  0.167 |   0.157\n",
      "        1 | 2437 |   0.753 |  0.091 |  0.162 |   0.155\n",
      "        6 | 1695 |   0.738 |  0.063 |  0.150 |   0.142\n",
      "        2 | 4984 |   0.727 |  0.186 |  0.142 |   0.147\n",
      "        0 | 3563 |   0.657 |  0.133 |  0.087 |   0.092\n",
      "        5 | 9373 |   0.646 |  0.349 |  0.079 |   0.106\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 23.02% accuracy, 2.7852 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 23.02%\n",
      "   Best Accuracy: 24.88%\n",
      "   avg_filter_rate: 0.363\n",
      "   max_filter_rate: 0.500\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 6/8\n",
      "   Learning Rate: 0.01\n",
      "   Extreme Type: catastrophic\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'catastrophic':\n",
      "   30% pristine, 20% degraded, 50% CATASTROPHIC (unrecognizable)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_catastrophic_lr0.01_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  PRISTINE: 4 clients\n",
      "  DEGRADED: 3 clients\n",
      "  CATASTROPHIC: 8 clients\n",
      "   💀 Client 0 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 1 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 2 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 3 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 4 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 5 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 6 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 7 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 8 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 9 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 10 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 11 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 12 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 13 (catastrophic): CATASTROPHIC: 80% wrong labels, 90% images destroyed\n",
      "   💀 Client 14 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.020 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   PRISTINE: 4 clients (avg score: 0.980)\n",
      "   CATASTROPHIC: 8 clients (avg score: 0.020)\n",
      "   DEGRADED: 3 clients (avg score: 0.450)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs CATASTROPHIC\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9951\n",
      "     Epoch 2: Loss = 1.8908\n",
      "   ✅ Training complete. Final avg loss: 1.9430\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9472\n",
      "     Epoch 2: Loss = 1.7145\n",
      "   ✅ Training complete. Final avg loss: 1.8309\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0065\n",
      "     Epoch 2: Loss = 1.8044\n",
      "   ✅ Training complete. Final avg loss: 1.9055\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2942\n",
      "     Epoch 2: Loss = 2.2918\n",
      "   ✅ Training complete. Final avg loss: 2.2930\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3035\n",
      "     Epoch 2: Loss = 2.2965\n",
      "   ✅ Training complete. Final avg loss: 2.3000\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2970\n",
      "     Epoch 2: Loss = 2.2918\n",
      "   ✅ Training complete. Final avg loss: 2.2944\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3021\n",
      "     Epoch 2: Loss = 2.2960\n",
      "   ✅ Training complete. Final avg loss: 2.2990\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7703\n",
      "     Epoch 2: Loss = 1.6586\n",
      "   ✅ Training complete. Final avg loss: 1.7144\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0331\n",
      "     Epoch 2: Loss = 1.8873\n",
      "   ✅ Training complete. Final avg loss: 1.9602\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1065\n",
      "     Epoch 2: Loss = 1.8310\n",
      "   ✅ Training complete. Final avg loss: 1.9687\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=5331, Weight=0.1621, Quality=degraded\n",
      "  Client 1: Size=2013, Weight=0.0612, Quality=pristine\n",
      "  Client 2: Size=1951, Weight=0.0593, Quality=pristine\n",
      "  Client 3: Size=4717, Weight=0.1434, Quality=catastrophic\n",
      "  Client 4: Size=1524, Weight=0.0463, Quality=catastrophic\n",
      "  Client 5: Size=4946, Weight=0.1504, Quality=catastrophic\n",
      "  Client 6: Size=2108, Weight=0.0641, Quality=catastrophic\n",
      "  Client 7: Size=6957, Weight=0.2115, Quality=pristine\n",
      "  Client 8: Size=2133, Weight=0.0649, Quality=degraded\n",
      "  Client 9: Size=1210, Weight=0.0368, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 13.92% accuracy, 2.2949 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3080\n",
      "     Epoch 2: Loss = 2.2937\n",
      "   ✅ Training complete. Final avg loss: 2.3008\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6965\n",
      "     Epoch 2: Loss = 1.5953\n",
      "   ✅ Training complete. Final avg loss: 1.6459\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9972\n",
      "     Epoch 2: Loss = 1.8760\n",
      "   ✅ Training complete. Final avg loss: 1.9366\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0409\n",
      "     Epoch 2: Loss = 1.8342\n",
      "   ✅ Training complete. Final avg loss: 1.9375\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9195\n",
      "     Epoch 2: Loss = 1.8482\n",
      "   ✅ Training complete. Final avg loss: 1.8839\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3001\n",
      "     Epoch 2: Loss = 2.2938\n",
      "   ✅ Training complete. Final avg loss: 2.2970\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6999\n",
      "     Epoch 2: Loss = 1.5261\n",
      "   ✅ Training complete. Final avg loss: 1.6130\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3051\n",
      "     Epoch 2: Loss = 2.3002\n",
      "   ✅ Training complete. Final avg loss: 2.3027\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3050\n",
      "     Epoch 2: Loss = 2.2965\n",
      "   ✅ Training complete. Final avg loss: 2.3008\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8312\n",
      "     Epoch 2: Loss = 1.6801\n",
      "   ✅ Training complete. Final avg loss: 1.7557\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1524, Weight=0.0424, Quality=catastrophic\n",
      "  Client 1: Size=6957, Weight=0.1933, Quality=pristine\n",
      "  Client 2: Size=2133, Weight=0.0593, Quality=degraded\n",
      "  Client 3: Size=1210, Weight=0.0336, Quality=degraded\n",
      "  Client 4: Size=5331, Weight=0.1481, Quality=degraded\n",
      "  Client 5: Size=4717, Weight=0.1311, Quality=catastrophic\n",
      "  Client 6: Size=4764, Weight=0.1324, Quality=pristine\n",
      "  Client 7: Size=5228, Weight=0.1453, Quality=catastrophic\n",
      "  Client 8: Size=2108, Weight=0.0586, Quality=catastrophic\n",
      "  Client 9: Size=2013, Weight=0.0559, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 15.13% accuracy, 2.2161 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8886\n",
      "     Epoch 2: Loss = 1.7382\n",
      "   ✅ Training complete. Final avg loss: 1.8134\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3002\n",
      "     Epoch 2: Loss = 2.2986\n",
      "   ✅ Training complete. Final avg loss: 2.2994\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7858\n",
      "     Epoch 2: Loss = 1.6290\n",
      "   ✅ Training complete. Final avg loss: 1.7074\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8682\n",
      "     Epoch 2: Loss = 1.7475\n",
      "   ✅ Training complete. Final avg loss: 1.8078\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3022\n",
      "     Epoch 2: Loss = 2.2981\n",
      "   ✅ Training complete. Final avg loss: 2.3001\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2923\n",
      "     Epoch 2: Loss = 2.2840\n",
      "   ✅ Training complete. Final avg loss: 2.2881\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3024\n",
      "     Epoch 2: Loss = 2.2961\n",
      "   ✅ Training complete. Final avg loss: 2.2993\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3029\n",
      "     Epoch 2: Loss = 2.3007\n",
      "   ✅ Training complete. Final avg loss: 2.3018\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9524\n",
      "     Epoch 2: Loss = 1.8427\n",
      "   ✅ Training complete. Final avg loss: 1.8975\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2986\n",
      "     Epoch 2: Loss = 2.2922\n",
      "   ✅ Training complete. Final avg loss: 2.2954\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1951, Weight=0.0665, Quality=pristine\n",
      "  Client 1: Size=2108, Weight=0.0718, Quality=catastrophic\n",
      "  Client 2: Size=2013, Weight=0.0686, Quality=pristine\n",
      "  Client 3: Size=5331, Weight=0.1817, Quality=degraded\n",
      "  Client 4: Size=2117, Weight=0.0722, Quality=catastrophic\n",
      "  Client 5: Size=1990, Weight=0.0678, Quality=catastrophic\n",
      "  Client 6: Size=1524, Weight=0.0519, Quality=catastrophic\n",
      "  Client 7: Size=5228, Weight=0.1782, Quality=catastrophic\n",
      "  Client 8: Size=2133, Weight=0.0727, Quality=degraded\n",
      "  Client 9: Size=4946, Weight=0.1686, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.87% accuracy, 2.1828 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6055\n",
      "     Epoch 2: Loss = 1.4424\n",
      "   ✅ Training complete. Final avg loss: 1.5240\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5833\n",
      "     Epoch 2: Loss = 1.4494\n",
      "   ✅ Training complete. Final avg loss: 1.5163\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2948\n",
      "     Epoch 2: Loss = 2.2923\n",
      "   ✅ Training complete. Final avg loss: 2.2936\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2980\n",
      "     Epoch 2: Loss = 2.2931\n",
      "   ✅ Training complete. Final avg loss: 2.2956\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8136\n",
      "     Epoch 2: Loss = 1.7368\n",
      "   ✅ Training complete. Final avg loss: 1.7752\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7409\n",
      "     Epoch 2: Loss = 1.5667\n",
      "   ✅ Training complete. Final avg loss: 1.6538\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9492\n",
      "     Epoch 2: Loss = 1.8169\n",
      "   ✅ Training complete. Final avg loss: 1.8831\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8292\n",
      "     Epoch 2: Loss = 1.6115\n",
      "   ✅ Training complete. Final avg loss: 1.7203\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2884\n",
      "     Epoch 2: Loss = 2.2807\n",
      "   ✅ Training complete. Final avg loss: 2.2845\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3019\n",
      "     Epoch 2: Loss = 2.2961\n",
      "   ✅ Training complete. Final avg loss: 2.2990\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4764, Weight=0.1308, Quality=pristine\n",
      "  Client 1: Size=6957, Weight=0.1910, Quality=pristine\n",
      "  Client 2: Size=4946, Weight=0.1358, Quality=catastrophic\n",
      "  Client 3: Size=4717, Weight=0.1295, Quality=catastrophic\n",
      "  Client 4: Size=5331, Weight=0.1464, Quality=degraded\n",
      "  Client 5: Size=2013, Weight=0.0553, Quality=pristine\n",
      "  Client 6: Size=1210, Weight=0.0332, Quality=degraded\n",
      "  Client 7: Size=1951, Weight=0.0536, Quality=pristine\n",
      "  Client 8: Size=3011, Weight=0.0827, Quality=catastrophic\n",
      "  Client 9: Size=1524, Weight=0.0418, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 15.83% accuracy, 2.1744 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9519\n",
      "     Epoch 2: Loss = 1.7775\n",
      "   ✅ Training complete. Final avg loss: 1.8647\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3109\n",
      "     Epoch 2: Loss = 2.2871\n",
      "   ✅ Training complete. Final avg loss: 2.2990\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2919\n",
      "     Epoch 2: Loss = 2.2833\n",
      "   ✅ Training complete. Final avg loss: 2.2876\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3042\n",
      "     Epoch 2: Loss = 2.2941\n",
      "   ✅ Training complete. Final avg loss: 2.2991\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5356\n",
      "     Epoch 2: Loss = 1.4259\n",
      "   ✅ Training complete. Final avg loss: 1.4807\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3188\n",
      "     Epoch 2: Loss = 2.2976\n",
      "   ✅ Training complete. Final avg loss: 2.3082\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7611\n",
      "     Epoch 2: Loss = 1.7132\n",
      "   ✅ Training complete. Final avg loss: 1.7371\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3133\n",
      "     Epoch 2: Loss = 2.2972\n",
      "   ✅ Training complete. Final avg loss: 2.3052\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6980\n",
      "     Epoch 2: Loss = 1.5431\n",
      "   ✅ Training complete. Final avg loss: 1.6206\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3235\n",
      "     Epoch 2: Loss = 2.2996\n",
      "   ✅ Training complete. Final avg loss: 2.3116\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1210, Weight=0.0421, Quality=degraded\n",
      "  Client 1: Size=1990, Weight=0.0693, Quality=catastrophic\n",
      "  Client 2: Size=3011, Weight=0.1048, Quality=catastrophic\n",
      "  Client 3: Size=4717, Weight=0.1642, Quality=catastrophic\n",
      "  Client 4: Size=4764, Weight=0.1659, Quality=pristine\n",
      "  Client 5: Size=2108, Weight=0.0734, Quality=catastrophic\n",
      "  Client 6: Size=5331, Weight=0.1856, Quality=degraded\n",
      "  Client 7: Size=2117, Weight=0.0737, Quality=catastrophic\n",
      "  Client 8: Size=1951, Weight=0.0679, Quality=pristine\n",
      "  Client 9: Size=1524, Weight=0.0531, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 19.66% accuracy, 2.1329 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3002\n",
      "     Epoch 2: Loss = 2.2920\n",
      "   ✅ Training complete. Final avg loss: 2.2961\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9094\n",
      "     Epoch 2: Loss = 1.7791\n",
      "   ✅ Training complete. Final avg loss: 1.8443\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6605\n",
      "     Epoch 2: Loss = 1.4884\n",
      "   ✅ Training complete. Final avg loss: 1.5745\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4840\n",
      "     Epoch 2: Loss = 1.3891\n",
      "   ✅ Training complete. Final avg loss: 1.4365\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8444\n",
      "     Epoch 2: Loss = 1.7628\n",
      "   ✅ Training complete. Final avg loss: 1.8036\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3014\n",
      "     Epoch 2: Loss = 2.2872\n",
      "   ✅ Training complete. Final avg loss: 2.2943\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3115\n",
      "     Epoch 2: Loss = 2.2987\n",
      "   ✅ Training complete. Final avg loss: 2.3051\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7532\n",
      "     Epoch 2: Loss = 1.6984\n",
      "   ✅ Training complete. Final avg loss: 1.7258\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2898\n",
      "     Epoch 2: Loss = 2.2811\n",
      "   ✅ Training complete. Final avg loss: 2.2855\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3128\n",
      "     Epoch 2: Loss = 2.2951\n",
      "   ✅ Training complete. Final avg loss: 2.3039\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4946, Weight=0.1704, Quality=catastrophic\n",
      "  Client 1: Size=1210, Weight=0.0417, Quality=degraded\n",
      "  Client 2: Size=2013, Weight=0.0693, Quality=pristine\n",
      "  Client 3: Size=4764, Weight=0.1641, Quality=pristine\n",
      "  Client 4: Size=2133, Weight=0.0735, Quality=degraded\n",
      "  Client 5: Size=1990, Weight=0.0685, Quality=catastrophic\n",
      "  Client 6: Size=2108, Weight=0.0726, Quality=catastrophic\n",
      "  Client 7: Size=5331, Weight=0.1836, Quality=degraded\n",
      "  Client 8: Size=3011, Weight=0.1037, Quality=catastrophic\n",
      "  Client 9: Size=1524, Weight=0.0525, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 21.42% accuracy, 2.1285 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3004\n",
      "     Epoch 2: Loss = 2.2923\n",
      "   ✅ Training complete. Final avg loss: 2.2963\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6569\n",
      "     Epoch 2: Loss = 1.5251\n",
      "   ✅ Training complete. Final avg loss: 1.5910\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3094\n",
      "     Epoch 2: Loss = 2.2961\n",
      "   ✅ Training complete. Final avg loss: 2.3028\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3112\n",
      "     Epoch 2: Loss = 2.3019\n",
      "   ✅ Training complete. Final avg loss: 2.3065\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8883\n",
      "     Epoch 2: Loss = 1.7851\n",
      "   ✅ Training complete. Final avg loss: 1.8367\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2955\n",
      "     Epoch 2: Loss = 2.2852\n",
      "   ✅ Training complete. Final avg loss: 2.2903\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7350\n",
      "     Epoch 2: Loss = 1.6855\n",
      "   ✅ Training complete. Final avg loss: 1.7102\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3057\n",
      "     Epoch 2: Loss = 2.2986\n",
      "   ✅ Training complete. Final avg loss: 2.3022\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2957\n",
      "     Epoch 2: Loss = 2.2801\n",
      "   ✅ Training complete. Final avg loss: 2.2879\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3084\n",
      "     Epoch 2: Loss = 2.2978\n",
      "   ✅ Training complete. Final avg loss: 2.3031\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4946, Weight=0.1681, Quality=catastrophic\n",
      "  Client 1: Size=1951, Weight=0.0663, Quality=pristine\n",
      "  Client 2: Size=1524, Weight=0.0518, Quality=catastrophic\n",
      "  Client 3: Size=2108, Weight=0.0717, Quality=catastrophic\n",
      "  Client 4: Size=1210, Weight=0.0411, Quality=degraded\n",
      "  Client 5: Size=1990, Weight=0.0677, Quality=catastrophic\n",
      "  Client 6: Size=5331, Weight=0.1812, Quality=degraded\n",
      "  Client 7: Size=5228, Weight=0.1777, Quality=catastrophic\n",
      "  Client 8: Size=3011, Weight=0.1024, Quality=catastrophic\n",
      "  Client 9: Size=2117, Weight=0.0720, Quality=catastrophic\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 21.24% accuracy, 2.0948 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2964\n",
      "     Epoch 2: Loss = 2.2921\n",
      "   ✅ Training complete. Final avg loss: 2.2943\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7224\n",
      "     Epoch 2: Loss = 1.6710\n",
      "   ✅ Training complete. Final avg loss: 1.6967\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2952\n",
      "     Epoch 2: Loss = 2.2912\n",
      "   ✅ Training complete. Final avg loss: 2.2932\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2969\n",
      "     Epoch 2: Loss = 2.2857\n",
      "   ✅ Training complete. Final avg loss: 2.2913\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3060\n",
      "     Epoch 2: Loss = 2.2984\n",
      "   ✅ Training complete. Final avg loss: 2.3022\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8612\n",
      "     Epoch 2: Loss = 1.7453\n",
      "   ✅ Training complete. Final avg loss: 1.8033\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3060\n",
      "     Epoch 2: Loss = 2.2946\n",
      "   ✅ Training complete. Final avg loss: 2.3003\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4926\n",
      "     Epoch 2: Loss = 1.3411\n",
      "   ✅ Training complete. Final avg loss: 1.4168\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9246\n",
      "     Epoch 2: Loss = 1.7812\n",
      "   ✅ Training complete. Final avg loss: 1.8529\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6468\n",
      "     Epoch 2: Loss = 1.5023\n",
      "   ✅ Training complete. Final avg loss: 1.5745\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   catastrophic scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4717, Weight=0.1537, Quality=catastrophic\n",
      "  Client 1: Size=5331, Weight=0.1737, Quality=degraded\n",
      "  Client 2: Size=4946, Weight=0.1612, Quality=catastrophic\n",
      "  Client 3: Size=1990, Weight=0.0649, Quality=catastrophic\n",
      "  Client 4: Size=2117, Weight=0.0690, Quality=catastrophic\n",
      "  Client 5: Size=2133, Weight=0.0695, Quality=degraded\n",
      "  Client 6: Size=1524, Weight=0.0497, Quality=catastrophic\n",
      "  Client 7: Size=4764, Weight=0.1553, Quality=pristine\n",
      "  Client 8: Size=1210, Weight=0.0394, Quality=degraded\n",
      "  Client 9: Size=1951, Weight=0.0636, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 21.51% accuracy, 2.1697 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 21.51%\n",
      "   Best Accuracy: 21.51%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs CATASTROPHIC\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'catastrophic':\n",
      "   Quality threshold: 0.250\n",
      "   Minimum clients ratio: 40.0%\n",
      "   Harm detection threshold: 0.050\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9951\n",
      "     Epoch 2: Loss = 1.8909\n",
      "   ✅ Training complete. Final avg loss: 1.9430\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9472\n",
      "     Epoch 2: Loss = 1.7145\n",
      "   ✅ Training complete. Final avg loss: 1.8309\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0065\n",
      "     Epoch 2: Loss = 1.8044\n",
      "   ✅ Training complete. Final avg loss: 1.9055\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2942\n",
      "     Epoch 2: Loss = 2.2919\n",
      "   ✅ Training complete. Final avg loss: 2.2930\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3035\n",
      "     Epoch 2: Loss = 2.2965\n",
      "   ✅ Training complete. Final avg loss: 2.3000\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2969\n",
      "     Epoch 2: Loss = 2.2918\n",
      "   ✅ Training complete. Final avg loss: 2.2944\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3021\n",
      "     Epoch 2: Loss = 2.2960\n",
      "   ✅ Training complete. Final avg loss: 2.2990\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7704\n",
      "     Epoch 2: Loss = 1.6590\n",
      "   ✅ Training complete. Final avg loss: 1.7147\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0331\n",
      "     Epoch 2: Loss = 1.8873\n",
      "   ✅ Training complete. Final avg loss: 1.9602\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1065\n",
      "     Epoch 2: Loss = 1.8310\n",
      "   ✅ Training complete. Final avg loss: 1.9687\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.356, Loss=1.850, Loss_std=0.910, Entropy=1.836\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.537\n",
      "      Stability: 0.697, Confidence: 0.266\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.640\n",
      "   ✅ Decision: KEEP (Score 0.640 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.298, Loss=1.677, Loss_std=0.990, Entropy=1.618\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.994, Loss: 0.581\n",
      "      Stability: 0.670, Confidence: 0.353\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.711\n",
      "   ✅ Decision: KEEP (Score 0.711 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.831, Loss_std=0.818, Entropy=1.801\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.542\n",
      "      Stability: 0.727, Confidence: 0.280\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.154, Loss=2.289, Loss_std=0.161, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.513, Loss: 0.428\n",
      "      Stability: 0.946, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.280\n",
      "   ✅ Decision: KEEP (Score 0.280 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.137, Loss=2.292, Loss_std=0.092, Entropy=2.298\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.457, Loss: 0.427\n",
      "      Stability: 0.969, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.273\n",
      "   ✅ Decision: KEEP (Score 0.273 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.163, Loss=2.298, Loss_std=0.141, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.545, Loss: 0.426\n",
      "      Stability: 0.953, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.285\n",
      "   ✅ Decision: KEEP (Score 0.285 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.132, Loss=2.297, Loss_std=0.114, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.441, Loss: 0.426\n",
      "      Stability: 0.962, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.270\n",
      "   ✅ Decision: KEEP (Score 0.270 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.440, Loss=1.575, Loss_std=0.566, Entropy=1.760\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.606\n",
      "      Stability: 0.811, Confidence: 0.296\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.740\n",
      "   ✅ Decision: KEEP (Score 0.740 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.375, Loss=1.988, Loss_std=1.004, Entropy=1.821\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.503\n",
      "      Stability: 0.665, Confidence: 0.272\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.627\n",
      "   ✅ Decision: KEEP (Score 0.627 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.368, Loss=1.849, Loss_std=0.930, Entropy=1.836\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.538\n",
      "      Stability: 0.690, Confidence: 0.266\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.639\n",
      "   ✅ Decision: KEEP (Score 0.639 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.740 |    6957 | KEEP     | Score 0.740 ≥ threshold 0.250\n",
      "      2 |      1 |  0.980 |     0.711 |    2013 | KEEP     | Score 0.711 ≥ threshold 0.250\n",
      "      3 |      2 |  0.980 |     0.704 |    1951 | KEEP     | Score 0.704 ≥ threshold 0.250\n",
      "      4 |      0 |  0.450 |     0.640 |    5331 | KEEP     | Score 0.640 ≥ threshold 0.250\n",
      "      5 |      9 |  0.450 |     0.639 |    1210 | KEEP     | Score 0.639 ≥ threshold 0.250\n",
      "      6 |      8 |  0.450 |     0.627 |    2133 | KEEP     | Score 0.627 ≥ threshold 0.250\n",
      "      7 |      5 |  0.020 |     0.285 |    4946 | KEEP     | Score 0.285 ≥ threshold 0.250\n",
      "      8 |      3 |  0.020 |     0.280 |    4717 | KEEP     | Score 0.280 ≥ threshold 0.250\n",
      "      9 |      4 |  0.020 |     0.273 |    1524 | KEEP     | Score 0.273 ≥ threshold 0.250\n",
      "     10 |      6 |  0.020 |     0.270 |    2108 | KEEP     | Score 0.270 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 1, 2, 0, 9, 8, 5, 3, 4, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.517\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 6957 |   0.740 |  0.212 |  0.164 |   0.178\n",
      "        1 | 2013 |   0.711 |  0.061 |  0.156 |   0.127\n",
      "        2 | 1951 |   0.704 |  0.059 |  0.154 |   0.125\n",
      "        0 | 5331 |   0.640 |  0.162 |  0.136 |   0.144\n",
      "        9 | 1210 |   0.639 |  0.037 |  0.135 |   0.106\n",
      "        8 | 2133 |   0.627 |  0.065 |  0.132 |   0.112\n",
      "        5 | 4946 |   0.285 |  0.150 |  0.033 |   0.068\n",
      "        3 | 4717 |   0.280 |  0.143 |  0.032 |   0.065\n",
      "        4 | 1524 |   0.273 |  0.046 |  0.030 |   0.035\n",
      "        6 | 2108 |   0.270 |  0.064 |  0.029 |   0.039\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 10.57% accuracy, 2.3134 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2926\n",
      "     Epoch 2: Loss = 2.2823\n",
      "   ✅ Training complete. Final avg loss: 2.2874\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9998\n",
      "     Epoch 2: Loss = 1.8353\n",
      "   ✅ Training complete. Final avg loss: 1.9175\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8999\n",
      "     Epoch 2: Loss = 1.7910\n",
      "   ✅ Training complete. Final avg loss: 1.8455\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9719\n",
      "     Epoch 2: Loss = 1.8810\n",
      "   ✅ Training complete. Final avg loss: 1.9265\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9203\n",
      "     Epoch 2: Loss = 1.8549\n",
      "   ✅ Training complete. Final avg loss: 1.8876\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3009\n",
      "     Epoch 2: Loss = 2.2936\n",
      "   ✅ Training complete. Final avg loss: 2.2973\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3064\n",
      "     Epoch 2: Loss = 2.2970\n",
      "   ✅ Training complete. Final avg loss: 2.3017\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3041\n",
      "     Epoch 2: Loss = 2.2991\n",
      "   ✅ Training complete. Final avg loss: 2.3016\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7117\n",
      "     Epoch 2: Loss = 1.6092\n",
      "   ✅ Training complete. Final avg loss: 1.6604\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8347\n",
      "     Epoch 2: Loss = 1.6872\n",
      "   ✅ Training complete. Final avg loss: 1.7610\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.175, Loss=2.272, Loss_std=0.275, Entropy=2.268\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.585, Loss: 0.432\n",
      "      Stability: 0.908, Confidence: 0.093\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.288\n",
      "   ✅ Decision: KEEP (Score 0.288 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.373, Loss=1.776, Loss_std=0.913, Entropy=1.810\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.556\n",
      "      Stability: 0.696, Confidence: 0.276\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.646\n",
      "   ✅ Decision: KEEP (Score 0.646 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.361, Loss=1.800, Loss_std=0.845, Entropy=1.763\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.550\n",
      "      Stability: 0.718, Confidence: 0.295\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.440, Loss=1.854, Loss_std=0.868, Entropy=1.957\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.536\n",
      "      Stability: 0.711, Confidence: 0.217\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.635\n",
      "   ✅ Decision: KEEP (Score 0.635 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.380, Loss=1.775, Loss_std=1.018, Entropy=1.700\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.556\n",
      "      Stability: 0.661, Confidence: 0.320\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.646\n",
      "   ✅ Decision: KEEP (Score 0.646 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.154, Loss=2.286, Loss_std=0.179, Entropy=2.288\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.513, Loss: 0.428\n",
      "      Stability: 0.940, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.279\n",
      "   ✅ Decision: KEEP (Score 0.279 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.294, Loss_std=0.142, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.427\n",
      "      Stability: 0.953, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.257\n",
      "   ✅ Decision: KEEP (Score 0.257 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.113, Loss=2.301, Loss_std=0.074, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.377, Loss: 0.425\n",
      "      Stability: 0.975, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.261\n",
      "   ✅ Decision: KEEP (Score 0.261 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.454, Loss=1.538, Loss_std=0.714, Entropy=1.678\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.615\n",
      "      Stability: 0.762, Confidence: 0.329\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.737\n",
      "   ✅ Decision: KEEP (Score 0.737 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.428, Loss=1.608, Loss_std=0.888, Entropy=1.683\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.598\n",
      "      Stability: 0.704, Confidence: 0.327\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.720\n",
      "   ✅ Decision: KEEP (Score 0.720 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.737 |    6957 | KEEP     | Score 0.737 ≥ threshold 0.250\n",
      "      2 |      9 |  0.980 |     0.720 |    2013 | KEEP     | Score 0.720 ≥ threshold 0.250\n",
      "      3 |      2 |  0.980 |     0.706 |    1951 | KEEP     | Score 0.706 ≥ threshold 0.250\n",
      "      4 |      4 |  0.450 |     0.646 |    5331 | KEEP     | Score 0.646 ≥ threshold 0.250\n",
      "      5 |      1 |  0.450 |     0.646 |    1210 | KEEP     | Score 0.646 ≥ threshold 0.250\n",
      "      6 |      3 |  0.450 |     0.635 |    2133 | KEEP     | Score 0.635 ≥ threshold 0.250\n",
      "      7 |      0 |  0.020 |     0.288 |    3011 | KEEP     | Score 0.288 ≥ threshold 0.250\n",
      "      8 |      5 |  0.020 |     0.279 |    4717 | KEEP     | Score 0.279 ≥ threshold 0.250\n",
      "      9 |      7 |  0.020 |     0.261 |    5228 | KEEP     | Score 0.261 ≥ threshold 0.250\n",
      "     10 |      6 |  0.020 |     0.257 |    2117 | KEEP     | Score 0.257 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [8, 9, 2, 4, 1, 3, 0, 5, 7, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.518\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 6957 |   0.737 |  0.201 |  0.161 |   0.173\n",
      "        9 | 2013 |   0.720 |  0.058 |  0.156 |   0.127\n",
      "        2 | 1951 |   0.706 |  0.056 |  0.152 |   0.124\n",
      "        4 | 5331 |   0.646 |  0.154 |  0.136 |   0.141\n",
      "        1 | 1210 |   0.646 |  0.035 |  0.136 |   0.105\n",
      "        3 | 2133 |   0.635 |  0.062 |  0.132 |   0.111\n",
      "        0 | 3011 |   0.288 |  0.087 |  0.036 |   0.051\n",
      "        5 | 4717 |   0.279 |  0.136 |  0.034 |   0.065\n",
      "        7 | 5228 |   0.261 |  0.151 |  0.029 |   0.065\n",
      "        6 | 2117 |   0.257 |  0.061 |  0.028 |   0.038\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.48% accuracy, 2.2674 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3077\n",
      "     Epoch 2: Loss = 2.2986\n",
      "   ✅ Training complete. Final avg loss: 2.3032\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8602\n",
      "     Epoch 2: Loss = 1.7548\n",
      "   ✅ Training complete. Final avg loss: 1.8075\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3036\n",
      "     Epoch 2: Loss = 2.2934\n",
      "   ✅ Training complete. Final avg loss: 2.2985\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6433\n",
      "     Epoch 2: Loss = 1.4900\n",
      "   ✅ Training complete. Final avg loss: 1.5667\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6648\n",
      "     Epoch 2: Loss = 1.4996\n",
      "   ✅ Training complete. Final avg loss: 1.5822\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9357\n",
      "     Epoch 2: Loss = 1.8474\n",
      "   ✅ Training complete. Final avg loss: 1.8916\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3169\n",
      "     Epoch 2: Loss = 2.2969\n",
      "   ✅ Training complete. Final avg loss: 2.3069\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2959\n",
      "     Epoch 2: Loss = 2.2858\n",
      "   ✅ Training complete. Final avg loss: 2.2909\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3101\n",
      "     Epoch 2: Loss = 2.3021\n",
      "   ✅ Training complete. Final avg loss: 2.3061\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3078\n",
      "     Epoch 2: Loss = 2.3003\n",
      "   ✅ Training complete. Final avg loss: 2.3040\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.296, Loss_std=0.128, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.426\n",
      "      Stability: 0.957, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.260\n",
      "   ✅ Decision: KEEP (Score 0.260 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.284, Loss=1.726, Loss_std=0.808, Entropy=1.804\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.946, Loss: 0.568\n",
      "      Stability: 0.731, Confidence: 0.279\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.696\n",
      "   ✅ Decision: KEEP (Score 0.696 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.103, Loss=2.291, Loss_std=0.128, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.345, Loss: 0.427\n",
      "      Stability: 0.957, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.254\n",
      "   ✅ Decision: KEEP (Score 0.254 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.505, Loss=1.459, Loss_std=1.181, Entropy=1.458\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.635\n",
      "      Stability: 0.606, Confidence: 0.417\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.471, Loss=1.389, Loss_std=0.820, Entropy=1.535\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.653\n",
      "      Stability: 0.727, Confidence: 0.386\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.748\n",
      "   ✅ Decision: KEEP (Score 0.748 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.433, Loss=1.847, Loss_std=1.159, Entropy=1.635\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.538\n",
      "      Stability: 0.614, Confidence: 0.346\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.636\n",
      "   ✅ Decision: KEEP (Score 0.636 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.307, Loss_std=0.166, Entropy=2.288\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.423\n",
      "      Stability: 0.945, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.254\n",
      "   ✅ Decision: KEEP (Score 0.254 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.149, Loss=2.292, Loss_std=0.220, Entropy=2.280\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.497, Loss: 0.427\n",
      "      Stability: 0.927, Confidence: 0.088\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.275\n",
      "   ✅ Decision: KEEP (Score 0.275 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.123, Loss=2.295, Loss_std=0.123, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.409, Loss: 0.426\n",
      "      Stability: 0.959, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.264\n",
      "   ✅ Decision: KEEP (Score 0.264 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.108, Loss=2.296, Loss_std=0.077, Entropy=2.300\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.361, Loss: 0.426\n",
      "      Stability: 0.974, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.258\n",
      "   ✅ Decision: KEEP (Score 0.258 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.748 |    6957 | KEEP     | Score 0.748 ≥ threshold 0.250\n",
      "      2 |      3 |  0.980 |     0.722 |    4764 | KEEP     | Score 0.722 ≥ threshold 0.250\n",
      "      3 |      1 |  0.980 |     0.696 |    1951 | KEEP     | Score 0.696 ≥ threshold 0.250\n",
      "      4 |      5 |  0.450 |     0.636 |    2133 | KEEP     | Score 0.636 ≥ threshold 0.250\n",
      "      5 |      7 |  0.020 |     0.275 |    3011 | KEEP     | Score 0.275 ≥ threshold 0.250\n",
      "      6 |      8 |  0.020 |     0.264 |    2117 | KEEP     | Score 0.264 ≥ threshold 0.250\n",
      "      7 |      0 |  0.020 |     0.260 |    2108 | KEEP     | Score 0.260 ≥ threshold 0.250\n",
      "      8 |      9 |  0.020 |     0.258 |    5228 | KEEP     | Score 0.258 ≥ threshold 0.250\n",
      "      9 |      6 |  0.020 |     0.254 |    1524 | KEEP     | Score 0.254 ≥ threshold 0.250\n",
      "     10 |      2 |  0.020 |     0.254 |    4946 | KEEP     | Score 0.254 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 3, 1, 5, 7, 8, 0, 9, 6, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.437\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 6957 |   0.748 |  0.200 |  0.210 |   0.207\n",
      "        3 | 4764 |   0.722 |  0.137 |  0.201 |   0.182\n",
      "        1 | 1951 |   0.696 |  0.056 |  0.192 |   0.151\n",
      "        5 | 2133 |   0.636 |  0.061 |  0.171 |   0.138\n",
      "        7 | 3011 |   0.275 |  0.087 |  0.043 |   0.056\n",
      "        8 | 2117 |   0.264 |  0.061 |  0.039 |   0.046\n",
      "        0 | 2108 |   0.260 |  0.061 |  0.038 |   0.044\n",
      "        9 | 5228 |   0.258 |  0.150 |  0.037 |   0.071\n",
      "        6 | 1524 |   0.254 |  0.044 |  0.036 |   0.038\n",
      "        2 | 4946 |   0.254 |  0.142 |  0.035 |   0.067\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.57% accuracy, 2.2113 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3121\n",
      "     Epoch 2: Loss = 2.2957\n",
      "   ✅ Training complete. Final avg loss: 2.3039\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3005\n",
      "     Epoch 2: Loss = 2.2924\n",
      "   ✅ Training complete. Final avg loss: 2.2965\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8026\n",
      "     Epoch 2: Loss = 1.5860\n",
      "   ✅ Training complete. Final avg loss: 1.6943\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2976\n",
      "     Epoch 2: Loss = 2.2839\n",
      "   ✅ Training complete. Final avg loss: 2.2908\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5630\n",
      "     Epoch 2: Loss = 1.4374\n",
      "   ✅ Training complete. Final avg loss: 1.5002\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3130\n",
      "     Epoch 2: Loss = 2.3029\n",
      "   ✅ Training complete. Final avg loss: 2.3079\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.2989\n",
      "     Epoch 2: Loss = 2.2829\n",
      "   ✅ Training complete. Final avg loss: 2.2909\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9145\n",
      "     Epoch 2: Loss = 1.8147\n",
      "   ✅ Training complete. Final avg loss: 1.8646\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8210\n",
      "     Epoch 2: Loss = 1.7413\n",
      "   ✅ Training complete. Final avg loss: 1.7811\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3059\n",
      "     Epoch 2: Loss = 2.2999\n",
      "   ✅ Training complete. Final avg loss: 2.3029\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.291, Loss_std=0.138, Entropy=2.293\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.427\n",
      "      Stability: 0.954, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.257\n",
      "   ✅ Decision: KEEP (Score 0.257 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.154, Loss=2.292, Loss_std=0.195, Entropy=2.286\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.513, Loss: 0.427\n",
      "      Stability: 0.935, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.278\n",
      "   ✅ Decision: KEEP (Score 0.278 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.462, Loss=1.558, Loss_std=1.086, Entropy=1.495\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.610\n",
      "      Stability: 0.638, Confidence: 0.402\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.721\n",
      "   ✅ Decision: KEEP (Score 0.721 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.190, Loss=2.270, Loss_std=0.233, Entropy=2.281\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.633, Loss: 0.433\n",
      "      Stability: 0.922, Confidence: 0.087\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.297\n",
      "   ✅ Decision: KEEP (Score 0.297 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.474, Loss=1.403, Loss_std=0.878, Entropy=1.477\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.649\n",
      "      Stability: 0.707, Confidence: 0.409\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.747\n",
      "   ✅ Decision: KEEP (Score 0.747 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.161, Loss=2.281, Loss_std=0.124, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.537, Loss: 0.430\n",
      "      Stability: 0.959, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.285\n",
      "   ✅ Decision: KEEP (Score 0.285 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.166, Loss=2.286, Loss_std=0.198, Entropy=2.286\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.553, Loss: 0.428\n",
      "      Stability: 0.934, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.285\n",
      "   ✅ Decision: KEEP (Score 0.285 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.766, Loss_std=0.796, Entropy=1.894\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.558\n",
      "      Stability: 0.735, Confidence: 0.242\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.650\n",
      "   ✅ Decision: KEEP (Score 0.650 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.440, Loss=1.660, Loss_std=0.933, Entropy=1.757\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.585\n",
      "      Stability: 0.689, Confidence: 0.297\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.655\n",
      "   ✅ Decision: KEEP (Score 0.655 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.139, Loss=2.295, Loss_std=0.087, Entropy=2.299\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.465, Loss: 0.426\n",
      "      Stability: 0.971, Confidence: 0.080\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.275\n",
      "   ✅ Decision: KEEP (Score 0.275 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.747 |    6957 | KEEP     | Score 0.747 ≥ threshold 0.250\n",
      "      2 |      2 |  0.980 |     0.721 |    1951 | KEEP     | Score 0.721 ≥ threshold 0.250\n",
      "      3 |      8 |  0.450 |     0.655 |    5331 | KEEP     | Score 0.655 ≥ threshold 0.250\n",
      "      4 |      7 |  0.450 |     0.650 |    1210 | KEEP     | Score 0.650 ≥ threshold 0.250\n",
      "      5 |      3 |  0.020 |     0.297 |    3011 | KEEP     | Score 0.297 ≥ threshold 0.250\n",
      "      6 |      5 |  0.020 |     0.285 |    2108 | KEEP     | Score 0.285 ≥ threshold 0.250\n",
      "      7 |      6 |  0.020 |     0.285 |    1990 | KEEP     | Score 0.285 ≥ threshold 0.250\n",
      "      8 |      1 |  0.020 |     0.278 |    4946 | KEEP     | Score 0.278 ≥ threshold 0.250\n",
      "      9 |      9 |  0.020 |     0.275 |    5228 | KEEP     | Score 0.275 ≥ threshold 0.250\n",
      "     10 |      0 |  0.020 |     0.257 |    2117 | KEEP     | Score 0.257 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 2, 8, 7, 3, 5, 6, 1, 9, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.445\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 6957 |   0.747 |  0.200 |  0.205 |   0.203\n",
      "        2 | 1951 |   0.721 |  0.056 |  0.196 |   0.154\n",
      "        8 | 5331 |   0.655 |  0.153 |  0.173 |   0.167\n",
      "        7 | 1210 |   0.650 |  0.035 |  0.171 |   0.130\n",
      "        3 | 3011 |   0.297 |  0.086 |  0.049 |   0.060\n",
      "        5 | 2108 |   0.285 |  0.060 |  0.045 |   0.049\n",
      "        6 | 1990 |   0.285 |  0.057 |  0.044 |   0.048\n",
      "        1 | 4946 |   0.278 |  0.142 |  0.042 |   0.072\n",
      "        9 | 5228 |   0.275 |  0.150 |  0.041 |   0.074\n",
      "        0 | 2117 |   0.257 |  0.061 |  0.035 |   0.043\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.73% accuracy, 2.1943 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 6: PRISTINE (score: 0.980)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5396\n",
      "     Epoch 2: Loss = 1.3968\n",
      "   ✅ Training complete. Final avg loss: 1.4682\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4935\n",
      "     Epoch 2: Loss = 1.3896\n",
      "   ✅ Training complete. Final avg loss: 1.4416\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3133\n",
      "     Epoch 2: Loss = 2.2905\n",
      "   ✅ Training complete. Final avg loss: 2.3019\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3108\n",
      "     Epoch 2: Loss = 2.3002\n",
      "   ✅ Training complete. Final avg loss: 2.3055\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6818\n",
      "     Epoch 2: Loss = 1.5357\n",
      "   ✅ Training complete. Final avg loss: 1.6088\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3072\n",
      "     Epoch 2: Loss = 2.2942\n",
      "   ✅ Training complete. Final avg loss: 2.3007\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7663\n",
      "     Epoch 2: Loss = 1.7066\n",
      "   ✅ Training complete. Final avg loss: 1.7364\n",
      "🔧 Training Client 6 (pristine):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6813\n",
      "     Epoch 2: Loss = 1.5067\n",
      "   ✅ Training complete. Final avg loss: 1.5940\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3062\n",
      "     Epoch 2: Loss = 2.2935\n",
      "   ✅ Training complete. Final avg loss: 2.2999\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3300\n",
      "     Epoch 2: Loss = 2.2983\n",
      "   ✅ Training complete. Final avg loss: 2.3142\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.548, Loss=1.323, Loss_std=1.189, Entropy=1.332\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.669\n",
      "      Stability: 0.604, Confidence: 0.467\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.366, Loss_std=1.022, Entropy=1.352\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.658\n",
      "      Stability: 0.659, Confidence: 0.459\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.747\n",
      "   ✅ Decision: KEEP (Score 0.747 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.156, Loss=2.302, Loss_std=0.358, Entropy=2.242\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.521, Loss: 0.425\n",
      "      Stability: 0.881, Confidence: 0.103\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.274\n",
      "   ✅ Decision: KEEP (Score 0.274 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.296, Loss_std=0.102, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.426\n",
      "      Stability: 0.966, Confidence: 0.081\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.266\n",
      "   ✅ Decision: KEEP (Score 0.266 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.476, Loss=1.548, Loss_std=1.183, Entropy=1.397\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.613\n",
      "      Stability: 0.606, Confidence: 0.441\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.722\n",
      "   ✅ Decision: KEEP (Score 0.722 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.151, Loss=2.286, Loss_std=0.177, Entropy=2.288\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.505, Loss: 0.428\n",
      "      Stability: 0.941, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.278\n",
      "   ✅ Decision: KEEP (Score 0.278 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.450, Loss=1.651, Loss_std=1.123, Entropy=1.580\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.587\n",
      "      Stability: 0.626, Confidence: 0.368\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.654\n",
      "   ✅ Decision: KEEP (Score 0.654 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.466, Loss=1.510, Loss_std=1.010, Entropy=1.552\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.623\n",
      "      Stability: 0.663, Confidence: 0.379\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.726\n",
      "   ✅ Decision: KEEP (Score 0.726 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.166, Loss=2.286, Loss_std=0.131, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.553, Loss: 0.428\n",
      "      Stability: 0.956, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.287\n",
      "   ✅ Decision: KEEP (Score 0.287 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.135, Loss=2.291, Loss_std=0.186, Entropy=2.286\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.449, Loss: 0.427\n",
      "      Stability: 0.938, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.268\n",
      "   ✅ Decision: KEEP (Score 0.268 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      1 |  0.980 |     0.747 |    6957 | KEEP     | Score 0.747 ≥ threshold 0.250\n",
      "      2 |      0 |  0.980 |     0.738 |    4764 | KEEP     | Score 0.738 ≥ threshold 0.250\n",
      "      3 |      7 |  0.980 |     0.726 |    2013 | KEEP     | Score 0.726 ≥ threshold 0.250\n",
      "      4 |      4 |  0.980 |     0.722 |    1951 | KEEP     | Score 0.722 ≥ threshold 0.250\n",
      "      5 |      6 |  0.450 |     0.654 |    5331 | KEEP     | Score 0.654 ≥ threshold 0.250\n",
      "      6 |      8 |  0.020 |     0.287 |    4717 | KEEP     | Score 0.287 ≥ threshold 0.250\n",
      "      7 |      5 |  0.020 |     0.278 |    4946 | KEEP     | Score 0.278 ≥ threshold 0.250\n",
      "      8 |      2 |  0.020 |     0.274 |    1990 | KEEP     | Score 0.274 ≥ threshold 0.250\n",
      "      9 |      9 |  0.020 |     0.268 |    1524 | KEEP     | Score 0.268 ≥ threshold 0.250\n",
      "     10 |      3 |  0.020 |     0.266 |    5228 | KEEP     | Score 0.266 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [1, 0, 7, 4, 6, 8, 5, 2, 9, 3])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.496\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        1 | 6957 |   0.747 |  0.176 |  0.176 |   0.176\n",
      "        0 | 4764 |   0.738 |  0.121 |  0.173 |   0.158\n",
      "        7 | 2013 |   0.726 |  0.051 |  0.170 |   0.134\n",
      "        4 | 1951 |   0.722 |  0.049 |  0.168 |   0.133\n",
      "        6 | 5331 |   0.654 |  0.135 |  0.148 |   0.144\n",
      "        8 | 4717 |   0.287 |  0.120 |  0.037 |   0.062\n",
      "        5 | 4946 |   0.278 |  0.125 |  0.034 |   0.061\n",
      "        2 | 1990 |   0.274 |  0.050 |  0.033 |   0.038\n",
      "        9 | 1524 |   0.268 |  0.039 |  0.031 |   0.033\n",
      "        3 | 5228 |   0.266 |  0.133 |  0.030 |   0.061\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.85% accuracy, 2.3371 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9163\n",
      "     Epoch 2: Loss = 1.7575\n",
      "   ✅ Training complete. Final avg loss: 1.8369\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3199\n",
      "     Epoch 2: Loss = 2.2948\n",
      "   ✅ Training complete. Final avg loss: 2.3074\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3376\n",
      "     Epoch 2: Loss = 2.3027\n",
      "   ✅ Training complete. Final avg loss: 2.3201\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3426\n",
      "     Epoch 2: Loss = 2.3034\n",
      "   ✅ Training complete. Final avg loss: 2.3230\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3170\n",
      "     Epoch 2: Loss = 2.2984\n",
      "   ✅ Training complete. Final avg loss: 2.3077\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3245\n",
      "     Epoch 2: Loss = 2.2841\n",
      "   ✅ Training complete. Final avg loss: 2.3043\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7262\n",
      "     Epoch 2: Loss = 1.6839\n",
      "   ✅ Training complete. Final avg loss: 1.7051\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4351\n",
      "     Epoch 2: Loss = 1.3275\n",
      "   ✅ Training complete. Final avg loss: 1.3813\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4725\n",
      "     Epoch 2: Loss = 1.3641\n",
      "   ✅ Training complete. Final avg loss: 1.4183\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5953\n",
      "     Epoch 2: Loss = 1.5106\n",
      "   ✅ Training complete. Final avg loss: 1.5529\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.435, Loss=1.724, Loss_std=0.887, Entropy=1.830\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.569\n",
      "      Stability: 0.704, Confidence: 0.268\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.650\n",
      "   ✅ Decision: KEEP (Score 0.650 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.156, Loss=2.292, Loss_std=0.142, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.521, Loss: 0.427\n",
      "      Stability: 0.953, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.282\n",
      "   ✅ Decision: KEEP (Score 0.282 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.115, Loss=2.300, Loss_std=0.188, Entropy=2.284\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.385, Loss: 0.425\n",
      "      Stability: 0.937, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.258\n",
      "   ✅ Decision: KEEP (Score 0.258 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.111, Loss=2.298, Loss_std=0.218, Entropy=2.279\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.369, Loss: 0.426\n",
      "      Stability: 0.927, Confidence: 0.088\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.254\n",
      "   ✅ Decision: KEEP (Score 0.254 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.099, Loss=2.304, Loss_std=0.153, Entropy=2.289\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.329, Loss: 0.424\n",
      "      Stability: 0.949, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.250\n",
      "   ❌ Decision: FILTER (Score 0.250 < threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.197, Loss=2.261, Loss_std=0.260, Entropy=2.274\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.657, Loss: 0.435\n",
      "      Stability: 0.913, Confidence: 0.091\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.300\n",
      "   ✅ Decision: KEEP (Score 0.300 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.409, Loss=1.763, Loss_std=1.049, Entropy=1.701\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.559\n",
      "      Stability: 0.650, Confidence: 0.320\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.645\n",
      "   ✅ Decision: KEEP (Score 0.645 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.577, Loss=1.279, Loss_std=1.074, Entropy=1.315\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.680\n",
      "      Stability: 0.642, Confidence: 0.474\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.751\n",
      "   ✅ Decision: KEEP (Score 0.751 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.603, Loss=1.223, Loss_std=1.023, Entropy=1.388\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.694\n",
      "      Stability: 0.659, Confidence: 0.445\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.753\n",
      "   ✅ Decision: KEEP (Score 0.753 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.486, Loss=1.413, Loss_std=0.956, Entropy=1.505\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.647\n",
      "      Stability: 0.681, Confidence: 0.398\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.753 |    4764 | KEEP     | Score 0.753 ≥ threshold 0.250\n",
      "      2 |      7 |  0.980 |     0.751 |    6957 | KEEP     | Score 0.751 ≥ threshold 0.250\n",
      "      3 |      9 |  0.980 |     0.738 |    1951 | KEEP     | Score 0.738 ≥ threshold 0.250\n",
      "      4 |      0 |  0.450 |     0.650 |    1210 | KEEP     | Score 0.650 ≥ threshold 0.250\n",
      "      5 |      6 |  0.450 |     0.645 |    5331 | KEEP     | Score 0.645 ≥ threshold 0.250\n",
      "      6 |      5 |  0.020 |     0.300 |    3011 | KEEP     | Score 0.300 ≥ threshold 0.250\n",
      "      7 |      1 |  0.020 |     0.282 |    4717 | KEEP     | Score 0.282 ≥ threshold 0.250\n",
      "      8 |      2 |  0.020 |     0.258 |    2108 | KEEP     | Score 0.258 ≥ threshold 0.250\n",
      "      9 |      3 |  0.020 |     0.254 |    2117 | KEEP     | Score 0.254 ≥ threshold 0.250\n",
      "     10 |      4 |  0.020 |     0.250 |    5228 | FILTER   | Score 0.250 < threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 9 (IDs: [8, 7, 9, 0, 6, 5, 1, 2, 3])\n",
      "   Filter rate: 10.0%\n",
      "   Average quality score: 0.514\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 4764 |   0.753 |  0.148 |  0.185 |   0.174\n",
      "        7 | 6957 |   0.751 |  0.216 |  0.184 |   0.194\n",
      "        9 | 1951 |   0.738 |  0.061 |  0.180 |   0.144\n",
      "        0 | 1210 |   0.650 |  0.038 |  0.153 |   0.118\n",
      "        6 | 5331 |   0.645 |  0.166 |  0.151 |   0.156\n",
      "        5 | 3011 |   0.300 |  0.094 |  0.045 |   0.060\n",
      "        1 | 4717 |   0.282 |  0.147 |  0.039 |   0.072\n",
      "        2 | 2108 |   0.258 |  0.066 |  0.032 |   0.042\n",
      "        3 | 2117 |   0.254 |  0.066 |  0.031 |   0.041\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 19.88% accuracy, 2.3938 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 11: CATASTROPHIC (score: 0.020)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 10: CATASTROPHIC (score: 0.020)\n",
      "   Client 1: PRISTINE (score: 0.980)\n",
      "   Client 7: CATASTROPHIC (score: 0.020)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3447\n",
      "     Epoch 2: Loss = 2.3046\n",
      "   ✅ Training complete. Final avg loss: 2.3246\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3114\n",
      "     Epoch 2: Loss = 2.2920\n",
      "   ✅ Training complete. Final avg loss: 2.3017\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8785\n",
      "     Epoch 2: Loss = 1.7540\n",
      "   ✅ Training complete. Final avg loss: 1.8163\n",
      "🔧 Training Client 11 (catastrophic):\n",
      "   Samples: 2108, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3391\n",
      "     Epoch 2: Loss = 2.2999\n",
      "   ✅ Training complete. Final avg loss: 2.3195\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3708\n",
      "     Epoch 2: Loss = 2.2974\n",
      "   ✅ Training complete. Final avg loss: 2.3341\n",
      "🔧 Training Client 10 (catastrophic):\n",
      "   Samples: 1990, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3317\n",
      "     Epoch 2: Loss = 2.2895\n",
      "   ✅ Training complete. Final avg loss: 2.3106\n",
      "🔧 Training Client 1 (pristine):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4105\n",
      "     Epoch 2: Loss = 1.2972\n",
      "   ✅ Training complete. Final avg loss: 1.3538\n",
      "🔧 Training Client 7 (catastrophic):\n",
      "   Samples: 3011, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3166\n",
      "     Epoch 2: Loss = 2.2837\n",
      "   ✅ Training complete. Final avg loss: 2.3002\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7090\n",
      "     Epoch 2: Loss = 1.6554\n",
      "   ✅ Training complete. Final avg loss: 1.6822\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3742\n",
      "     Epoch 2: Loss = 1.2627\n",
      "   ✅ Training complete. Final avg loss: 1.3185\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.151, Loss=2.282, Loss_std=0.120, Entropy=2.295\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.505, Loss: 0.429\n",
      "      Stability: 0.960, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.280\n",
      "   ✅ Decision: KEEP (Score 0.280 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.135, Loss=2.300, Loss_std=0.195, Entropy=2.285\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.449, Loss: 0.425\n",
      "      Stability: 0.935, Confidence: 0.086\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.268\n",
      "   ✅ Decision: KEEP (Score 0.268 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.397, Loss=1.746, Loss_std=0.887, Entropy=1.845\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.564\n",
      "      Stability: 0.704, Confidence: 0.262\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.296, Loss_std=0.137, Entropy=2.294\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.426\n",
      "      Stability: 0.954, Confidence: 0.082\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.267\n",
      "   ✅ Decision: KEEP (Score 0.267 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.130, Loss=2.299, Loss_std=0.233, Entropy=2.277\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.433, Loss: 0.425\n",
      "      Stability: 0.922, Confidence: 0.089\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.264\n",
      "   ✅ Decision: KEEP (Score 0.264 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.171, Loss=2.288, Loss_std=0.289, Entropy=2.266\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.569, Loss: 0.428\n",
      "      Stability: 0.904, Confidence: 0.094\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.284\n",
      "   ✅ Decision: KEEP (Score 0.284 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.567, Loss=1.297, Loss_std=1.103, Entropy=1.325\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.676\n",
      "      Stability: 0.632, Confidence: 0.470\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.747\n",
      "   ✅ Decision: KEEP (Score 0.747 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.197, Loss=2.268, Loss_std=0.200, Entropy=2.287\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.657, Loss: 0.433\n",
      "      Stability: 0.933, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.302\n",
      "   ✅ Decision: KEEP (Score 0.302 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.471, Loss=1.585, Loss_std=1.091, Entropy=1.614\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.604\n",
      "      Stability: 0.636, Confidence: 0.354\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.658\n",
      "   ✅ Decision: KEEP (Score 0.658 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.579, Loss=1.170, Loss_std=0.991, Entropy=1.266\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.707\n",
      "      Stability: 0.670, Confidence: 0.494\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.767\n",
      "   ✅ Decision: KEEP (Score 0.767 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      9 |  0.980 |     0.767 |    6957 | KEEP     | Score 0.767 ≥ threshold 0.250\n",
      "      2 |      6 |  0.980 |     0.747 |    4764 | KEEP     | Score 0.747 ≥ threshold 0.250\n",
      "      3 |      8 |  0.450 |     0.658 |    5331 | KEEP     | Score 0.658 ≥ threshold 0.250\n",
      "      4 |      2 |  0.450 |     0.647 |    1210 | KEEP     | Score 0.647 ≥ threshold 0.250\n",
      "      5 |      7 |  0.020 |     0.302 |    3011 | KEEP     | Score 0.302 ≥ threshold 0.250\n",
      "      6 |      5 |  0.020 |     0.284 |    1990 | KEEP     | Score 0.284 ≥ threshold 0.250\n",
      "      7 |      0 |  0.020 |     0.280 |    2117 | KEEP     | Score 0.280 ≥ threshold 0.250\n",
      "      8 |      1 |  0.020 |     0.268 |    4946 | KEEP     | Score 0.268 ≥ threshold 0.250\n",
      "      9 |      3 |  0.020 |     0.267 |    2108 | KEEP     | Score 0.267 ≥ threshold 0.250\n",
      "     10 |      4 |  0.020 |     0.264 |    1524 | KEEP     | Score 0.264 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [9, 6, 8, 2, 7, 5, 0, 1, 3, 4])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.448\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        9 | 6957 |   0.767 |  0.205 |  0.212 |   0.210\n",
      "        6 | 4764 |   0.747 |  0.140 |  0.205 |   0.185\n",
      "        8 | 5331 |   0.658 |  0.157 |  0.174 |   0.169\n",
      "        2 | 1210 |   0.647 |  0.036 |  0.170 |   0.130\n",
      "        7 | 3011 |   0.302 |  0.089 |  0.049 |   0.061\n",
      "        5 | 1990 |   0.284 |  0.059 |  0.042 |   0.047\n",
      "        0 | 2117 |   0.280 |  0.062 |  0.041 |   0.047\n",
      "        1 | 4946 |   0.268 |  0.146 |  0.036 |   0.069\n",
      "        3 | 2108 |   0.267 |  0.062 |  0.036 |   0.044\n",
      "        4 | 1524 |   0.264 |  0.045 |  0.035 |   0.038\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 20.47% accuracy, 2.4852 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 5: DEGRADED (score: 0.450)\n",
      "   Client 13: CATASTROPHIC (score: 0.020)\n",
      "   Client 3: CATASTROPHIC (score: 0.020)\n",
      "   Client 8: DEGRADED (score: 0.450)\n",
      "   Client 2: CATASTROPHIC (score: 0.020)\n",
      "   Client 0: PRISTINE (score: 0.980)\n",
      "   Client 14: DEGRADED (score: 0.450)\n",
      "   Client 4: CATASTROPHIC (score: 0.020)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 12: CATASTROPHIC (score: 0.020)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 5 (degraded):\n",
      "   Samples: 2133, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7658\n",
      "     Epoch 2: Loss = 1.7130\n",
      "   ✅ Training complete. Final avg loss: 1.7394\n",
      "🔧 Training Client 13 (catastrophic):\n",
      "   Samples: 1524, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3435\n",
      "     Epoch 2: Loss = 2.2941\n",
      "   ✅ Training complete. Final avg loss: 2.3188\n",
      "🔧 Training Client 3 (catastrophic):\n",
      "   Samples: 4946, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3090\n",
      "     Epoch 2: Loss = 2.2939\n",
      "   ✅ Training complete. Final avg loss: 2.3014\n",
      "🔧 Training Client 8 (degraded):\n",
      "   Samples: 1210, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8566\n",
      "     Epoch 2: Loss = 1.7465\n",
      "   ✅ Training complete. Final avg loss: 1.8016\n",
      "🔧 Training Client 2 (catastrophic):\n",
      "   Samples: 4717, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3201\n",
      "     Epoch 2: Loss = 2.2940\n",
      "   ✅ Training complete. Final avg loss: 2.3071\n",
      "🔧 Training Client 0 (pristine):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3158\n",
      "     Epoch 2: Loss = 1.2123\n",
      "   ✅ Training complete. Final avg loss: 1.2641\n",
      "🔧 Training Client 14 (degraded):\n",
      "   Samples: 5331, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.6799\n",
      "     Epoch 2: Loss = 1.6390\n",
      "   ✅ Training complete. Final avg loss: 1.6594\n",
      "🔧 Training Client 4 (catastrophic):\n",
      "   Samples: 2117, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3342\n",
      "     Epoch 2: Loss = 2.3021\n",
      "   ✅ Training complete. Final avg loss: 2.3181\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5574\n",
      "     Epoch 2: Loss = 1.4617\n",
      "   ✅ Training complete. Final avg loss: 1.5095\n",
      "🔧 Training Client 12 (catastrophic):\n",
      "   Samples: 5228, Quality: 0.020\n",
      "     Epoch 1: Loss = 2.3128\n",
      "     Epoch 2: Loss = 2.2989\n",
      "   ✅ Training complete. Final avg loss: 2.3059\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.493, Loss=1.637, Loss_std=0.913, Entropy=1.833\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.591\n",
      "      Stability: 0.696, Confidence: 0.267\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.652\n",
      "   ✅ Decision: KEEP (Score 0.652 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.166, Loss=2.278, Loss_std=0.177, Entropy=2.288\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.553, Loss: 0.431\n",
      "      Stability: 0.941, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.286\n",
      "   ✅ Decision: KEEP (Score 0.286 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.147, Loss=2.297, Loss_std=0.167, Entropy=2.290\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.489, Loss: 0.426\n",
      "      Stability: 0.944, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.275\n",
      "   ✅ Decision: KEEP (Score 0.275 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.442, Loss=1.706, Loss_std=0.975, Entropy=1.723\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.574\n",
      "      Stability: 0.675, Confidence: 0.311\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.652\n",
      "   ✅ Decision: KEEP (Score 0.652 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.142, Loss=2.295, Loss_std=0.173, Entropy=2.289\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.473, Loss: 0.426\n",
      "      Stability: 0.942, Confidence: 0.085\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.272\n",
      "   ✅ Decision: KEEP (Score 0.272 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.627, Loss=1.107, Loss_std=0.956, Entropy=1.257\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.723\n",
      "      Stability: 0.681, Confidence: 0.497\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.774\n",
      "   ✅ Decision: KEEP (Score 0.774 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.601, Loss_std=1.071, Entropy=1.652\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.600\n",
      "      Stability: 0.643, Confidence: 0.339\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.656\n",
      "   ✅ Decision: KEEP (Score 0.656 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.125, Loss=2.300, Loss_std=0.150, Entropy=2.291\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.417, Loss: 0.425\n",
      "      Stability: 0.950, Confidence: 0.084\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.264\n",
      "   ✅ Decision: KEEP (Score 0.264 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.529, Loss=1.391, Loss_std=0.844, Entropy=1.577\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.652\n",
      "      Stability: 0.719, Confidence: 0.369\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.743\n",
      "   ✅ Decision: KEEP (Score 0.743 ≥ threshold 0.250)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.020)\n",
      "   📊 Metrics: Acc=0.101, Loss=2.303, Loss_std=0.141, Entropy=2.292\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.337, Loss: 0.424\n",
      "      Stability: 0.953, Confidence: 0.083\n",
      "      Harm penalty: 0.400, Size penalty: 0.000\n",
      "      Final score: 0.251\n",
      "   ✅ Decision: KEEP (Score 0.251 ≥ threshold 0.250)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      5 |  0.980 |     0.774 |    6957 | KEEP     | Score 0.774 ≥ threshold 0.250\n",
      "      2 |      8 |  0.980 |     0.743 |    1951 | KEEP     | Score 0.743 ≥ threshold 0.250\n",
      "      3 |      6 |  0.450 |     0.656 |    5331 | KEEP     | Score 0.656 ≥ threshold 0.250\n",
      "      4 |      0 |  0.450 |     0.652 |    2133 | KEEP     | Score 0.652 ≥ threshold 0.250\n",
      "      5 |      3 |  0.450 |     0.652 |    1210 | KEEP     | Score 0.652 ≥ threshold 0.250\n",
      "      6 |      1 |  0.020 |     0.286 |    1524 | KEEP     | Score 0.286 ≥ threshold 0.250\n",
      "      7 |      2 |  0.020 |     0.275 |    4946 | KEEP     | Score 0.275 ≥ threshold 0.250\n",
      "      8 |      4 |  0.020 |     0.272 |    4717 | KEEP     | Score 0.272 ≥ threshold 0.250\n",
      "      9 |      7 |  0.020 |     0.264 |    2117 | KEEP     | Score 0.264 ≥ threshold 0.250\n",
      "     10 |      9 |  0.020 |     0.251 |    5228 | KEEP     | Score 0.251 ≥ threshold 0.250\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [5, 8, 6, 0, 3, 1, 2, 4, 7, 9])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.483\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for catastrophic\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: catastrophic\n",
      "   Quality emphasis: 70.0%, Size emphasis: 30.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        5 | 6957 |   0.774 |  0.193 |  0.188 |   0.189\n",
      "        8 | 1951 |   0.743 |  0.054 |  0.179 |   0.141\n",
      "        6 | 5331 |   0.656 |  0.148 |  0.152 |   0.151\n",
      "        0 | 2133 |   0.652 |  0.059 |  0.151 |   0.124\n",
      "        3 | 1210 |   0.652 |  0.034 |  0.151 |   0.116\n",
      "        1 | 1524 |   0.286 |  0.042 |  0.041 |   0.041\n",
      "        2 | 4946 |   0.275 |  0.137 |  0.037 |   0.067\n",
      "        4 | 4717 |   0.272 |  0.131 |  0.037 |   0.065\n",
      "        7 | 2117 |   0.264 |  0.059 |  0.034 |   0.041\n",
      "        9 | 5228 |   0.251 |  0.145 |  0.030 |   0.065\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 19.12% accuracy, 2.7353 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 19.12%\n",
      "   Best Accuracy: 20.47%\n",
      "   avg_filter_rate: 0.012\n",
      "   max_filter_rate: 0.100\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 7/8\n",
      "   Learning Rate: 0.01\n",
      "   Extreme Type: byzantine\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'byzantine':\n",
      "   50% honest, 20% poor quality, 30% BYZANTINE (adversarial)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_byzantine_lr0.01_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  PRISTINE: 7 clients\n",
      "  DEGRADED: 3 clients\n",
      "  BYZANTINE: 5 clients\n",
      "   💀 Client 0 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 1 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 2 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 3 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 4 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 5 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 6 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 7 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 8 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 9 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 10 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "   💀 Client 11 (pristine): PRISTINE: No corruption\n",
      "   💀 Client 12 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 13 (degraded): DEGRADED: 15% label noise, 30% image corruption\n",
      "   💀 Client 14 (byzantine): BYZANTINE: Adversarial labels + hostile noise\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.010 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   BYZANTINE: 5 clients (avg score: 0.010)\n",
      "   PRISTINE: 7 clients (avg score: 0.980)\n",
      "   DEGRADED: 3 clients (avg score: 0.450)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs BYZANTINE\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.7800\n",
      "     Epoch 2: Loss = 1.5498\n",
      "   ✅ Training complete. Final avg loss: 1.6649\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0113\n",
      "     Epoch 2: Loss = 1.7995\n",
      "   ✅ Training complete. Final avg loss: 1.9054\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0019\n",
      "     Epoch 2: Loss = 1.7918\n",
      "   ✅ Training complete. Final avg loss: 1.8968\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5503\n",
      "     Epoch 2: Loss = 1.2924\n",
      "   ✅ Training complete. Final avg loss: 1.4213\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1613\n",
      "     Epoch 2: Loss = 2.0607\n",
      "   ✅ Training complete. Final avg loss: 2.1110\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8544\n",
      "     Epoch 2: Loss = 1.7037\n",
      "   ✅ Training complete. Final avg loss: 1.7790\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7115\n",
      "     Epoch 2: Loss = 1.5342\n",
      "   ✅ Training complete. Final avg loss: 1.6228\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2307\n",
      "     Epoch 2: Loss = 2.0738\n",
      "   ✅ Training complete. Final avg loss: 2.1522\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5602\n",
      "     Epoch 2: Loss = 1.3424\n",
      "   ✅ Training complete. Final avg loss: 1.4513\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9747\n",
      "     Epoch 2: Loss = 1.7910\n",
      "   ✅ Training complete. Final avg loss: 1.8829\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=3686, Weight=0.1035, Quality=byzantine\n",
      "  Client 1: Size=1990, Weight=0.0559, Quality=degraded\n",
      "  Client 2: Size=1753, Weight=0.0492, Quality=pristine\n",
      "  Client 3: Size=3432, Weight=0.0964, Quality=pristine\n",
      "  Client 4: Size=6352, Weight=0.1784, Quality=degraded\n",
      "  Client 5: Size=5934, Weight=0.1666, Quality=pristine\n",
      "  Client 6: Size=4303, Weight=0.1208, Quality=pristine\n",
      "  Client 7: Size=1877, Weight=0.0527, Quality=byzantine\n",
      "  Client 8: Size=4072, Weight=0.1143, Quality=pristine\n",
      "  Client 9: Size=2211, Weight=0.0621, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 16.37% accuracy, 2.2816 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0689\n",
      "     Epoch 2: Loss = 1.9954\n",
      "   ✅ Training complete. Final avg loss: 2.0322\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0359\n",
      "     Epoch 2: Loss = 1.9784\n",
      "   ✅ Training complete. Final avg loss: 2.0071\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8201\n",
      "     Epoch 2: Loss = 1.6588\n",
      "   ✅ Training complete. Final avg loss: 1.7394\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1298\n",
      "     Epoch 2: Loss = 2.0382\n",
      "   ✅ Training complete. Final avg loss: 2.0840\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3990\n",
      "     Epoch 2: Loss = 1.1963\n",
      "   ✅ Training complete. Final avg loss: 1.2976\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8887\n",
      "     Epoch 2: Loss = 1.7313\n",
      "   ✅ Training complete. Final avg loss: 1.8100\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5801\n",
      "     Epoch 2: Loss = 1.4142\n",
      "   ✅ Training complete. Final avg loss: 1.4972\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6419\n",
      "     Epoch 2: Loss = 1.5530\n",
      "   ✅ Training complete. Final avg loss: 1.5974\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7377\n",
      "     Epoch 2: Loss = 1.5772\n",
      "   ✅ Training complete. Final avg loss: 1.6574\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0582\n",
      "     Epoch 2: Loss = 1.9329\n",
      "   ✅ Training complete. Final avg loss: 1.9956\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2419, Weight=0.0645, Quality=byzantine\n",
      "  Client 1: Size=4484, Weight=0.1195, Quality=byzantine\n",
      "  Client 2: Size=2211, Weight=0.0589, Quality=pristine\n",
      "  Client 3: Size=2714, Weight=0.0723, Quality=byzantine\n",
      "  Client 4: Size=3432, Weight=0.0915, Quality=pristine\n",
      "  Client 5: Size=1990, Weight=0.0530, Quality=degraded\n",
      "  Client 6: Size=4303, Weight=0.1147, Quality=pristine\n",
      "  Client 7: Size=3686, Weight=0.0982, Quality=byzantine\n",
      "  Client 8: Size=5934, Weight=0.1581, Quality=pristine\n",
      "  Client 9: Size=6352, Weight=0.1693, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 21.87% accuracy, 2.3082 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0853\n",
      "     Epoch 2: Loss = 1.9751\n",
      "   ✅ Training complete. Final avg loss: 2.0302\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7806\n",
      "     Epoch 2: Loss = 1.6675\n",
      "   ✅ Training complete. Final avg loss: 1.7241\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4725\n",
      "     Epoch 2: Loss = 1.2784\n",
      "   ✅ Training complete. Final avg loss: 1.3755\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4380\n",
      "     Epoch 2: Loss = 1.3391\n",
      "   ✅ Training complete. Final avg loss: 1.3886\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2067\n",
      "     Epoch 2: Loss = 1.0778\n",
      "   ✅ Training complete. Final avg loss: 1.1422\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6555\n",
      "     Epoch 2: Loss = 1.5285\n",
      "   ✅ Training complete. Final avg loss: 1.5920\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9522\n",
      "     Epoch 2: Loss = 1.9151\n",
      "   ✅ Training complete. Final avg loss: 1.9337\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7774\n",
      "     Epoch 2: Loss = 1.6319\n",
      "   ✅ Training complete. Final avg loss: 1.7047\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1271\n",
      "     Epoch 2: Loss = 2.0039\n",
      "   ✅ Training complete. Final avg loss: 2.0655\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8917\n",
      "     Epoch 2: Loss = 1.7383\n",
      "   ✅ Training complete. Final avg loss: 1.8150\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2714, Weight=0.0804, Quality=byzantine\n",
      "  Client 1: Size=1990, Weight=0.0590, Quality=degraded\n",
      "  Client 2: Size=4072, Weight=0.1207, Quality=pristine\n",
      "  Client 3: Size=4303, Weight=0.1275, Quality=pristine\n",
      "  Client 4: Size=3432, Weight=0.1017, Quality=pristine\n",
      "  Client 5: Size=3686, Weight=0.1092, Quality=byzantine\n",
      "  Client 6: Size=6352, Weight=0.1883, Quality=degraded\n",
      "  Client 7: Size=2868, Weight=0.0850, Quality=pristine\n",
      "  Client 8: Size=2419, Weight=0.0717, Quality=byzantine\n",
      "  Client 9: Size=1905, Weight=0.0565, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 25.48% accuracy, 2.2681 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6677\n",
      "     Epoch 2: Loss = 1.6035\n",
      "   ✅ Training complete. Final avg loss: 1.6356\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1695\n",
      "     Epoch 2: Loss = 1.9895\n",
      "   ✅ Training complete. Final avg loss: 2.0795\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4004\n",
      "     Epoch 2: Loss = 1.3119\n",
      "   ✅ Training complete. Final avg loss: 1.3561\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5985\n",
      "     Epoch 2: Loss = 1.5338\n",
      "   ✅ Training complete. Final avg loss: 1.5661\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6482\n",
      "     Epoch 2: Loss = 1.5193\n",
      "   ✅ Training complete. Final avg loss: 1.5837\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5877\n",
      "     Epoch 2: Loss = 1.4741\n",
      "   ✅ Training complete. Final avg loss: 1.5309\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7255\n",
      "     Epoch 2: Loss = 1.6499\n",
      "   ✅ Training complete. Final avg loss: 1.6877\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1589\n",
      "     Epoch 2: Loss = 1.0453\n",
      "   ✅ Training complete. Final avg loss: 1.1021\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9229\n",
      "     Epoch 2: Loss = 1.8849\n",
      "   ✅ Training complete. Final avg loss: 1.9039\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0361\n",
      "     Epoch 2: Loss = 1.9392\n",
      "   ✅ Training complete. Final avg loss: 1.9876\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2868, Weight=0.0761, Quality=pristine\n",
      "  Client 1: Size=2419, Weight=0.0642, Quality=byzantine\n",
      "  Client 2: Size=4303, Weight=0.1142, Quality=pristine\n",
      "  Client 3: Size=5934, Weight=0.1575, Quality=pristine\n",
      "  Client 4: Size=3686, Weight=0.0978, Quality=byzantine\n",
      "  Client 5: Size=2211, Weight=0.0587, Quality=pristine\n",
      "  Client 6: Size=1990, Weight=0.0528, Quality=degraded\n",
      "  Client 7: Size=3432, Weight=0.0911, Quality=pristine\n",
      "  Client 8: Size=6352, Weight=0.1686, Quality=degraded\n",
      "  Client 9: Size=4484, Weight=0.1190, Quality=byzantine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 25.03% accuracy, 2.3821 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7330\n",
      "     Epoch 2: Loss = 1.5824\n",
      "   ✅ Training complete. Final avg loss: 1.6577\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1862\n",
      "     Epoch 2: Loss = 1.9792\n",
      "   ✅ Training complete. Final avg loss: 2.0827\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1352\n",
      "     Epoch 2: Loss = 1.0337\n",
      "   ✅ Training complete. Final avg loss: 1.0845\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0054\n",
      "     Epoch 2: Loss = 1.9220\n",
      "   ✅ Training complete. Final avg loss: 1.9637\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6720\n",
      "     Epoch 2: Loss = 1.5867\n",
      "   ✅ Training complete. Final avg loss: 1.6293\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8011\n",
      "     Epoch 2: Loss = 1.6919\n",
      "   ✅ Training complete. Final avg loss: 1.7465\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8950\n",
      "     Epoch 2: Loss = 1.8527\n",
      "   ✅ Training complete. Final avg loss: 1.8739\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1930\n",
      "     Epoch 2: Loss = 2.0058\n",
      "   ✅ Training complete. Final avg loss: 2.0994\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7395\n",
      "     Epoch 2: Loss = 1.6381\n",
      "   ✅ Training complete. Final avg loss: 1.6888\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3823\n",
      "     Epoch 2: Loss = 1.3001\n",
      "   ✅ Training complete. Final avg loss: 1.3412\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1753, Weight=0.0559, Quality=pristine\n",
      "  Client 1: Size=2419, Weight=0.0771, Quality=byzantine\n",
      "  Client 2: Size=3432, Weight=0.1094, Quality=pristine\n",
      "  Client 3: Size=4484, Weight=0.1429, Quality=byzantine\n",
      "  Client 4: Size=2868, Weight=0.0914, Quality=pristine\n",
      "  Client 5: Size=1905, Weight=0.0607, Quality=degraded\n",
      "  Client 6: Size=6352, Weight=0.2024, Quality=degraded\n",
      "  Client 7: Size=1877, Weight=0.0598, Quality=byzantine\n",
      "  Client 8: Size=1990, Weight=0.0634, Quality=degraded\n",
      "  Client 9: Size=4303, Weight=0.1371, Quality=pristine\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 25.42% accuracy, 2.2706 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7490\n",
      "     Epoch 2: Loss = 1.6729\n",
      "   ✅ Training complete. Final avg loss: 1.7109\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0288\n",
      "     Epoch 2: Loss = 1.9004\n",
      "   ✅ Training complete. Final avg loss: 1.9646\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7199\n",
      "     Epoch 2: Loss = 1.5623\n",
      "   ✅ Training complete. Final avg loss: 1.6411\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3391\n",
      "     Epoch 2: Loss = 1.2027\n",
      "   ✅ Training complete. Final avg loss: 1.2709\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8658\n",
      "     Epoch 2: Loss = 1.8328\n",
      "   ✅ Training complete. Final avg loss: 1.8493\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6214\n",
      "     Epoch 2: Loss = 1.5623\n",
      "   ✅ Training complete. Final avg loss: 1.5918\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1749\n",
      "     Epoch 2: Loss = 1.9970\n",
      "   ✅ Training complete. Final avg loss: 2.0859\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.0945\n",
      "     Epoch 2: Loss = 1.0176\n",
      "   ✅ Training complete. Final avg loss: 1.0560\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1358\n",
      "     Epoch 2: Loss = 1.9678\n",
      "   ✅ Training complete. Final avg loss: 2.0518\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7016\n",
      "     Epoch 2: Loss = 1.6160\n",
      "   ✅ Training complete. Final avg loss: 1.6588\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1905, Weight=0.0648, Quality=degraded\n",
      "  Client 1: Size=2714, Weight=0.0924, Quality=byzantine\n",
      "  Client 2: Size=1753, Weight=0.0597, Quality=pristine\n",
      "  Client 3: Size=4072, Weight=0.1386, Quality=pristine\n",
      "  Client 4: Size=6352, Weight=0.2162, Quality=degraded\n",
      "  Client 5: Size=2868, Weight=0.0976, Quality=pristine\n",
      "  Client 6: Size=1877, Weight=0.0639, Quality=byzantine\n",
      "  Client 7: Size=3432, Weight=0.1168, Quality=pristine\n",
      "  Client 8: Size=2419, Weight=0.0823, Quality=byzantine\n",
      "  Client 9: Size=1990, Weight=0.0677, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 24.95% accuracy, 2.3317 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5985\n",
      "     Epoch 2: Loss = 1.5388\n",
      "   ✅ Training complete. Final avg loss: 1.5686\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8591\n",
      "     Epoch 2: Loss = 1.8165\n",
      "   ✅ Training complete. Final avg loss: 1.8378\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0017\n",
      "     Epoch 2: Loss = 1.9094\n",
      "   ✅ Training complete. Final avg loss: 1.9555\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3451\n",
      "     Epoch 2: Loss = 1.2818\n",
      "   ✅ Training complete. Final avg loss: 1.3135\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5530\n",
      "     Epoch 2: Loss = 1.4268\n",
      "   ✅ Training complete. Final avg loss: 1.4899\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6835\n",
      "     Epoch 2: Loss = 1.4973\n",
      "   ✅ Training complete. Final avg loss: 1.5904\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6692\n",
      "     Epoch 2: Loss = 1.5579\n",
      "   ✅ Training complete. Final avg loss: 1.6135\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0222\n",
      "     Epoch 2: Loss = 1.8744\n",
      "   ✅ Training complete. Final avg loss: 1.9483\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5507\n",
      "     Epoch 2: Loss = 1.4776\n",
      "   ✅ Training complete. Final avg loss: 1.5141\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.6879\n",
      "     Epoch 2: Loss = 1.6141\n",
      "   ✅ Training complete. Final avg loss: 1.6510\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2868, Weight=0.0790, Quality=pristine\n",
      "  Client 1: Size=6352, Weight=0.1750, Quality=degraded\n",
      "  Client 2: Size=4484, Weight=0.1235, Quality=byzantine\n",
      "  Client 3: Size=4303, Weight=0.1186, Quality=pristine\n",
      "  Client 4: Size=2211, Weight=0.0609, Quality=pristine\n",
      "  Client 5: Size=3686, Weight=0.1016, Quality=byzantine\n",
      "  Client 6: Size=1753, Weight=0.0483, Quality=pristine\n",
      "  Client 7: Size=2714, Weight=0.0748, Quality=byzantine\n",
      "  Client 8: Size=5934, Weight=0.1635, Quality=pristine\n",
      "  Client 9: Size=1990, Weight=0.0548, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 26.03% accuracy, 2.2937 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1737\n",
      "     Epoch 2: Loss = 1.9471\n",
      "   ✅ Training complete. Final avg loss: 2.0604\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5212\n",
      "     Epoch 2: Loss = 1.4585\n",
      "   ✅ Training complete. Final avg loss: 1.4898\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1575\n",
      "     Epoch 2: Loss = 1.9558\n",
      "   ✅ Training complete. Final avg loss: 2.0566\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3104\n",
      "     Epoch 2: Loss = 1.2607\n",
      "   ✅ Training complete. Final avg loss: 1.2856\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0031\n",
      "     Epoch 2: Loss = 1.8727\n",
      "   ✅ Training complete. Final avg loss: 1.9379\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1140\n",
      "     Epoch 2: Loss = 0.9933\n",
      "   ✅ Training complete. Final avg loss: 1.0536\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6358\n",
      "     Epoch 2: Loss = 1.4932\n",
      "   ✅ Training complete. Final avg loss: 1.5645\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8233\n",
      "     Epoch 2: Loss = 1.7918\n",
      "   ✅ Training complete. Final avg loss: 1.8076\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5018\n",
      "     Epoch 2: Loss = 1.3991\n",
      "   ✅ Training complete. Final avg loss: 1.4504\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.6865\n",
      "     Epoch 2: Loss = 1.6056\n",
      "   ✅ Training complete. Final avg loss: 1.6461\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   byzantine scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=1877, Weight=0.0538, Quality=byzantine\n",
      "  Client 1: Size=5934, Weight=0.1699, Quality=pristine\n",
      "  Client 2: Size=2419, Weight=0.0693, Quality=byzantine\n",
      "  Client 3: Size=4303, Weight=0.1232, Quality=pristine\n",
      "  Client 4: Size=2714, Weight=0.0777, Quality=byzantine\n",
      "  Client 5: Size=3432, Weight=0.0983, Quality=pristine\n",
      "  Client 6: Size=3686, Weight=0.1056, Quality=byzantine\n",
      "  Client 7: Size=6352, Weight=0.1819, Quality=degraded\n",
      "  Client 8: Size=2211, Weight=0.0633, Quality=pristine\n",
      "  Client 9: Size=1990, Weight=0.0570, Quality=degraded\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 26.62% accuracy, 2.4008 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 26.62%\n",
      "   Best Accuracy: 26.62%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs BYZANTINE\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'byzantine':\n",
      "   Quality threshold: 0.400\n",
      "   Minimum clients ratio: 30.0%\n",
      "   Harm detection threshold: 0.100\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.7800\n",
      "     Epoch 2: Loss = 1.5498\n",
      "   ✅ Training complete. Final avg loss: 1.6649\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0113\n",
      "     Epoch 2: Loss = 1.7995\n",
      "   ✅ Training complete. Final avg loss: 1.9054\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0019\n",
      "     Epoch 2: Loss = 1.7918\n",
      "   ✅ Training complete. Final avg loss: 1.8968\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5503\n",
      "     Epoch 2: Loss = 1.2924\n",
      "   ✅ Training complete. Final avg loss: 1.4214\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.1611\n",
      "     Epoch 2: Loss = 2.0609\n",
      "   ✅ Training complete. Final avg loss: 2.1110\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8544\n",
      "     Epoch 2: Loss = 1.7036\n",
      "   ✅ Training complete. Final avg loss: 1.7790\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7115\n",
      "     Epoch 2: Loss = 1.5341\n",
      "   ✅ Training complete. Final avg loss: 1.6228\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2307\n",
      "     Epoch 2: Loss = 2.0738\n",
      "   ✅ Training complete. Final avg loss: 2.1522\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5602\n",
      "     Epoch 2: Loss = 1.3423\n",
      "   ✅ Training complete. Final avg loss: 1.4512\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9747\n",
      "     Epoch 2: Loss = 1.7911\n",
      "   ✅ Training complete. Final avg loss: 1.8829\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.457, Loss=1.525, Loss_std=0.983, Entropy=1.544\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.619\n",
      "      Stability: 0.672, Confidence: 0.382\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.630\n",
      "   ✅ Decision: KEEP (Score 0.630 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.332, Loss=1.854, Loss_std=0.823, Entropy=1.931\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.537\n",
      "      Stability: 0.726, Confidence: 0.228\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.640\n",
      "   ✅ Decision: KEEP (Score 0.640 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.262, Loss=1.735, Loss_std=0.693, Entropy=1.854\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.873, Loss: 0.566\n",
      "      Stability: 0.769, Confidence: 0.258\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.681\n",
      "   ✅ Decision: KEEP (Score 0.681 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.555, Loss=1.414, Loss_std=1.464, Entropy=1.106\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.646\n",
      "      Stability: 0.512, Confidence: 0.557\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.729\n",
      "   ✅ Decision: KEEP (Score 0.729 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.322, Loss=1.971, Loss_std=0.737, Entropy=1.992\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.507\n",
      "      Stability: 0.754, Confidence: 0.203\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.635\n",
      "   ✅ Decision: KEEP (Score 0.635 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.332, Loss=1.637, Loss_std=0.922, Entropy=1.579\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.591\n",
      "      Stability: 0.693, Confidence: 0.369\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.723\n",
      "   ✅ Decision: KEEP (Score 0.723 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.474, Loss=1.595, Loss_std=0.932, Entropy=1.701\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.601\n",
      "      Stability: 0.689, Confidence: 0.320\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.212, Loss=2.047, Loss_std=0.609, Entropy=2.043\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.705, Loss: 0.488\n",
      "      Stability: 0.797, Confidence: 0.183\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.513\n",
      "   ✅ Decision: KEEP (Score 0.513 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.512, Loss=1.396, Loss_std=1.264, Entropy=1.210\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.651\n",
      "      Stability: 0.579, Confidence: 0.516\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.296, Loss=1.669, Loss_std=0.814, Entropy=1.694\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.986, Loss: 0.583\n",
      "      Stability: 0.729, Confidence: 0.322\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.717\n",
      "   ✅ Decision: KEEP (Score 0.717 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      8 |  0.980 |     0.738 |    4072 | KEEP     | Score 0.738 ≥ threshold 0.400\n",
      "      2 |      3 |  0.980 |     0.729 |    3432 | KEEP     | Score 0.729 ≥ threshold 0.400\n",
      "      3 |      5 |  0.980 |     0.723 |    5934 | KEEP     | Score 0.723 ≥ threshold 0.400\n",
      "      4 |      9 |  0.980 |     0.717 |    2211 | KEEP     | Score 0.717 ≥ threshold 0.400\n",
      "      5 |      6 |  0.980 |     0.716 |    4303 | KEEP     | Score 0.716 ≥ threshold 0.400\n",
      "      6 |      2 |  0.980 |     0.681 |    1753 | KEEP     | Score 0.681 ≥ threshold 0.400\n",
      "      7 |      1 |  0.450 |     0.640 |    1990 | KEEP     | Score 0.640 ≥ threshold 0.400\n",
      "      8 |      4 |  0.450 |     0.635 |    6352 | KEEP     | Score 0.635 ≥ threshold 0.400\n",
      "      9 |      0 |  0.010 |     0.630 |    3686 | KEEP     | Score 0.630 ≥ threshold 0.400\n",
      "     10 |      7 |  0.010 |     0.513 |    1877 | KEEP     | Score 0.513 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [8, 3, 5, 9, 6, 2, 1, 4, 0, 7])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.672\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        8 | 4072 |   0.738 |  0.114 |  0.125 |   0.124\n",
      "        3 | 3432 |   0.729 |  0.096 |  0.122 |   0.119\n",
      "        5 | 5934 |   0.723 |  0.167 |  0.120 |   0.124\n",
      "        9 | 2211 |   0.717 |  0.062 |  0.117 |   0.112\n",
      "        6 | 4303 |   0.716 |  0.121 |  0.117 |   0.117\n",
      "        2 | 1753 |   0.681 |  0.049 |  0.103 |   0.098\n",
      "        1 | 1990 |   0.640 |  0.056 |  0.088 |   0.084\n",
      "        4 | 6352 |   0.635 |  0.178 |  0.086 |   0.095\n",
      "        0 | 3686 |   0.630 |  0.104 |  0.084 |   0.086\n",
      "        7 | 1877 |   0.513 |  0.053 |  0.039 |   0.040\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 13.58% accuracy, 2.2915 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0677\n",
      "     Epoch 2: Loss = 2.0043\n",
      "   ✅ Training complete. Final avg loss: 2.0360\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0387\n",
      "     Epoch 2: Loss = 1.9713\n",
      "   ✅ Training complete. Final avg loss: 2.0050\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8366\n",
      "     Epoch 2: Loss = 1.6860\n",
      "   ✅ Training complete. Final avg loss: 1.7613\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1287\n",
      "     Epoch 2: Loss = 2.0400\n",
      "   ✅ Training complete. Final avg loss: 2.0844\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4041\n",
      "     Epoch 2: Loss = 1.2351\n",
      "   ✅ Training complete. Final avg loss: 1.3196\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8723\n",
      "     Epoch 2: Loss = 1.7349\n",
      "   ✅ Training complete. Final avg loss: 1.8036\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5967\n",
      "     Epoch 2: Loss = 1.4399\n",
      "   ✅ Training complete. Final avg loss: 1.5183\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6490\n",
      "     Epoch 2: Loss = 1.5545\n",
      "   ✅ Training complete. Final avg loss: 1.6018\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7599\n",
      "     Epoch 2: Loss = 1.5842\n",
      "   ✅ Training complete. Final avg loss: 1.6720\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 2.0910\n",
      "     Epoch 2: Loss = 1.9430\n",
      "   ✅ Training complete. Final avg loss: 2.0170\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.322, Loss=1.915, Loss_std=0.758, Entropy=1.935\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.521\n",
      "      Stability: 0.747, Confidence: 0.226\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.597\n",
      "   ✅ Decision: KEEP (Score 0.597 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.228, Loss=1.927, Loss_std=0.601, Entropy=1.932\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.761, Loss: 0.518\n",
      "      Stability: 0.800, Confidence: 0.227\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.544\n",
      "   ✅ Decision: KEEP (Score 0.544 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.435, Loss=1.651, Loss_std=0.904, Entropy=1.726\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.587\n",
      "      Stability: 0.699, Confidence: 0.309\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.713\n",
      "   ✅ Decision: KEEP (Score 0.713 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.255, Loss=1.970, Loss_std=0.626, Entropy=1.976\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.849, Loss: 0.507\n",
      "      Stability: 0.791, Confidence: 0.210\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.560\n",
      "   ✅ Decision: KEEP (Score 0.560 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.668, Loss=1.115, Loss_std=1.238, Entropy=1.138\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.721\n",
      "      Stability: 0.587, Confidence: 0.545\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.760\n",
      "   ✅ Decision: KEEP (Score 0.760 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.418, Loss=1.700, Loss_std=1.020, Entropy=1.724\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.575\n",
      "      Stability: 0.660, Confidence: 0.310\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.529, Loss=1.404, Loss_std=1.324, Entropy=1.230\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.649\n",
      "      Stability: 0.559, Confidence: 0.508\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.731\n",
      "   ✅ Decision: KEEP (Score 0.731 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.438, Loss=1.603, Loss_std=1.137, Entropy=1.443\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.599\n",
      "      Stability: 0.621, Confidence: 0.423\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.622\n",
      "   ✅ Decision: KEEP (Score 0.622 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.406, Loss=1.487, Loss_std=0.826, Entropy=1.569\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.628\n",
      "      Stability: 0.725, Confidence: 0.372\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.739\n",
      "   ✅ Decision: KEEP (Score 0.739 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.317, Loss=1.955, Loss_std=0.885, Entropy=1.919\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.511\n",
      "      Stability: 0.705, Confidence: 0.232\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.630\n",
      "   ✅ Decision: KEEP (Score 0.630 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      4 |  0.980 |     0.760 |    3432 | KEEP     | Score 0.760 ≥ threshold 0.400\n",
      "      2 |      8 |  0.980 |     0.739 |    5934 | KEEP     | Score 0.739 ≥ threshold 0.400\n",
      "      3 |      6 |  0.980 |     0.731 |    4303 | KEEP     | Score 0.731 ≥ threshold 0.400\n",
      "      4 |      2 |  0.980 |     0.713 |    2211 | KEEP     | Score 0.713 ≥ threshold 0.400\n",
      "      5 |      5 |  0.450 |     0.649 |    1990 | KEEP     | Score 0.649 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.630 |    6352 | KEEP     | Score 0.630 ≥ threshold 0.400\n",
      "      7 |      7 |  0.010 |     0.622 |    3686 | KEEP     | Score 0.622 ≥ threshold 0.400\n",
      "      8 |      0 |  0.010 |     0.597 |    2419 | KEEP     | Score 0.597 ≥ threshold 0.400\n",
      "      9 |      3 |  0.010 |     0.560 |    2714 | KEEP     | Score 0.560 ≥ threshold 0.400\n",
      "     10 |      1 |  0.010 |     0.544 |    4484 | KEEP     | Score 0.544 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [4, 8, 6, 2, 5, 9, 7, 0, 3, 1])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.655\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        4 | 3432 |   0.760 |  0.091 |  0.150 |   0.144\n",
      "        8 | 5934 |   0.739 |  0.158 |  0.140 |   0.142\n",
      "        6 | 4303 |   0.731 |  0.115 |  0.136 |   0.134\n",
      "        2 | 2211 |   0.713 |  0.059 |  0.128 |   0.121\n",
      "        5 | 1990 |   0.649 |  0.053 |  0.097 |   0.093\n",
      "        9 | 6352 |   0.630 |  0.169 |  0.089 |   0.097\n",
      "        7 | 3686 |   0.622 |  0.098 |  0.084 |   0.086\n",
      "        0 | 2419 |   0.597 |  0.064 |  0.073 |   0.072\n",
      "        3 | 2714 |   0.560 |  0.072 |  0.055 |   0.057\n",
      "        1 | 4484 |   0.544 |  0.119 |  0.047 |   0.055\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 21.03% accuracy, 2.3390 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1214\n",
      "     Epoch 2: Loss = 1.9976\n",
      "   ✅ Training complete. Final avg loss: 2.0595\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8316\n",
      "     Epoch 2: Loss = 1.6861\n",
      "   ✅ Training complete. Final avg loss: 1.7589\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4455\n",
      "     Epoch 2: Loss = 1.2844\n",
      "   ✅ Training complete. Final avg loss: 1.3649\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4565\n",
      "     Epoch 2: Loss = 1.3558\n",
      "   ✅ Training complete. Final avg loss: 1.4062\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2398\n",
      "     Epoch 2: Loss = 1.0802\n",
      "   ✅ Training complete. Final avg loss: 1.1600\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6539\n",
      "     Epoch 2: Loss = 1.5439\n",
      "   ✅ Training complete. Final avg loss: 1.5989\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9814\n",
      "     Epoch 2: Loss = 1.9099\n",
      "   ✅ Training complete. Final avg loss: 1.9456\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7850\n",
      "     Epoch 2: Loss = 1.6364\n",
      "   ✅ Training complete. Final avg loss: 1.7107\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1022\n",
      "     Epoch 2: Loss = 2.0034\n",
      "   ✅ Training complete. Final avg loss: 2.0528\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8941\n",
      "     Epoch 2: Loss = 1.7554\n",
      "   ✅ Training complete. Final avg loss: 1.8248\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.272, Loss=1.997, Loss_std=0.624, Entropy=2.046\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.905, Loss: 0.501\n",
      "      Stability: 0.792, Confidence: 0.181\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.569\n",
      "   ✅ Decision: KEEP (Score 0.569 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.483, Loss=1.593, Loss_std=1.083, Entropy=1.657\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.602\n",
      "      Stability: 0.639, Confidence: 0.337\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.655\n",
      "   ✅ Decision: KEEP (Score 0.655 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.589, Loss=1.173, Loss_std=1.106, Entropy=1.177\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.707\n",
      "      Stability: 0.631, Confidence: 0.529\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.764\n",
      "   ✅ Decision: KEEP (Score 0.764 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.555, Loss=1.321, Loss_std=1.114, Entropy=1.349\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.670\n",
      "      Stability: 0.629, Confidence: 0.460\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.743\n",
      "   ✅ Decision: KEEP (Score 0.743 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.683, Loss=1.097, Loss_std=1.258, Entropy=1.093\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.726\n",
      "      Stability: 0.581, Confidence: 0.563\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.763\n",
      "   ✅ Decision: KEEP (Score 0.763 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.464, Loss=1.470, Loss_std=0.985, Entropy=1.472\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.633\n",
      "      Stability: 0.672, Confidence: 0.411\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.638\n",
      "   ✅ Decision: KEEP (Score 0.638 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.346, Loss=1.858, Loss_std=0.828, Entropy=1.904\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.536\n",
      "      Stability: 0.724, Confidence: 0.238\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.641\n",
      "   ✅ Decision: KEEP (Score 0.641 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.454, Loss=1.606, Loss_std=1.100, Entropy=1.533\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.599\n",
      "      Stability: 0.633, Confidence: 0.387\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.257, Loss=2.030, Loss_std=0.728, Entropy=1.979\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.857, Loss: 0.493\n",
      "      Stability: 0.757, Confidence: 0.209\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.551\n",
      "   ✅ Decision: KEEP (Score 0.551 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.462, Loss=1.692, Loss_std=0.909, Entropy=1.820\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.577\n",
      "      Stability: 0.697, Confidence: 0.272\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.651\n",
      "   ✅ Decision: KEEP (Score 0.651 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      2 |  0.980 |     0.764 |    4072 | KEEP     | Score 0.764 ≥ threshold 0.400\n",
      "      2 |      4 |  0.980 |     0.763 |    3432 | KEEP     | Score 0.763 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.743 |    4303 | KEEP     | Score 0.743 ≥ threshold 0.400\n",
      "      4 |      7 |  0.980 |     0.715 |    2868 | KEEP     | Score 0.715 ≥ threshold 0.400\n",
      "      5 |      1 |  0.450 |     0.655 |    1990 | KEEP     | Score 0.655 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.651 |    1905 | KEEP     | Score 0.651 ≥ threshold 0.400\n",
      "      7 |      6 |  0.450 |     0.641 |    6352 | KEEP     | Score 0.641 ≥ threshold 0.400\n",
      "      8 |      5 |  0.010 |     0.638 |    3686 | KEEP     | Score 0.638 ≥ threshold 0.400\n",
      "      9 |      0 |  0.010 |     0.569 |    2714 | KEEP     | Score 0.569 ≥ threshold 0.400\n",
      "     10 |      8 |  0.010 |     0.551 |    2419 | KEEP     | Score 0.551 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [2, 4, 3, 7, 1, 9, 6, 5, 0, 8])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.669\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        2 | 4072 |   0.764 |  0.121 |  0.144 |   0.141\n",
      "        4 | 3432 |   0.763 |  0.102 |  0.143 |   0.139\n",
      "        3 | 4303 |   0.743 |  0.128 |  0.134 |   0.133\n",
      "        7 | 2868 |   0.715 |  0.085 |  0.121 |   0.117\n",
      "        1 | 1990 |   0.655 |  0.059 |  0.093 |   0.090\n",
      "        9 | 1905 |   0.651 |  0.056 |  0.091 |   0.088\n",
      "        6 | 6352 |   0.641 |  0.188 |  0.087 |   0.097\n",
      "        5 | 3686 |   0.638 |  0.109 |  0.086 |   0.088\n",
      "        0 | 2714 |   0.569 |  0.080 |  0.054 |   0.057\n",
      "        8 | 2419 |   0.551 |  0.072 |  0.046 |   0.048\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 22.72% accuracy, 2.3522 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6645\n",
      "     Epoch 2: Loss = 1.5994\n",
      "   ✅ Training complete. Final avg loss: 1.6320\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1786\n",
      "     Epoch 2: Loss = 2.0052\n",
      "   ✅ Training complete. Final avg loss: 2.0919\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4168\n",
      "     Epoch 2: Loss = 1.3274\n",
      "   ✅ Training complete. Final avg loss: 1.3721\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6204\n",
      "     Epoch 2: Loss = 1.5395\n",
      "   ✅ Training complete. Final avg loss: 1.5800\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6865\n",
      "     Epoch 2: Loss = 1.5266\n",
      "   ✅ Training complete. Final avg loss: 1.6066\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6021\n",
      "     Epoch 2: Loss = 1.4914\n",
      "   ✅ Training complete. Final avg loss: 1.5467\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7386\n",
      "     Epoch 2: Loss = 1.6472\n",
      "   ✅ Training complete. Final avg loss: 1.6929\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1669\n",
      "     Epoch 2: Loss = 1.0541\n",
      "   ✅ Training complete. Final avg loss: 1.1105\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9467\n",
      "     Epoch 2: Loss = 1.8928\n",
      "   ✅ Training complete. Final avg loss: 1.9198\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0456\n",
      "     Epoch 2: Loss = 1.9464\n",
      "   ✅ Training complete. Final avg loss: 1.9960\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.450, Loss=1.494, Loss_std=1.044, Entropy=1.493\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.627\n",
      "      Stability: 0.652, Confidence: 0.403\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.274, Loss=1.996, Loss_std=0.663, Entropy=2.009\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.913, Loss: 0.501\n",
      "      Stability: 0.779, Confidence: 0.196\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.571\n",
      "   ✅ Decision: KEEP (Score 0.571 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.579, Loss=1.290, Loss_std=1.191, Entropy=1.244\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.678\n",
      "      Stability: 0.603, Confidence: 0.503\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.747\n",
      "   ✅ Decision: KEEP (Score 0.747 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.365, Loss=1.499, Loss_std=0.833, Entropy=1.543\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.625\n",
      "      Stability: 0.722, Confidence: 0.383\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.740\n",
      "   ✅ Decision: KEEP (Score 0.740 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.450, Loss=1.584, Loss_std=1.060, Entropy=1.566\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.604\n",
      "      Stability: 0.647, Confidence: 0.373\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.620\n",
      "   ✅ Decision: KEEP (Score 0.620 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.430, Loss=1.551, Loss_std=1.124, Entropy=1.388\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.612\n",
      "      Stability: 0.625, Confidence: 0.445\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.478, Loss=1.652, Loss_std=1.008, Entropy=1.730\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.587\n",
      "      Stability: 0.664, Confidence: 0.308\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.652\n",
      "   ✅ Decision: KEEP (Score 0.652 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.675, Loss=1.122, Loss_std=1.433, Entropy=0.956\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.720\n",
      "      Stability: 0.522, Confidence: 0.618\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.759\n",
      "   ✅ Decision: KEEP (Score 0.759 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.361, Loss=1.884, Loss_std=0.824, Entropy=1.922\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.529\n",
      "      Stability: 0.725, Confidence: 0.231\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.639\n",
      "   ✅ Decision: KEEP (Score 0.639 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.255, Loss=1.885, Loss_std=0.552, Entropy=1.950\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.849, Loss: 0.529\n",
      "      Stability: 0.816, Confidence: 0.220\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.573\n",
      "   ✅ Decision: KEEP (Score 0.573 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.759 |    3432 | KEEP     | Score 0.759 ≥ threshold 0.400\n",
      "      2 |      2 |  0.980 |     0.747 |    4303 | KEEP     | Score 0.747 ≥ threshold 0.400\n",
      "      3 |      3 |  0.980 |     0.740 |    5934 | KEEP     | Score 0.740 ≥ threshold 0.400\n",
      "      4 |      0 |  0.980 |     0.728 |    2868 | KEEP     | Score 0.728 ≥ threshold 0.400\n",
      "      5 |      5 |  0.980 |     0.727 |    2211 | KEEP     | Score 0.727 ≥ threshold 0.400\n",
      "      6 |      6 |  0.450 |     0.652 |    1990 | KEEP     | Score 0.652 ≥ threshold 0.400\n",
      "      7 |      8 |  0.450 |     0.639 |    6352 | KEEP     | Score 0.639 ≥ threshold 0.400\n",
      "      8 |      4 |  0.010 |     0.620 |    3686 | KEEP     | Score 0.620 ≥ threshold 0.400\n",
      "      9 |      9 |  0.010 |     0.573 |    4484 | KEEP     | Score 0.573 ≥ threshold 0.400\n",
      "     10 |      1 |  0.010 |     0.571 |    2419 | KEEP     | Score 0.571 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 2, 3, 0, 5, 6, 8, 4, 9, 1])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.675\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 3432 |   0.759 |  0.091 |  0.141 |   0.136\n",
      "        2 | 4303 |   0.747 |  0.114 |  0.135 |   0.133\n",
      "        3 | 5934 |   0.740 |  0.157 |  0.132 |   0.134\n",
      "        0 | 2868 |   0.728 |  0.076 |  0.126 |   0.121\n",
      "        5 | 2211 |   0.727 |  0.059 |  0.125 |   0.118\n",
      "        6 | 1990 |   0.652 |  0.053 |  0.089 |   0.085\n",
      "        8 | 6352 |   0.639 |  0.169 |  0.082 |   0.091\n",
      "        4 | 3686 |   0.620 |  0.098 |  0.073 |   0.075\n",
      "        9 | 4484 |   0.573 |  0.119 |  0.050 |   0.057\n",
      "        1 | 2419 |   0.571 |  0.064 |  0.049 |   0.050\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 24.14% accuracy, 2.5290 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7380\n",
      "     Epoch 2: Loss = 1.5936\n",
      "   ✅ Training complete. Final avg loss: 1.6658\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1940\n",
      "     Epoch 2: Loss = 1.9899\n",
      "   ✅ Training complete. Final avg loss: 2.0919\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1072\n",
      "     Epoch 2: Loss = 1.0335\n",
      "   ✅ Training complete. Final avg loss: 1.0703\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0411\n",
      "     Epoch 2: Loss = 1.9401\n",
      "   ✅ Training complete. Final avg loss: 1.9906\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6575\n",
      "     Epoch 2: Loss = 1.5828\n",
      "   ✅ Training complete. Final avg loss: 1.6202\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8288\n",
      "     Epoch 2: Loss = 1.6889\n",
      "   ✅ Training complete. Final avg loss: 1.7589\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.9191\n",
      "     Epoch 2: Loss = 1.8760\n",
      "   ✅ Training complete. Final avg loss: 1.8976\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2188\n",
      "     Epoch 2: Loss = 2.0252\n",
      "   ✅ Training complete. Final avg loss: 2.1220\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7281\n",
      "     Epoch 2: Loss = 1.6350\n",
      "   ✅ Training complete. Final avg loss: 1.6815\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3834\n",
      "     Epoch 2: Loss = 1.3097\n",
      "   ✅ Training complete. Final avg loss: 1.3466\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.558, Loss_std=1.007, Entropy=1.513\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.611\n",
      "      Stability: 0.664, Confidence: 0.395\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.726\n",
      "   ✅ Decision: KEEP (Score 0.726 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.344, Loss=1.917, Loss_std=0.663, Entropy=1.990\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.521\n",
      "      Stability: 0.779, Confidence: 0.204\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.600\n",
      "   ✅ Decision: KEEP (Score 0.600 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.671, Loss=1.075, Loss_std=1.158, Entropy=1.144\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.731\n",
      "      Stability: 0.614, Confidence: 0.542\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.768\n",
      "   ✅ Decision: KEEP (Score 0.768 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.236, Loss=1.918, Loss_std=0.570, Entropy=1.974\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.785, Loss: 0.520\n",
      "      Stability: 0.810, Confidence: 0.210\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.550\n",
      "   ✅ Decision: KEEP (Score 0.550 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.481, Loss=1.495, Loss_std=0.888, Entropy=1.664\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.626\n",
      "      Stability: 0.704, Confidence: 0.334\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.476, Loss=1.686, Loss_std=1.108, Entropy=1.665\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.579\n",
      "      Stability: 0.631, Confidence: 0.334\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.647\n",
      "   ✅ Decision: KEEP (Score 0.647 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.329, Loss=1.894, Loss_std=0.869, Entropy=1.892\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.526\n",
      "      Stability: 0.710, Confidence: 0.243\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.637\n",
      "   ✅ Decision: KEEP (Score 0.637 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.245, Loss=2.006, Loss_std=0.590, Entropy=2.057\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.817, Loss: 0.499\n",
      "      Stability: 0.803, Confidence: 0.177\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.546\n",
      "   ✅ Decision: KEEP (Score 0.546 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.430, Loss=1.665, Loss_std=1.057, Entropy=1.685\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.584\n",
      "      Stability: 0.648, Confidence: 0.326\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.651\n",
      "   ✅ Decision: KEEP (Score 0.651 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.519, Loss=1.352, Loss_std=1.067, Entropy=1.349\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.662\n",
      "      Stability: 0.644, Confidence: 0.460\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.745\n",
      "   ✅ Decision: KEEP (Score 0.745 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      2 |  0.980 |     0.768 |    3432 | KEEP     | Score 0.768 ≥ threshold 0.400\n",
      "      2 |      9 |  0.980 |     0.745 |    4303 | KEEP     | Score 0.745 ≥ threshold 0.400\n",
      "      3 |      4 |  0.980 |     0.727 |    2868 | KEEP     | Score 0.727 ≥ threshold 0.400\n",
      "      4 |      0 |  0.980 |     0.726 |    1753 | KEEP     | Score 0.726 ≥ threshold 0.400\n",
      "      5 |      8 |  0.450 |     0.651 |    1990 | KEEP     | Score 0.651 ≥ threshold 0.400\n",
      "      6 |      5 |  0.450 |     0.647 |    1905 | KEEP     | Score 0.647 ≥ threshold 0.400\n",
      "      7 |      6 |  0.450 |     0.637 |    6352 | KEEP     | Score 0.637 ≥ threshold 0.400\n",
      "      8 |      1 |  0.010 |     0.600 |    2419 | KEEP     | Score 0.600 ≥ threshold 0.400\n",
      "      9 |      3 |  0.010 |     0.550 |    4484 | KEEP     | Score 0.550 ≥ threshold 0.400\n",
      "     10 |      7 |  0.010 |     0.546 |    1877 | KEEP     | Score 0.546 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [2, 9, 4, 0, 8, 5, 6, 1, 3, 7])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.660\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        2 | 3432 |   0.768 |  0.109 |  0.151 |   0.147\n",
      "        9 | 4303 |   0.745 |  0.137 |  0.140 |   0.140\n",
      "        4 | 2868 |   0.727 |  0.091 |  0.132 |   0.128\n",
      "        0 | 1753 |   0.726 |  0.056 |  0.131 |   0.123\n",
      "        8 | 1990 |   0.651 |  0.063 |  0.096 |   0.093\n",
      "        5 | 1905 |   0.647 |  0.061 |  0.094 |   0.091\n",
      "        6 | 6352 |   0.637 |  0.202 |  0.089 |   0.101\n",
      "        1 | 2419 |   0.600 |  0.077 |  0.072 |   0.073\n",
      "        3 | 4484 |   0.550 |  0.143 |  0.049 |   0.058\n",
      "        7 | 1877 |   0.546 |  0.060 |  0.047 |   0.048\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 25.69% accuracy, 2.3662 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 12: DEGRADED (score: 0.450)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 5: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 12 (degraded):\n",
      "   Samples: 1905, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7442\n",
      "     Epoch 2: Loss = 1.6969\n",
      "   ✅ Training complete. Final avg loss: 1.7205\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0762\n",
      "     Epoch 2: Loss = 1.9045\n",
      "   ✅ Training complete. Final avg loss: 1.9903\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6804\n",
      "     Epoch 2: Loss = 1.5685\n",
      "   ✅ Training complete. Final avg loss: 1.6245\n",
      "🔧 Training Client 5 (pristine):\n",
      "   Samples: 4072, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2974\n",
      "     Epoch 2: Loss = 1.2204\n",
      "   ✅ Training complete. Final avg loss: 1.2589\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8918\n",
      "     Epoch 2: Loss = 1.8542\n",
      "   ✅ Training complete. Final avg loss: 1.8730\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6287\n",
      "     Epoch 2: Loss = 1.5793\n",
      "   ✅ Training complete. Final avg loss: 1.6040\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2100\n",
      "     Epoch 2: Loss = 2.0197\n",
      "   ✅ Training complete. Final avg loss: 2.1149\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1239\n",
      "     Epoch 2: Loss = 1.0204\n",
      "   ✅ Training complete. Final avg loss: 1.0722\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1702\n",
      "     Epoch 2: Loss = 1.9755\n",
      "   ✅ Training complete. Final avg loss: 2.0728\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.7032\n",
      "     Epoch 2: Loss = 1.6327\n",
      "   ✅ Training complete. Final avg loss: 1.6680\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.510, Loss=1.598, Loss_std=1.118, Entropy=1.623\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.601\n",
      "      Stability: 0.627, Confidence: 0.351\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.654\n",
      "   ✅ Decision: KEEP (Score 0.654 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.252, Loss=1.901, Loss_std=0.698, Entropy=1.906\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.841, Loss: 0.525\n",
      "      Stability: 0.767, Confidence: 0.238\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.562\n",
      "   ✅ Decision: KEEP (Score 0.562 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.462, Loss=1.573, Loss_std=0.968, Entropy=1.614\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.607\n",
      "      Stability: 0.677, Confidence: 0.355\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.721\n",
      "   ✅ Decision: KEEP (Score 0.721 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.570, Loss=1.258, Loss_std=1.109, Entropy=1.218\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.686\n",
      "      Stability: 0.630, Confidence: 0.513\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.756\n",
      "   ✅ Decision: KEEP (Score 0.756 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.392, Loss=1.744, Loss_std=0.870, Entropy=1.844\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.564\n",
      "      Stability: 0.710, Confidence: 0.263\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.649\n",
      "   ✅ Decision: KEEP (Score 0.649 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.447, Loss=1.550, Loss_std=0.970, Entropy=1.589\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.612\n",
      "      Stability: 0.677, Confidence: 0.364\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.724\n",
      "   ✅ Decision: KEEP (Score 0.724 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.236, Loss=2.041, Loss_std=0.655, Entropy=2.046\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.785, Loss: 0.490\n",
      "      Stability: 0.782, Confidence: 0.182\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.532\n",
      "   ✅ Decision: KEEP (Score 0.532 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.683, Loss=1.084, Loss_std=1.235, Entropy=1.112\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.729\n",
      "      Stability: 0.588, Confidence: 0.555\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.764\n",
      "   ✅ Decision: KEEP (Score 0.764 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.298, Loss=1.938, Loss_std=0.759, Entropy=1.928\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.994, Loss: 0.515\n",
      "      Stability: 0.747, Confidence: 0.229\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.595\n",
      "   ✅ Decision: KEEP (Score 0.595 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.493, Loss=1.580, Loss_std=1.074, Entropy=1.634\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.605\n",
      "      Stability: 0.642, Confidence: 0.346\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.658\n",
      "   ✅ Decision: KEEP (Score 0.658 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.764 |    3432 | KEEP     | Score 0.764 ≥ threshold 0.400\n",
      "      2 |      3 |  0.980 |     0.756 |    4072 | KEEP     | Score 0.756 ≥ threshold 0.400\n",
      "      3 |      5 |  0.980 |     0.724 |    2868 | KEEP     | Score 0.724 ≥ threshold 0.400\n",
      "      4 |      2 |  0.980 |     0.721 |    1753 | KEEP     | Score 0.721 ≥ threshold 0.400\n",
      "      5 |      9 |  0.450 |     0.658 |    1990 | KEEP     | Score 0.658 ≥ threshold 0.400\n",
      "      6 |      0 |  0.450 |     0.654 |    1905 | KEEP     | Score 0.654 ≥ threshold 0.400\n",
      "      7 |      4 |  0.450 |     0.649 |    6352 | KEEP     | Score 0.649 ≥ threshold 0.400\n",
      "      8 |      8 |  0.010 |     0.595 |    2419 | KEEP     | Score 0.595 ≥ threshold 0.400\n",
      "      9 |      1 |  0.010 |     0.562 |    2714 | KEEP     | Score 0.562 ≥ threshold 0.400\n",
      "     10 |      6 |  0.010 |     0.532 |    1877 | KEEP     | Score 0.532 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 3, 5, 2, 9, 0, 4, 8, 1, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.661\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 3432 |   0.764 |  0.117 |  0.145 |   0.142\n",
      "        3 | 4072 |   0.756 |  0.139 |  0.141 |   0.141\n",
      "        5 | 2868 |   0.724 |  0.098 |  0.127 |   0.124\n",
      "        2 | 1753 |   0.721 |  0.060 |  0.126 |   0.119\n",
      "        9 | 1990 |   0.658 |  0.068 |  0.098 |   0.095\n",
      "        0 | 1905 |   0.654 |  0.065 |  0.097 |   0.094\n",
      "        4 | 6352 |   0.649 |  0.216 |  0.095 |   0.107\n",
      "        8 | 2419 |   0.595 |  0.082 |  0.071 |   0.072\n",
      "        1 | 2714 |   0.562 |  0.092 |  0.057 |   0.060\n",
      "        6 | 1877 |   0.532 |  0.064 |  0.044 |   0.046\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 25.52% accuracy, 2.4097 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 4: PRISTINE (score: 0.980)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 1: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 9: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 4 (pristine):\n",
      "   Samples: 2868, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6050\n",
      "     Epoch 2: Loss = 1.5377\n",
      "   ✅ Training complete. Final avg loss: 1.5714\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8849\n",
      "     Epoch 2: Loss = 1.8414\n",
      "   ✅ Training complete. Final avg loss: 1.8631\n",
      "🔧 Training Client 1 (byzantine):\n",
      "   Samples: 4484, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0304\n",
      "     Epoch 2: Loss = 1.9266\n",
      "   ✅ Training complete. Final avg loss: 1.9785\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3579\n",
      "     Epoch 2: Loss = 1.2922\n",
      "   ✅ Training complete. Final avg loss: 1.3250\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5099\n",
      "     Epoch 2: Loss = 1.4431\n",
      "   ✅ Training complete. Final avg loss: 1.4765\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6872\n",
      "     Epoch 2: Loss = 1.5152\n",
      "   ✅ Training complete. Final avg loss: 1.6012\n",
      "🔧 Training Client 9 (pristine):\n",
      "   Samples: 1753, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6429\n",
      "     Epoch 2: Loss = 1.5658\n",
      "   ✅ Training complete. Final avg loss: 1.6043\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0670\n",
      "     Epoch 2: Loss = 1.8901\n",
      "   ✅ Training complete. Final avg loss: 1.9786\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5712\n",
      "     Epoch 2: Loss = 1.4949\n",
      "   ✅ Training complete. Final avg loss: 1.5330\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.6932\n",
      "     Epoch 2: Loss = 1.6219\n",
      "   ✅ Training complete. Final avg loss: 1.6576\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.478, Loss=1.482, Loss_std=0.854, Entropy=1.629\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.630\n",
      "      Stability: 0.715, Confidence: 0.348\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.733\n",
      "   ✅ Decision: KEEP (Score 0.733 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.373, Loss=1.855, Loss_std=0.895, Entropy=1.862\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.536\n",
      "      Stability: 0.702, Confidence: 0.255\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.640\n",
      "   ✅ Decision: KEEP (Score 0.640 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.257, Loss=1.898, Loss_std=0.629, Entropy=1.931\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.857, Loss: 0.526\n",
      "      Stability: 0.790, Confidence: 0.227\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.570\n",
      "   ✅ Decision: KEEP (Score 0.570 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.558, Loss=1.279, Loss_std=1.209, Entropy=1.175\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.680\n",
      "      Stability: 0.597, Confidence: 0.530\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.751\n",
      "   ✅ Decision: KEEP (Score 0.751 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.502, Loss=1.422, Loss_std=1.092, Entropy=1.383\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.644\n",
      "      Stability: 0.636, Confidence: 0.447\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.737\n",
      "   ✅ Decision: KEEP (Score 0.737 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.483, Loss=1.454, Loss_std=0.972, Entropy=1.486\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.637\n",
      "      Stability: 0.676, Confidence: 0.406\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.639\n",
      "   ✅ Decision: KEEP (Score 0.639 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.435, Loss=1.553, Loss_std=0.925, Entropy=1.590\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.612\n",
      "      Stability: 0.692, Confidence: 0.364\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.286, Loss=1.830, Loss_std=0.631, Entropy=1.925\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.954, Loss: 0.542\n",
      "      Stability: 0.790, Confidence: 0.230\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.600\n",
      "   ✅ Decision: KEEP (Score 0.600 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.421, Loss=1.492, Loss_std=0.877, Entropy=1.550\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.627\n",
      "      Stability: 0.708, Confidence: 0.380\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.737\n",
      "   ✅ Decision: KEEP (Score 0.737 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.483, Loss=1.601, Loss_std=1.133, Entropy=1.596\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.600\n",
      "      Stability: 0.622, Confidence: 0.362\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.655\n",
      "   ✅ Decision: KEEP (Score 0.655 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.751 |    4303 | KEEP     | Score 0.751 ≥ threshold 0.400\n",
      "      2 |      8 |  0.980 |     0.737 |    5934 | KEEP     | Score 0.737 ≥ threshold 0.400\n",
      "      3 |      4 |  0.980 |     0.737 |    2211 | KEEP     | Score 0.737 ≥ threshold 0.400\n",
      "      4 |      0 |  0.980 |     0.733 |    2868 | KEEP     | Score 0.733 ≥ threshold 0.400\n",
      "      5 |      6 |  0.980 |     0.727 |    1753 | KEEP     | Score 0.727 ≥ threshold 0.400\n",
      "      6 |      9 |  0.450 |     0.655 |    1990 | KEEP     | Score 0.655 ≥ threshold 0.400\n",
      "      7 |      1 |  0.450 |     0.640 |    6352 | KEEP     | Score 0.640 ≥ threshold 0.400\n",
      "      8 |      5 |  0.010 |     0.639 |    3686 | KEEP     | Score 0.639 ≥ threshold 0.400\n",
      "      9 |      7 |  0.010 |     0.600 |    2714 | KEEP     | Score 0.600 ≥ threshold 0.400\n",
      "     10 |      2 |  0.010 |     0.570 |    4484 | KEEP     | Score 0.570 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [3, 8, 4, 0, 6, 9, 1, 5, 7, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.679\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 4303 |   0.751 |  0.119 |  0.134 |   0.133\n",
      "        8 | 5934 |   0.737 |  0.163 |  0.128 |   0.131\n",
      "        4 | 2211 |   0.737 |  0.061 |  0.128 |   0.121\n",
      "        0 | 2868 |   0.733 |  0.079 |  0.126 |   0.121\n",
      "        6 | 1753 |   0.727 |  0.048 |  0.123 |   0.116\n",
      "        9 | 1990 |   0.655 |  0.055 |  0.089 |   0.085\n",
      "        1 | 6352 |   0.640 |  0.175 |  0.081 |   0.091\n",
      "        5 | 3686 |   0.639 |  0.102 |  0.081 |   0.083\n",
      "        7 | 2714 |   0.600 |  0.075 |  0.062 |   0.063\n",
      "        2 | 4484 |   0.570 |  0.124 |  0.048 |   0.055\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 24.57% accuracy, 2.4083 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: BYZANTINE (score: 0.010)\n",
      "   Client 3: PRISTINE (score: 0.980)\n",
      "   Client 7: BYZANTINE (score: 0.010)\n",
      "   Client 11: PRISTINE (score: 0.980)\n",
      "   Client 10: BYZANTINE (score: 0.010)\n",
      "   Client 2: PRISTINE (score: 0.980)\n",
      "   Client 14: BYZANTINE (score: 0.010)\n",
      "   Client 13: DEGRADED (score: 0.450)\n",
      "   Client 8: PRISTINE (score: 0.980)\n",
      "   Client 6: DEGRADED (score: 0.450)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (byzantine):\n",
      "   Samples: 1877, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.2058\n",
      "     Epoch 2: Loss = 1.9753\n",
      "   ✅ Training complete. Final avg loss: 2.0906\n",
      "🔧 Training Client 3 (pristine):\n",
      "   Samples: 5934, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5292\n",
      "     Epoch 2: Loss = 1.4766\n",
      "   ✅ Training complete. Final avg loss: 1.5029\n",
      "🔧 Training Client 7 (byzantine):\n",
      "   Samples: 2419, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.1761\n",
      "     Epoch 2: Loss = 1.9668\n",
      "   ✅ Training complete. Final avg loss: 2.0715\n",
      "🔧 Training Client 11 (pristine):\n",
      "   Samples: 4303, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3288\n",
      "     Epoch 2: Loss = 1.2835\n",
      "   ✅ Training complete. Final avg loss: 1.3061\n",
      "🔧 Training Client 10 (byzantine):\n",
      "   Samples: 2714, Quality: 0.010\n",
      "     Epoch 1: Loss = 2.0525\n",
      "     Epoch 2: Loss = 1.8838\n",
      "   ✅ Training complete. Final avg loss: 1.9682\n",
      "🔧 Training Client 2 (pristine):\n",
      "   Samples: 3432, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.0951\n",
      "     Epoch 2: Loss = 1.0225\n",
      "   ✅ Training complete. Final avg loss: 1.0588\n",
      "🔧 Training Client 14 (byzantine):\n",
      "   Samples: 3686, Quality: 0.010\n",
      "     Epoch 1: Loss = 1.6604\n",
      "     Epoch 2: Loss = 1.4950\n",
      "   ✅ Training complete. Final avg loss: 1.5777\n",
      "🔧 Training Client 13 (degraded):\n",
      "   Samples: 6352, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.8479\n",
      "     Epoch 2: Loss = 1.8226\n",
      "   ✅ Training complete. Final avg loss: 1.8353\n",
      "🔧 Training Client 8 (pristine):\n",
      "   Samples: 2211, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4932\n",
      "     Epoch 2: Loss = 1.4493\n",
      "   ✅ Training complete. Final avg loss: 1.4712\n",
      "🔧 Training Client 6 (degraded):\n",
      "   Samples: 1990, Quality: 0.450\n",
      "     Epoch 1: Loss = 1.6930\n",
      "     Epoch 2: Loss = 1.6198\n",
      "   ✅ Training complete. Final avg loss: 1.6564\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.303, Loss=1.936, Loss_std=0.647, Entropy=2.021\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.516\n",
      "      Stability: 0.784, Confidence: 0.192\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.598\n",
      "   ✅ Decision: KEEP (Score 0.598 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.498, Loss=1.366, Loss_std=0.895, Entropy=1.448\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.658\n",
      "      Stability: 0.702, Confidence: 0.421\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.750\n",
      "   ✅ Decision: KEEP (Score 0.750 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.315, Loss=1.941, Loss_std=0.736, Entropy=1.978\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.515\n",
      "      Stability: 0.755, Confidence: 0.209\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.594\n",
      "   ✅ Decision: KEEP (Score 0.594 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.570, Loss=1.221, Loss_std=1.072, Entropy=1.307\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.695\n",
      "      Stability: 0.643, Confidence: 0.477\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.755\n",
      "   ✅ Decision: KEEP (Score 0.755 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.298, Loss=1.812, Loss_std=0.640, Entropy=1.891\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.994, Loss: 0.547\n",
      "      Stability: 0.787, Confidence: 0.244\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.613\n",
      "   ✅ Decision: KEEP (Score 0.613 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.685, Loss=1.025, Loss_std=1.120, Entropy=1.114\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.744\n",
      "      Stability: 0.627, Confidence: 0.554\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.776\n",
      "   ✅ Decision: KEEP (Score 0.776 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.010)\n",
      "   📊 Metrics: Acc=0.524, Loss=1.372, Loss_std=0.878, Entropy=1.550\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.657\n",
      "      Stability: 0.707, Confidence: 0.380\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.646\n",
      "   ✅ Decision: KEEP (Score 0.646 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.375, Loss=1.856, Loss_std=0.916, Entropy=1.829\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.536\n",
      "      Stability: 0.695, Confidence: 0.269\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.640\n",
      "   ✅ Decision: KEEP (Score 0.640 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.462, Loss=1.440, Loss_std=0.979, Entropy=1.447\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.640\n",
      "      Stability: 0.674, Confidence: 0.421\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.739\n",
      "   ✅ Decision: KEEP (Score 0.739 ≥ threshold 0.400)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.450)\n",
      "   📊 Metrics: Acc=0.478, Loss=1.554, Loss_std=1.171, Entropy=1.519\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.611\n",
      "      Stability: 0.610, Confidence: 0.393\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.660\n",
      "   ✅ Decision: KEEP (Score 0.660 ≥ threshold 0.400)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      5 |  0.980 |     0.776 |    3432 | KEEP     | Score 0.776 ≥ threshold 0.400\n",
      "      2 |      3 |  0.980 |     0.755 |    4303 | KEEP     | Score 0.755 ≥ threshold 0.400\n",
      "      3 |      1 |  0.980 |     0.750 |    5934 | KEEP     | Score 0.750 ≥ threshold 0.400\n",
      "      4 |      8 |  0.980 |     0.739 |    2211 | KEEP     | Score 0.739 ≥ threshold 0.400\n",
      "      5 |      9 |  0.450 |     0.660 |    1990 | KEEP     | Score 0.660 ≥ threshold 0.400\n",
      "      6 |      6 |  0.010 |     0.646 |    3686 | KEEP     | Score 0.646 ≥ threshold 0.400\n",
      "      7 |      7 |  0.450 |     0.640 |    6352 | KEEP     | Score 0.640 ≥ threshold 0.400\n",
      "      8 |      4 |  0.010 |     0.613 |    2714 | KEEP     | Score 0.613 ≥ threshold 0.400\n",
      "      9 |      0 |  0.010 |     0.598 |    1877 | KEEP     | Score 0.598 ≥ threshold 0.400\n",
      "     10 |      2 |  0.010 |     0.594 |    2419 | KEEP     | Score 0.594 ≥ threshold 0.400\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [5, 3, 1, 8, 9, 6, 7, 4, 0, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.677\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for byzantine\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: byzantine\n",
      "   Quality emphasis: 90.0%, Size emphasis: 10.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        5 | 3432 |   0.776 |  0.098 |  0.154 |   0.148\n",
      "        3 | 4303 |   0.755 |  0.123 |  0.142 |   0.140\n",
      "        1 | 5934 |   0.750 |  0.170 |  0.140 |   0.143\n",
      "        8 | 2211 |   0.739 |  0.063 |  0.134 |   0.127\n",
      "        9 | 1990 |   0.660 |  0.057 |  0.091 |   0.087\n",
      "        6 | 3686 |   0.646 |  0.106 |  0.083 |   0.085\n",
      "        7 | 6352 |   0.640 |  0.182 |  0.080 |   0.090\n",
      "        4 | 2714 |   0.613 |  0.078 |  0.065 |   0.066\n",
      "        0 | 1877 |   0.598 |  0.054 |  0.057 |   0.056\n",
      "        2 | 2419 |   0.594 |  0.069 |  0.055 |   0.056\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 25.49% accuracy, 2.3665 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 25.49%\n",
      "   Best Accuracy: 25.69%\n",
      "   avg_filter_rate: 0.000\n",
      "   max_filter_rate: 0.000\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 8/8\n",
      "   Learning Rate: 0.01\n",
      "   Extreme Type: resource\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME SCENARIO 'resource':\n",
      "   30% rich (5K+ samples), 40% poor (200 samples), 30% broken (50 bad samples)\n",
      "\n",
      "💀 LOADING EXTREME QUALITY DATA - extreme_resource_lr0.01_1\n",
      "======================================================================\n",
      "📁 Loading REAL CIFAR-10 dataset...\n",
      "✅ REAL CIFAR-10 loaded: 50000 train, 10000 test images\n",
      "   Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "   Image shape: 32x32x3 RGB\n",
      "Creating EXTREME federated splits for 15 clients...\n",
      "\n",
      "💀 EXTREME Quality Distribution:\n",
      "  POOR: 6 clients\n",
      "  BROKEN: 5 clients\n",
      "  RICH: 4 clients\n",
      "   💀 Client 0 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 1 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 2 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 3 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 4 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 5 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 6 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 7 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 8 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 9 (rich): DEFAULT: Pristine data\n",
      "   💀 Client 10 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 11 (broken): BROKEN: Resource-poor + 60% label noise\n",
      "   💀 Client 12 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 13 (poor): DEFAULT: Pristine data\n",
      "   💀 Client 14 (poor): DEFAULT: Pristine data\n",
      "\n",
      "✅ EXTREME data loaded: 15 clients\n",
      "   Quality score range: 0.080 - 0.980\n",
      "\n",
      "📊 Extreme Quality Summary:\n",
      "   RICH: 4 clients (avg score: 0.980)\n",
      "   BROKEN: 5 clients (avg score: 0.080)\n",
      "   POOR: 6 clients (avg score: 0.980)\n",
      "\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "💀 TESTING FEDAVG vs RESOURCE\n",
      "🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵🔵\n",
      "\n",
      "🔵 ROUND 1/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2921\n",
      "     Epoch 2: Loss = 2.2398\n",
      "   ✅ Training complete. Final avg loss: 2.2659\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9428\n",
      "     Epoch 2: Loss = 1.7229\n",
      "   ✅ Training complete. Final avg loss: 1.8328\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0096\n",
      "     Epoch 2: Loss = 1.7996\n",
      "   ✅ Training complete. Final avg loss: 1.9046\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2859\n",
      "     Epoch 2: Loss = 2.2865\n",
      "   ✅ Training complete. Final avg loss: 2.2862\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3083\n",
      "     Epoch 2: Loss = 2.2267\n",
      "   ✅ Training complete. Final avg loss: 2.2675\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3077\n",
      "     Epoch 2: Loss = 2.3063\n",
      "   ✅ Training complete. Final avg loss: 2.3070\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3110\n",
      "     Epoch 2: Loss = 2.3067\n",
      "   ✅ Training complete. Final avg loss: 2.3089\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7709\n",
      "     Epoch 2: Loss = 1.6565\n",
      "   ✅ Training complete. Final avg loss: 1.7137\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3096\n",
      "     Epoch 2: Loss = 2.2450\n",
      "   ✅ Training complete. Final avg loss: 2.2773\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3138\n",
      "     Epoch 2: Loss = 2.2294\n",
      "   ✅ Training complete. Final avg loss: 2.2716\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 1\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 200, Weight=0.0168, Quality=poor\n",
      "  Client 1: Size=2013, Weight=0.1696, Quality=rich\n",
      "  Client 2: Size=1951, Weight=0.1644, Quality=rich\n",
      "  Client 3: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 4: Size= 200, Weight=0.0168, Quality=poor\n",
      "  Client 5: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 6: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 7: Size=6957, Weight=0.5861, Quality=rich\n",
      "  Client 8: Size= 200, Weight=0.0168, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0168, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 13.59% accuracy, 2.6293 loss\n",
      "\n",
      "🔵 ROUND 2/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6466\n",
      "     Epoch 2: Loss = 1.5298\n",
      "   ✅ Training complete. Final avg loss: 1.5882\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9170\n",
      "     Epoch 2: Loss = 1.7869\n",
      "   ✅ Training complete. Final avg loss: 1.8520\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6314\n",
      "     Epoch 2: Loss = 2.5066\n",
      "   ✅ Training complete. Final avg loss: 2.5690\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3672\n",
      "     Epoch 2: Loss = 2.2443\n",
      "   ✅ Training complete. Final avg loss: 2.3058\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4388\n",
      "     Epoch 2: Loss = 2.4481\n",
      "   ✅ Training complete. Final avg loss: 2.4435\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.9985\n",
      "     Epoch 2: Loss = 2.4503\n",
      "   ✅ Training complete. Final avg loss: 2.7244\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8270\n",
      "     Epoch 2: Loss = 1.6730\n",
      "   ✅ Training complete. Final avg loss: 1.7500\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4495\n",
      "     Epoch 2: Loss = 2.4718\n",
      "   ✅ Training complete. Final avg loss: 2.4606\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3185\n",
      "     Epoch 2: Loss = 2.0058\n",
      "   ✅ Training complete. Final avg loss: 2.1621\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8116\n",
      "     Epoch 2: Loss = 2.7711\n",
      "   ✅ Training complete. Final avg loss: 2.7914\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 2\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=6957, Weight=0.5936, Quality=rich\n",
      "  Client 1: Size=1951, Weight=0.1665, Quality=rich\n",
      "  Client 2: Size=  50, Weight=0.0043, Quality=broken\n",
      "  Client 3: Size= 200, Weight=0.0171, Quality=poor\n",
      "  Client 4: Size=  50, Weight=0.0043, Quality=broken\n",
      "  Client 5: Size= 200, Weight=0.0171, Quality=poor\n",
      "  Client 6: Size=2013, Weight=0.1717, Quality=rich\n",
      "  Client 7: Size=  50, Weight=0.0043, Quality=broken\n",
      "  Client 8: Size= 200, Weight=0.0171, Quality=poor\n",
      "  Client 9: Size=  50, Weight=0.0043, Quality=broken\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 18.11% accuracy, 3.0952 loss\n",
      "\n",
      "🔵 ROUND 3/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7308\n",
      "     Epoch 2: Loss = 1.4522\n",
      "   ✅ Training complete. Final avg loss: 1.5915\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7906\n",
      "     Epoch 2: Loss = 1.5852\n",
      "   ✅ Training complete. Final avg loss: 1.6879\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7347\n",
      "     Epoch 2: Loss = 1.5512\n",
      "   ✅ Training complete. Final avg loss: 1.6429\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4124\n",
      "     Epoch 2: Loss = 2.1180\n",
      "   ✅ Training complete. Final avg loss: 2.2652\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7908\n",
      "     Epoch 2: Loss = 2.6981\n",
      "   ✅ Training complete. Final avg loss: 2.7445\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4838\n",
      "     Epoch 2: Loss = 1.4057\n",
      "   ✅ Training complete. Final avg loss: 1.4447\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.9007\n",
      "     Epoch 2: Loss = 2.7084\n",
      "   ✅ Training complete. Final avg loss: 2.8045\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7205\n",
      "     Epoch 2: Loss = 2.6075\n",
      "   ✅ Training complete. Final avg loss: 2.6640\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1895\n",
      "     Epoch 2: Loss = 1.9889\n",
      "   ✅ Training complete. Final avg loss: 2.0892\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0244\n",
      "     Epoch 2: Loss = 1.8337\n",
      "   ✅ Training complete. Final avg loss: 1.9290\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 3\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4764, Weight=0.2899, Quality=rich\n",
      "  Client 1: Size=1951, Weight=0.1187, Quality=rich\n",
      "  Client 2: Size=2013, Weight=0.1225, Quality=rich\n",
      "  Client 3: Size= 200, Weight=0.0122, Quality=poor\n",
      "  Client 4: Size=  50, Weight=0.0030, Quality=broken\n",
      "  Client 5: Size=6957, Weight=0.4233, Quality=rich\n",
      "  Client 6: Size=  50, Weight=0.0030, Quality=broken\n",
      "  Client 7: Size=  50, Weight=0.0030, Quality=broken\n",
      "  Client 8: Size= 200, Weight=0.0122, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0122, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 16.51% accuracy, 3.1444 loss\n",
      "\n",
      "🔵 ROUND 4/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6405\n",
      "     Epoch 2: Loss = 1.4804\n",
      "   ✅ Training complete. Final avg loss: 1.5605\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8680\n",
      "     Epoch 2: Loss = 2.6881\n",
      "   ✅ Training complete. Final avg loss: 2.7780\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2430\n",
      "     Epoch 2: Loss = 1.9058\n",
      "   ✅ Training complete. Final avg loss: 2.0744\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8298\n",
      "     Epoch 2: Loss = 1.5861\n",
      "   ✅ Training complete. Final avg loss: 1.7079\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7747\n",
      "     Epoch 2: Loss = 2.5621\n",
      "   ✅ Training complete. Final avg loss: 2.6684\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4374\n",
      "     Epoch 2: Loss = 2.3902\n",
      "   ✅ Training complete. Final avg loss: 2.4138\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4969\n",
      "     Epoch 2: Loss = 2.3807\n",
      "   ✅ Training complete. Final avg loss: 2.4388\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4076\n",
      "     Epoch 2: Loss = 1.3117\n",
      "   ✅ Training complete. Final avg loss: 1.3597\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0681\n",
      "     Epoch 2: Loss = 1.9066\n",
      "   ✅ Training complete. Final avg loss: 1.9874\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0795\n",
      "     Epoch 2: Loss = 1.6714\n",
      "   ✅ Training complete. Final avg loss: 1.8755\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 4\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=2013, Weight=0.2019, Quality=rich\n",
      "  Client 1: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 2: Size= 200, Weight=0.0201, Quality=poor\n",
      "  Client 3: Size= 200, Weight=0.0201, Quality=poor\n",
      "  Client 4: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 5: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 6: Size=  50, Weight=0.0050, Quality=broken\n",
      "  Client 7: Size=6957, Weight=0.6978, Quality=rich\n",
      "  Client 8: Size= 200, Weight=0.0201, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0201, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 19.24% accuracy, 4.7839 loss\n",
      "\n",
      "🔵 ROUND 5/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 3.1610\n",
      "     Epoch 2: Loss = 2.0447\n",
      "   ✅ Training complete. Final avg loss: 2.6028\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5926\n",
      "     Epoch 2: Loss = 1.4141\n",
      "   ✅ Training complete. Final avg loss: 1.5034\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3534\n",
      "     Epoch 2: Loss = 1.9785\n",
      "   ✅ Training complete. Final avg loss: 2.1660\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.9688\n",
      "     Epoch 2: Loss = 2.2275\n",
      "   ✅ Training complete. Final avg loss: 2.5982\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8835\n",
      "     Epoch 2: Loss = 1.5446\n",
      "   ✅ Training complete. Final avg loss: 1.7140\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5210\n",
      "     Epoch 2: Loss = 1.2794\n",
      "   ✅ Training complete. Final avg loss: 1.4002\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2680\n",
      "     Epoch 2: Loss = 1.1999\n",
      "   ✅ Training complete. Final avg loss: 1.2339\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.2145\n",
      "     Epoch 2: Loss = 3.0214\n",
      "   ✅ Training complete. Final avg loss: 3.1179\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.3702\n",
      "     Epoch 2: Loss = 3.0252\n",
      "   ✅ Training complete. Final avg loss: 3.1977\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.2585\n",
      "     Epoch 2: Loss = 3.0766\n",
      "   ✅ Training complete. Final avg loss: 3.1676\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 5\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 1: Size=2013, Weight=0.1371, Quality=rich\n",
      "  Client 2: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 3: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 4: Size= 200, Weight=0.0136, Quality=poor\n",
      "  Client 5: Size=4764, Weight=0.3244, Quality=rich\n",
      "  Client 6: Size=6957, Weight=0.4738, Quality=rich\n",
      "  Client 7: Size=  50, Weight=0.0034, Quality=broken\n",
      "  Client 8: Size=  50, Weight=0.0034, Quality=broken\n",
      "  Client 9: Size=  50, Weight=0.0034, Quality=broken\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 18.37% accuracy, 4.9444 loss\n",
      "\n",
      "🔵 ROUND 6/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3233\n",
      "     Epoch 2: Loss = 1.2430\n",
      "   ✅ Training complete. Final avg loss: 1.2831\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7195\n",
      "     Epoch 2: Loss = 1.4107\n",
      "   ✅ Training complete. Final avg loss: 1.5651\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6983\n",
      "     Epoch 2: Loss = 2.5157\n",
      "   ✅ Training complete. Final avg loss: 2.6070\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8993\n",
      "     Epoch 2: Loss = 2.7489\n",
      "   ✅ Training complete. Final avg loss: 2.8241\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.1449\n",
      "     Epoch 2: Loss = 2.9045\n",
      "   ✅ Training complete. Final avg loss: 3.0247\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.9221\n",
      "     Epoch 2: Loss = 2.7564\n",
      "   ✅ Training complete. Final avg loss: 2.8392\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6182\n",
      "     Epoch 2: Loss = 1.1790\n",
      "   ✅ Training complete. Final avg loss: 1.3986\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2142\n",
      "     Epoch 2: Loss = 1.1551\n",
      "   ✅ Training complete. Final avg loss: 1.1846\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1487\n",
      "     Epoch 2: Loss = 1.6735\n",
      "   ✅ Training complete. Final avg loss: 1.9111\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9502\n",
      "     Epoch 2: Loss = 1.6274\n",
      "   ✅ Training complete. Final avg loss: 1.7888\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 6\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=4764, Weight=0.3745, Quality=rich\n",
      "  Client 1: Size= 200, Weight=0.0157, Quality=poor\n",
      "  Client 2: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 3: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 4: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 5: Size=  50, Weight=0.0039, Quality=broken\n",
      "  Client 6: Size= 200, Weight=0.0157, Quality=poor\n",
      "  Client 7: Size=6957, Weight=0.5469, Quality=rich\n",
      "  Client 8: Size= 200, Weight=0.0157, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0157, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 17.04% accuracy, 6.6572 loss\n",
      "\n",
      "🔵 ROUND 7/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6036\n",
      "     Epoch 2: Loss = 1.3616\n",
      "   ✅ Training complete. Final avg loss: 1.4826\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0211\n",
      "     Epoch 2: Loss = 1.5662\n",
      "   ✅ Training complete. Final avg loss: 1.7937\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.8887\n",
      "     Epoch 2: Loss = 2.7334\n",
      "   ✅ Training complete. Final avg loss: 2.8111\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8402\n",
      "     Epoch 2: Loss = 1.6680\n",
      "   ✅ Training complete. Final avg loss: 1.7541\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8388\n",
      "     Epoch 2: Loss = 1.5327\n",
      "   ✅ Training complete. Final avg loss: 1.6857\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5363\n",
      "     Epoch 2: Loss = 1.3509\n",
      "   ✅ Training complete. Final avg loss: 1.4436\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5045\n",
      "     Epoch 2: Loss = 1.4103\n",
      "   ✅ Training complete. Final avg loss: 1.4574\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.0694\n",
      "     Epoch 2: Loss = 2.9466\n",
      "   ✅ Training complete. Final avg loss: 3.0080\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5170\n",
      "     Epoch 2: Loss = 1.0738\n",
      "   ✅ Training complete. Final avg loss: 1.2954\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.1533\n",
      "     Epoch 2: Loss = 1.1120\n",
      "   ✅ Training complete. Final avg loss: 1.1327\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 7\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 1: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 2: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 3: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 4: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 5: Size=2013, Weight=0.1675, Quality=rich\n",
      "  Client 6: Size=1951, Weight=0.1623, Quality=rich\n",
      "  Client 7: Size=  50, Weight=0.0042, Quality=broken\n",
      "  Client 8: Size= 200, Weight=0.0166, Quality=poor\n",
      "  Client 9: Size=6957, Weight=0.5787, Quality=rich\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 14.96% accuracy, 8.5616 loss\n",
      "\n",
      "🔵 ROUND 8/8 - FedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.2472\n",
      "     Epoch 2: Loss = 3.0304\n",
      "   ✅ Training complete. Final avg loss: 3.1388\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.2996\n",
      "     Epoch 2: Loss = 1.1804\n",
      "   ✅ Training complete. Final avg loss: 1.2400\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0216\n",
      "     Epoch 2: Loss = 1.6693\n",
      "   ✅ Training complete. Final avg loss: 1.8454\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4468\n",
      "     Epoch 2: Loss = 1.3645\n",
      "   ✅ Training complete. Final avg loss: 1.4057\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6470\n",
      "     Epoch 2: Loss = 1.3896\n",
      "   ✅ Training complete. Final avg loss: 1.5183\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.1098\n",
      "     Epoch 2: Loss = 2.7764\n",
      "   ✅ Training complete. Final avg loss: 2.9431\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 3.7720\n",
      "     Epoch 2: Loss = 3.2347\n",
      "   ✅ Training complete. Final avg loss: 3.5034\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5996\n",
      "     Epoch 2: Loss = 1.2895\n",
      "   ✅ Training complete. Final avg loss: 1.4445\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4942\n",
      "     Epoch 2: Loss = 1.4334\n",
      "   ✅ Training complete. Final avg loss: 1.9638\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9892\n",
      "     Epoch 2: Loss = 1.7846\n",
      "   ✅ Training complete. Final avg loss: 1.8869\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🔵 Standard FedAvg Aggregation - Round 8\n",
      "   resource scenario\n",
      "--------------------------------------------------\n",
      "📊 Simple Size-Based Weights:\n",
      "  Client 0: Size=  50, Weight=0.0064, Quality=broken\n",
      "  Client 1: Size=4764, Weight=0.6057, Quality=rich\n",
      "  Client 2: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 3: Size=1951, Weight=0.2481, Quality=rich\n",
      "  Client 4: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 5: Size=  50, Weight=0.0064, Quality=broken\n",
      "  Client 6: Size=  50, Weight=0.0064, Quality=broken\n",
      "  Client 7: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 8: Size= 200, Weight=0.0254, Quality=poor\n",
      "  Client 9: Size= 200, Weight=0.0254, Quality=poor\n",
      "⚠️  WARNING: Including ALL clients regardless of quality!\n",
      "🔄 Standard FedAvg: Aggregated 10 clients\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🔵 Standard FedAvg Evaluation: 15.59% accuracy, 6.4295 loss\n",
      "\n",
      "🔵 FEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 15.59%\n",
      "   Best Accuracy: 19.24%\n",
      "\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "💀 TESTING ROBUSTSMARTFEDAVG vs RESOURCE\n",
      "🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️🛡️\n",
      "🛡️  ROBUST SmartFedAvg Thresholds for 'resource':\n",
      "   Quality threshold: 0.200\n",
      "   Minimum clients ratio: 50.0%\n",
      "\n",
      "🛡️ ROUND 1/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2921\n",
      "     Epoch 2: Loss = 2.2398\n",
      "   ✅ Training complete. Final avg loss: 2.2659\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9428\n",
      "     Epoch 2: Loss = 1.7229\n",
      "   ✅ Training complete. Final avg loss: 1.8328\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0096\n",
      "     Epoch 2: Loss = 1.7996\n",
      "   ✅ Training complete. Final avg loss: 1.9046\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2859\n",
      "     Epoch 2: Loss = 2.2865\n",
      "   ✅ Training complete. Final avg loss: 2.2862\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3083\n",
      "     Epoch 2: Loss = 2.2267\n",
      "   ✅ Training complete. Final avg loss: 2.2675\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3077\n",
      "     Epoch 2: Loss = 2.3063\n",
      "   ✅ Training complete. Final avg loss: 2.3070\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3110\n",
      "     Epoch 2: Loss = 2.3067\n",
      "   ✅ Training complete. Final avg loss: 2.3089\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7709\n",
      "     Epoch 2: Loss = 1.6566\n",
      "   ✅ Training complete. Final avg loss: 1.7138\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3096\n",
      "     Epoch 2: Loss = 2.2450\n",
      "   ✅ Training complete. Final avg loss: 2.2773\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3138\n",
      "     Epoch 2: Loss = 2.2294\n",
      "   ✅ Training complete. Final avg loss: 2.2716\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 1\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=2.188, Loss_std=0.081, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.453\n",
      "      Stability: 0.973, Confidence: 0.082\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.298, Loss=1.678, Loss_std=0.986, Entropy=1.620\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.994, Loss: 0.580\n",
      "      Stability: 0.671, Confidence: 0.352\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.711\n",
      "   ✅ Decision: KEEP (Score 0.711 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.830, Loss_std=0.811, Entropy=1.805\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.543\n",
      "      Stability: 0.730, Confidence: 0.278\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.704\n",
      "   ✅ Decision: KEEP (Score 0.704 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.140, Loss=2.281, Loss_std=0.039, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.467, Loss: 0.430\n",
      "      Stability: 0.987, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.398\n",
      "   ✅ Decision: KEEP (Score 0.398 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=2.161, Loss_std=0.132, Entropy=2.296\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.460\n",
      "      Stability: 0.956, Confidence: 0.082\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.701\n",
      "   ✅ Decision: KEEP (Score 0.701 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.299, Loss_std=0.032, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.425\n",
      "      Stability: 0.989, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.352\n",
      "   ✅ Decision: KEEP (Score 0.352 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.300, Loss_std=0.031, Entropy=2.302\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.425\n",
      "      Stability: 0.990, Confidence: 0.079\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.352\n",
      "   ✅ Decision: KEEP (Score 0.352 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.425, Loss=1.579, Loss_std=0.569, Entropy=1.764\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.605\n",
      "      Stability: 0.810, Confidence: 0.294\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.739\n",
      "   ✅ Decision: KEEP (Score 0.739 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=2.182, Loss_std=0.151, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.455\n",
      "      Stability: 0.950, Confidence: 0.081\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.699\n",
      "   ✅ Decision: KEEP (Score 0.699 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.440, Loss=2.167, Loss_std=0.110, Entropy=2.297\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.458\n",
      "      Stability: 0.963, Confidence: 0.081\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.703\n",
      "   ✅ Decision: KEEP (Score 0.703 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      7 |  0.980 |     0.739 |    6957 | KEEP     | Score 0.739 ≥ threshold 0.200\n",
      "      2 |      1 |  0.980 |     0.711 |    2013 | KEEP     | Score 0.711 ≥ threshold 0.200\n",
      "      3 |      2 |  0.980 |     0.704 |    1951 | KEEP     | Score 0.704 ≥ threshold 0.200\n",
      "      4 |      0 |  0.980 |     0.704 |     200 | KEEP     | Score 0.704 ≥ threshold 0.200\n",
      "      5 |      9 |  0.980 |     0.703 |     200 | KEEP     | Score 0.703 ≥ threshold 0.200\n",
      "      6 |      4 |  0.980 |     0.701 |     200 | KEEP     | Score 0.701 ≥ threshold 0.200\n",
      "      7 |      8 |  0.980 |     0.699 |     200 | KEEP     | Score 0.699 ≥ threshold 0.200\n",
      "      8 |      3 |  0.080 |     0.398 |      50 | KEEP     | Score 0.398 ≥ threshold 0.200\n",
      "      9 |      6 |  0.080 |     0.352 |      50 | KEEP     | Score 0.352 ≥ threshold 0.200\n",
      "     10 |      5 |  0.080 |     0.352 |      50 | KEEP     | Score 0.352 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [7, 1, 2, 0, 9, 4, 8, 3, 6, 5])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.606\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        7 | 6957 |   0.739 |  0.586 |  0.138 |   0.317\n",
      "        1 | 2013 |   0.711 |  0.170 |  0.130 |   0.146\n",
      "        2 | 1951 |   0.704 |  0.164 |  0.128 |   0.142\n",
      "        0 |  200 |   0.704 |  0.017 |  0.127 |   0.083\n",
      "        9 |  200 |   0.703 |  0.017 |  0.127 |   0.083\n",
      "        4 |  200 |   0.701 |  0.017 |  0.127 |   0.083\n",
      "        8 |  200 |   0.699 |  0.017 |  0.126 |   0.082\n",
      "        3 |   50 |   0.398 |  0.004 |  0.041 |   0.026\n",
      "        6 |   50 |   0.352 |  0.004 |  0.028 |   0.019\n",
      "        5 |   50 |   0.352 |  0.004 |  0.028 |   0.019\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 11.64% accuracy, 2.3372 loss\n",
      "\n",
      "🛡️ ROUND 2/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4433\n",
      "     Epoch 2: Loss = 2.4190\n",
      "   ✅ Training complete. Final avg loss: 2.4311\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8260\n",
      "     Epoch 2: Loss = 1.6884\n",
      "   ✅ Training complete. Final avg loss: 1.7572\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3159\n",
      "     Epoch 2: Loss = 2.3196\n",
      "   ✅ Training complete. Final avg loss: 2.3177\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3284\n",
      "     Epoch 2: Loss = 2.3292\n",
      "   ✅ Training complete. Final avg loss: 2.3288\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2884\n",
      "     Epoch 2: Loss = 2.1272\n",
      "   ✅ Training complete. Final avg loss: 2.2078\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.4257\n",
      "     Epoch 2: Loss = 2.2395\n",
      "   ✅ Training complete. Final avg loss: 2.3326\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7307\n",
      "     Epoch 2: Loss = 1.5234\n",
      "   ✅ Training complete. Final avg loss: 1.6271\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2755\n",
      "     Epoch 2: Loss = 2.2758\n",
      "   ✅ Training complete. Final avg loss: 2.2756\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1558\n",
      "     Epoch 2: Loss = 1.9900\n",
      "   ✅ Training complete. Final avg loss: 2.0729\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3609\n",
      "     Epoch 2: Loss = 2.3697\n",
      "   ✅ Training complete. Final avg loss: 2.3653\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 2\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.387, Loss_std=0.307, Entropy=2.264\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.403\n",
      "      Stability: 0.898, Confidence: 0.094\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.332\n",
      "   ✅ Decision: KEEP (Score 0.332 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.413, Loss=1.583, Loss_std=0.798, Entropy=1.749\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.604\n",
      "      Stability: 0.734, Confidence: 0.300\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.723\n",
      "   ✅ Decision: KEEP (Score 0.723 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.302, Loss_std=0.259, Entropy=2.260\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.424\n",
      "      Stability: 0.914, Confidence: 0.096\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.325\n",
      "   ✅ Decision: KEEP (Score 0.325 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.040, Loss=2.302, Loss_std=0.280, Entropy=2.260\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.133, Loss: 0.425\n",
      "      Stability: 0.907, Confidence: 0.096\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.308\n",
      "   ✅ Decision: KEEP (Score 0.308 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.941, Loss_std=0.483, Entropy=2.206\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.515\n",
      "      Stability: 0.839, Confidence: 0.118\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.694\n",
      "   ✅ Decision: KEEP (Score 0.694 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.145, Loss=2.127, Loss_std=0.136, Entropy=2.278\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.483, Loss: 0.468\n",
      "      Stability: 0.955, Confidence: 0.089\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.565\n",
      "   ✅ Decision: KEEP (Score 0.565 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.505, Loss=1.468, Loss_std=1.158, Entropy=1.457\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.633\n",
      "      Stability: 0.614, Confidence: 0.417\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.724\n",
      "   ✅ Decision: KEEP (Score 0.724 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.220, Loss=2.252, Loss_std=0.380, Entropy=2.249\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.733, Loss: 0.437\n",
      "      Stability: 0.873, Confidence: 0.100\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.442\n",
      "   ✅ Decision: KEEP (Score 0.442 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.305, Loss=1.851, Loss_std=0.471, Entropy=2.100\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.537\n",
      "      Stability: 0.843, Confidence: 0.160\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.707\n",
      "   ✅ Decision: KEEP (Score 0.707 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.338, Loss_std=0.270, Entropy=2.263\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.416\n",
      "      Stability: 0.910, Confidence: 0.095\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.322\n",
      "   ✅ Decision: KEEP (Score 0.322 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.724 |    4764 | KEEP     | Score 0.724 ≥ threshold 0.200\n",
      "      2 |      1 |  0.980 |     0.723 |    2013 | KEEP     | Score 0.723 ≥ threshold 0.200\n",
      "      3 |      8 |  0.980 |     0.707 |     200 | KEEP     | Score 0.707 ≥ threshold 0.200\n",
      "      4 |      4 |  0.980 |     0.694 |     200 | KEEP     | Score 0.694 ≥ threshold 0.200\n",
      "      5 |      5 |  0.980 |     0.565 |     200 | KEEP     | Score 0.565 ≥ threshold 0.200\n",
      "      6 |      7 |  0.080 |     0.442 |      50 | KEEP     | Score 0.442 ≥ threshold 0.200\n",
      "      7 |      0 |  0.080 |     0.332 |      50 | KEEP     | Score 0.332 ≥ threshold 0.200\n",
      "      8 |      2 |  0.080 |     0.325 |      50 | KEEP     | Score 0.325 ≥ threshold 0.200\n",
      "      9 |      9 |  0.080 |     0.322 |      50 | KEEP     | Score 0.322 ≥ threshold 0.200\n",
      "     10 |      3 |  0.080 |     0.308 |      50 | KEEP     | Score 0.308 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [6, 1, 8, 4, 5, 7, 0, 2, 9, 3])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.514\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 4764 |   0.724 |  0.625 |  0.168 |   0.351\n",
      "        1 | 2013 |   0.723 |  0.264 |  0.168 |   0.207\n",
      "        8 |  200 |   0.707 |  0.026 |  0.163 |   0.108\n",
      "        4 |  200 |   0.694 |  0.026 |  0.159 |   0.106\n",
      "        5 |  200 |   0.565 |  0.026 |  0.116 |   0.080\n",
      "        7 |   50 |   0.442 |  0.007 |  0.077 |   0.049\n",
      "        0 |   50 |   0.332 |  0.007 |  0.041 |   0.027\n",
      "        2 |   50 |   0.325 |  0.007 |  0.038 |   0.025\n",
      "        9 |   50 |   0.322 |  0.007 |  0.037 |   0.025\n",
      "        3 |   50 |   0.308 |  0.007 |  0.033 |   0.022\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 16.43% accuracy, 2.3009 loss\n",
      "\n",
      "🛡️ ROUND 3/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8896\n",
      "     Epoch 2: Loss = 1.7841\n",
      "   ✅ Training complete. Final avg loss: 1.8369\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3565\n",
      "     Epoch 2: Loss = 2.3417\n",
      "   ✅ Training complete. Final avg loss: 2.3491\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1493\n",
      "     Epoch 2: Loss = 1.9880\n",
      "   ✅ Training complete. Final avg loss: 2.0687\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4084\n",
      "     Epoch 2: Loss = 2.3709\n",
      "   ✅ Training complete. Final avg loss: 2.3896\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1095\n",
      "     Epoch 2: Loss = 1.7993\n",
      "   ✅ Training complete. Final avg loss: 1.9544\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.2942\n",
      "     Epoch 2: Loss = 1.9829\n",
      "   ✅ Training complete. Final avg loss: 2.1386\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4988\n",
      "     Epoch 2: Loss = 2.4690\n",
      "   ✅ Training complete. Final avg loss: 2.4839\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.1797\n",
      "     Epoch 2: Loss = 2.2229\n",
      "   ✅ Training complete. Final avg loss: 2.2013\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4048\n",
      "     Epoch 2: Loss = 2.3660\n",
      "   ✅ Training complete. Final avg loss: 2.3854\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5742\n",
      "     Epoch 2: Loss = 1.4961\n",
      "   ✅ Training complete. Final avg loss: 1.5352\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 3\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.397, Loss=1.705, Loss_std=0.940, Entropy=1.687\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.574\n",
      "      Stability: 0.687, Confidence: 0.325\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.040, Loss=2.301, Loss_std=0.247, Entropy=2.257\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.133, Loss: 0.425\n",
      "      Stability: 0.918, Confidence: 0.097\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.310\n",
      "   ✅ Decision: KEEP (Score 0.310 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=1.856, Loss_std=0.820, Entropy=1.983\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.536\n",
      "      Stability: 0.727, Confidence: 0.207\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.689\n",
      "   ✅ Decision: KEEP (Score 0.689 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.316, Loss_std=0.239, Entropy=2.263\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.421\n",
      "      Stability: 0.920, Confidence: 0.095\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.325\n",
      "   ✅ Decision: KEEP (Score 0.325 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.621, Loss_std=0.767, Entropy=1.872\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.595\n",
      "      Stability: 0.744, Confidence: 0.251\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.455, Loss=1.795, Loss_std=0.486, Entropy=2.153\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.551\n",
      "      Stability: 0.838, Confidence: 0.139\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.706\n",
      "   ✅ Decision: KEEP (Score 0.706 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.429, Loss_std=0.255, Entropy=2.269\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.393\n",
      "      Stability: 0.915, Confidence: 0.093\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.333\n",
      "   ✅ Decision: KEEP (Score 0.333 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.180, Loss=2.160, Loss_std=0.327, Entropy=2.232\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.600, Loss: 0.460\n",
      "      Stability: 0.891, Confidence: 0.107\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.420\n",
      "   ✅ Decision: KEEP (Score 0.420 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.340, Loss_std=0.241, Entropy=2.264\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.415\n",
      "      Stability: 0.920, Confidence: 0.094\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.324\n",
      "   ✅ Decision: KEEP (Score 0.324 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.555, Loss=1.363, Loss_std=1.090, Entropy=1.504\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.659\n",
      "      Stability: 0.637, Confidence: 0.399\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.731\n",
      "   ✅ Decision: KEEP (Score 0.731 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      9 |  0.980 |     0.731 |    4764 | KEEP     | Score 0.731 ≥ threshold 0.200\n",
      "      2 |      4 |  0.980 |     0.715 |     200 | KEEP     | Score 0.715 ≥ threshold 0.200\n",
      "      3 |      0 |  0.980 |     0.710 |    1951 | KEEP     | Score 0.710 ≥ threshold 0.200\n",
      "      4 |      5 |  0.980 |     0.706 |     200 | KEEP     | Score 0.706 ≥ threshold 0.200\n",
      "      5 |      2 |  0.980 |     0.689 |     200 | KEEP     | Score 0.689 ≥ threshold 0.200\n",
      "      6 |      7 |  0.080 |     0.420 |      50 | KEEP     | Score 0.420 ≥ threshold 0.200\n",
      "      7 |      6 |  0.080 |     0.333 |      50 | KEEP     | Score 0.333 ≥ threshold 0.200\n",
      "      8 |      3 |  0.080 |     0.325 |      50 | KEEP     | Score 0.325 ≥ threshold 0.200\n",
      "      9 |      8 |  0.080 |     0.324 |      50 | KEEP     | Score 0.324 ≥ threshold 0.200\n",
      "     10 |      1 |  0.080 |     0.310 |      50 | KEEP     | Score 0.310 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [9, 4, 0, 5, 2, 7, 6, 3, 8, 1])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.526\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        9 | 4764 |   0.731 |  0.630 |  0.165 |   0.351\n",
      "        4 |  200 |   0.715 |  0.026 |  0.160 |   0.106\n",
      "        0 | 1951 |   0.710 |  0.258 |  0.158 |   0.198\n",
      "        5 |  200 |   0.706 |  0.026 |  0.157 |   0.105\n",
      "        2 |  200 |   0.689 |  0.026 |  0.152 |   0.101\n",
      "        7 |   50 |   0.420 |  0.007 |  0.067 |   0.043\n",
      "        6 |   50 |   0.333 |  0.007 |  0.039 |   0.026\n",
      "        3 |   50 |   0.325 |  0.007 |  0.036 |   0.024\n",
      "        8 |   50 |   0.324 |  0.007 |  0.036 |   0.024\n",
      "        1 |   50 |   0.310 |  0.007 |  0.032 |   0.022\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.62% accuracy, 2.5980 loss\n",
      "\n",
      "🛡️ ROUND 4/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5562\n",
      "     Epoch 2: Loss = 2.5574\n",
      "   ✅ Training complete. Final avg loss: 2.5568\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5277\n",
      "     Epoch 2: Loss = 1.4599\n",
      "   ✅ Training complete. Final avg loss: 1.4938\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0191\n",
      "     Epoch 2: Loss = 1.8939\n",
      "   ✅ Training complete. Final avg loss: 1.9565\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0104\n",
      "     Epoch 2: Loss = 1.7649\n",
      "   ✅ Training complete. Final avg loss: 1.8877\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1303\n",
      "     Epoch 2: Loss = 1.9514\n",
      "   ✅ Training complete. Final avg loss: 2.0409\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8311\n",
      "     Epoch 2: Loss = 1.7403\n",
      "   ✅ Training complete. Final avg loss: 1.7857\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7745\n",
      "     Epoch 2: Loss = 1.2772\n",
      "   ✅ Training complete. Final avg loss: 1.5259\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2502\n",
      "     Epoch 2: Loss = 2.1695\n",
      "   ✅ Training complete. Final avg loss: 2.2099\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3677\n",
      "     Epoch 2: Loss = 2.0090\n",
      "   ✅ Training complete. Final avg loss: 2.1883\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8168\n",
      "     Epoch 2: Loss = 1.6512\n",
      "   ✅ Training complete. Final avg loss: 1.7340\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 4\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.000, Loss=2.409, Loss_std=0.493, Entropy=2.176\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.000, Loss: 0.398\n",
      "      Stability: 0.836, Confidence: 0.129\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.264\n",
      "   ✅ Decision: KEEP (Score 0.264 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.575, Loss=1.295, Loss_std=1.128, Entropy=1.437\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.676\n",
      "      Stability: 0.624, Confidence: 0.425\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.737\n",
      "   ✅ Decision: KEEP (Score 0.737 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.475, Loss=1.792, Loss_std=1.003, Entropy=1.782\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.552\n",
      "      Stability: 0.666, Confidence: 0.287\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.694\n",
      "   ✅ Decision: KEEP (Score 0.694 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.440, Loss=1.580, Loss_std=1.058, Entropy=1.593\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.605\n",
      "      Stability: 0.647, Confidence: 0.363\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.715\n",
      "   ✅ Decision: KEEP (Score 0.715 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.295, Loss=1.878, Loss_std=0.631, Entropy=2.012\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.983, Loss: 0.531\n",
      "      Stability: 0.790, Confidence: 0.195\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.696\n",
      "   ✅ Decision: KEEP (Score 0.696 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.373, Loss=1.698, Loss_std=0.909, Entropy=1.697\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.576\n",
      "      Stability: 0.697, Confidence: 0.321\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.712\n",
      "   ✅ Decision: KEEP (Score 0.712 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.685, Loss=1.248, Loss_std=1.607, Entropy=0.882\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.688\n",
      "      Stability: 0.464, Confidence: 0.647\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.744\n",
      "   ✅ Decision: KEEP (Score 0.744 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.157, Loss_std=0.421, Entropy=2.148\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.400, Loss: 0.461\n",
      "      Stability: 0.860, Confidence: 0.141\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.374\n",
      "   ✅ Decision: KEEP (Score 0.374 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.460, Loss=1.737, Loss_std=0.508, Entropy=2.103\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.566\n",
      "      Stability: 0.831, Confidence: 0.159\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.711\n",
      "   ✅ Decision: KEEP (Score 0.711 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.433, Loss=1.584, Loss_std=0.910, Entropy=1.668\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.604\n",
      "      Stability: 0.697, Confidence: 0.333\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.721\n",
      "   ✅ Decision: KEEP (Score 0.721 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.744 |     200 | KEEP     | Score 0.744 ≥ threshold 0.200\n",
      "      2 |      1 |  0.980 |     0.737 |    4764 | KEEP     | Score 0.737 ≥ threshold 0.200\n",
      "      3 |      9 |  0.980 |     0.721 |    2013 | KEEP     | Score 0.721 ≥ threshold 0.200\n",
      "      4 |      3 |  0.980 |     0.715 |     200 | KEEP     | Score 0.715 ≥ threshold 0.200\n",
      "      5 |      5 |  0.980 |     0.712 |    1951 | KEEP     | Score 0.712 ≥ threshold 0.200\n",
      "      6 |      8 |  0.980 |     0.711 |     200 | KEEP     | Score 0.711 ≥ threshold 0.200\n",
      "      7 |      4 |  0.980 |     0.696 |     200 | KEEP     | Score 0.696 ≥ threshold 0.200\n",
      "      8 |      2 |  0.980 |     0.694 |     200 | KEEP     | Score 0.694 ≥ threshold 0.200\n",
      "      9 |      7 |  0.080 |     0.374 |      50 | KEEP     | Score 0.374 ≥ threshold 0.200\n",
      "     10 |      0 |  0.080 |     0.264 |      50 | KEEP     | Score 0.264 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [6, 1, 9, 3, 5, 8, 4, 2, 7, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.637\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 |  200 |   0.744 |  0.020 |  0.123 |   0.082\n",
      "        1 | 4764 |   0.737 |  0.485 |  0.121 |   0.267\n",
      "        9 | 2013 |   0.721 |  0.205 |  0.118 |   0.153\n",
      "        3 |  200 |   0.715 |  0.020 |  0.117 |   0.078\n",
      "        5 | 1951 |   0.712 |  0.199 |  0.116 |   0.149\n",
      "        8 |  200 |   0.711 |  0.020 |  0.116 |   0.078\n",
      "        4 |  200 |   0.696 |  0.020 |  0.112 |   0.076\n",
      "        2 |  200 |   0.694 |  0.020 |  0.112 |   0.075\n",
      "        7 |   50 |   0.374 |  0.005 |  0.044 |   0.029\n",
      "        0 |   50 |   0.264 |  0.005 |  0.021 |   0.015\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 14.73% accuracy, 2.7002 loss\n",
      "\n",
      "🛡️ ROUND 5/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4833\n",
      "     Epoch 2: Loss = 2.4473\n",
      "   ✅ Training complete. Final avg loss: 2.4653\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.4352\n",
      "     Epoch 2: Loss = 2.3766\n",
      "   ✅ Training complete. Final avg loss: 2.4059\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4836\n",
      "     Epoch 2: Loss = 1.4082\n",
      "   ✅ Training complete. Final avg loss: 1.4459\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6202\n",
      "     Epoch 2: Loss = 2.5075\n",
      "   ✅ Training complete. Final avg loss: 2.5639\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8005\n",
      "     Epoch 2: Loss = 1.6321\n",
      "   ✅ Training complete. Final avg loss: 1.7163\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7592\n",
      "     Epoch 2: Loss = 2.7005\n",
      "   ✅ Training complete. Final avg loss: 2.7298\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6353\n",
      "     Epoch 2: Loss = 1.4587\n",
      "   ✅ Training complete. Final avg loss: 1.5470\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.3473\n",
      "     Epoch 2: Loss = 1.9065\n",
      "   ✅ Training complete. Final avg loss: 2.1269\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7296\n",
      "     Epoch 2: Loss = 1.5771\n",
      "   ✅ Training complete. Final avg loss: 1.6533\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.2229\n",
      "     Epoch 2: Loss = 2.1416\n",
      "   ✅ Training complete. Final avg loss: 2.1822\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 5\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.020, Loss=2.380, Loss_std=0.413, Entropy=2.167\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.067, Loss: 0.405\n",
      "      Stability: 0.862, Confidence: 0.133\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.286\n",
      "   ✅ Decision: KEEP (Score 0.286 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.349, Loss_std=0.513, Entropy=2.169\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.413\n",
      "      Stability: 0.829, Confidence: 0.132\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.327\n",
      "   ✅ Decision: KEEP (Score 0.327 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.570, Loss=1.310, Loss_std=1.006, Entropy=1.506\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.672\n",
      "      Stability: 0.665, Confidence: 0.398\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.740\n",
      "   ✅ Decision: KEEP (Score 0.740 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.407, Loss_std=0.478, Entropy=2.175\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.398\n",
      "      Stability: 0.841, Confidence: 0.130\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.326\n",
      "   ✅ Decision: KEEP (Score 0.326 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.413, Loss=1.635, Loss_std=1.175, Entropy=1.458\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.591\n",
      "      Stability: 0.608, Confidence: 0.417\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.713\n",
      "   ✅ Decision: KEEP (Score 0.713 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.100, Loss=2.614, Loss_std=0.528, Entropy=2.175\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.333, Loss: 0.346\n",
      "      Stability: 0.824, Confidence: 0.130\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.328\n",
      "   ✅ Decision: KEEP (Score 0.328 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.502, Loss=1.373, Loss_std=0.870, Entropy=1.515\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.657\n",
      "      Stability: 0.710, Confidence: 0.394\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.746\n",
      "   ✅ Decision: KEEP (Score 0.746 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.470, Loss=1.669, Loss_std=0.672, Entropy=1.971\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.583\n",
      "      Stability: 0.776, Confidence: 0.211\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.712\n",
      "   ✅ Decision: KEEP (Score 0.712 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.447, Loss=1.452, Loss_std=0.854, Entropy=1.589\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.637\n",
      "      Stability: 0.715, Confidence: 0.364\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.140, Loss_std=0.519, Entropy=2.110\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.400, Loss: 0.465\n",
      "      Stability: 0.827, Confidence: 0.156\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.371\n",
      "   ✅ Decision: KEEP (Score 0.371 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      6 |  0.980 |     0.746 |    6957 | KEEP     | Score 0.746 ≥ threshold 0.200\n",
      "      2 |      2 |  0.980 |     0.740 |    4764 | KEEP     | Score 0.740 ≥ threshold 0.200\n",
      "      3 |      8 |  0.980 |     0.738 |    2013 | KEEP     | Score 0.738 ≥ threshold 0.200\n",
      "      4 |      4 |  0.980 |     0.713 |    1951 | KEEP     | Score 0.713 ≥ threshold 0.200\n",
      "      5 |      7 |  0.980 |     0.712 |     200 | KEEP     | Score 0.712 ≥ threshold 0.200\n",
      "      6 |      9 |  0.080 |     0.371 |      50 | KEEP     | Score 0.371 ≥ threshold 0.200\n",
      "      7 |      5 |  0.080 |     0.328 |      50 | KEEP     | Score 0.328 ≥ threshold 0.200\n",
      "      8 |      1 |  0.080 |     0.327 |      50 | KEEP     | Score 0.327 ≥ threshold 0.200\n",
      "      9 |      3 |  0.080 |     0.326 |      50 | KEEP     | Score 0.326 ≥ threshold 0.200\n",
      "     10 |      0 |  0.080 |     0.286 |      50 | KEEP     | Score 0.286 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [6, 2, 8, 4, 7, 9, 5, 1, 3, 0])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.529\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        6 | 6957 |   0.746 |  0.431 |  0.164 |   0.271\n",
      "        2 | 4764 |   0.740 |  0.295 |  0.162 |   0.215\n",
      "        8 | 2013 |   0.738 |  0.125 |  0.161 |   0.147\n",
      "        4 | 1951 |   0.713 |  0.121 |  0.154 |   0.141\n",
      "        7 |  200 |   0.712 |  0.012 |  0.153 |   0.097\n",
      "        9 |   50 |   0.371 |  0.003 |  0.054 |   0.034\n",
      "        5 |   50 |   0.328 |  0.003 |  0.042 |   0.026\n",
      "        1 |   50 |   0.327 |  0.003 |  0.041 |   0.026\n",
      "        3 |   50 |   0.326 |  0.003 |  0.041 |   0.026\n",
      "        0 |   50 |   0.286 |  0.003 |  0.029 |   0.019\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.97% accuracy, 2.6884 loss\n",
      "\n",
      "🛡️ ROUND 6/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 8: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4948\n",
      "     Epoch 2: Loss = 1.3813\n",
      "   ✅ Training complete. Final avg loss: 1.4381\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6053\n",
      "     Epoch 2: Loss = 1.4960\n",
      "   ✅ Training complete. Final avg loss: 1.5507\n",
      "🔧 Training Client 8 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.1708\n",
      "     Epoch 2: Loss = 1.8029\n",
      "   ✅ Training complete. Final avg loss: 1.9868\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9314\n",
      "     Epoch 2: Loss = 1.7302\n",
      "   ✅ Training complete. Final avg loss: 1.8308\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9433\n",
      "     Epoch 2: Loss = 1.2660\n",
      "   ✅ Training complete. Final avg loss: 1.6047\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.3818\n",
      "     Epoch 2: Loss = 2.2813\n",
      "   ✅ Training complete. Final avg loss: 2.3316\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.5351\n",
      "     Epoch 2: Loss = 2.4401\n",
      "   ✅ Training complete. Final avg loss: 2.4876\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 2.0175\n",
      "     Epoch 2: Loss = 1.7605\n",
      "   ✅ Training complete. Final avg loss: 1.8890\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6460\n",
      "     Epoch 2: Loss = 1.5423\n",
      "   ✅ Training complete. Final avg loss: 1.5942\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4563\n",
      "     Epoch 2: Loss = 1.3713\n",
      "   ✅ Training complete. Final avg loss: 1.4138\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 6\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.596, Loss=1.232, Loss_std=1.002, Entropy=1.341\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.692\n",
      "      Stability: 0.666, Confidence: 0.464\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.757\n",
      "   ✅ Decision: KEEP (Score 0.757 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.490, Loss=1.450, Loss_std=1.071, Entropy=1.474\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.637\n",
      "      Stability: 0.643, Confidence: 0.410\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.730\n",
      "   ✅ Decision: KEEP (Score 0.730 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.445, Loss=1.566, Loss_std=0.739, Entropy=1.801\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.608\n",
      "      Stability: 0.754, Confidence: 0.280\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.725\n",
      "   ✅ Decision: KEEP (Score 0.725 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.505, Loss=1.605, Loss_std=0.873, Entropy=1.835\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.599\n",
      "      Stability: 0.709, Confidence: 0.266\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.710\n",
      "   ✅ Decision: KEEP (Score 0.710 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.685, Loss=1.208, Loss_std=1.574, Entropy=0.838\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.698\n",
      "      Stability: 0.475, Confidence: 0.665\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.752\n",
      "   ✅ Decision: KEEP (Score 0.752 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.200, Loss=2.191, Loss_std=0.696, Entropy=2.017\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.667, Loss: 0.452\n",
      "      Stability: 0.768, Confidence: 0.193\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.424\n",
      "   ✅ Decision: KEEP (Score 0.424 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.364, Loss_std=0.579, Entropy=2.131\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.409\n",
      "      Stability: 0.807, Confidence: 0.148\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.324\n",
      "   ✅ Decision: KEEP (Score 0.324 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.520, Loss=1.557, Loss_std=0.940, Entropy=1.719\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.611\n",
      "      Stability: 0.687, Confidence: 0.312\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.517, Loss=1.414, Loss_std=0.942, Entropy=1.522\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.647\n",
      "      Stability: 0.686, Confidence: 0.391\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.738\n",
      "   ✅ Decision: KEEP (Score 0.738 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.579, Loss=1.298, Loss_std=1.026, Entropy=1.484\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.676\n",
      "      Stability: 0.658, Confidence: 0.406\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.741\n",
      "   ✅ Decision: KEEP (Score 0.741 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      0 |  0.980 |     0.757 |    6957 | KEEP     | Score 0.757 ≥ threshold 0.200\n",
      "      2 |      4 |  0.980 |     0.752 |     200 | KEEP     | Score 0.752 ≥ threshold 0.200\n",
      "      3 |      9 |  0.980 |     0.741 |    4764 | KEEP     | Score 0.741 ≥ threshold 0.200\n",
      "      4 |      8 |  0.980 |     0.738 |    1951 | KEEP     | Score 0.738 ≥ threshold 0.200\n",
      "      5 |      1 |  0.980 |     0.730 |    2013 | KEEP     | Score 0.730 ≥ threshold 0.200\n",
      "      6 |      2 |  0.980 |     0.725 |     200 | KEEP     | Score 0.725 ≥ threshold 0.200\n",
      "      7 |      7 |  0.980 |     0.716 |     200 | KEEP     | Score 0.716 ≥ threshold 0.200\n",
      "      8 |      3 |  0.980 |     0.710 |     200 | KEEP     | Score 0.710 ≥ threshold 0.200\n",
      "      9 |      5 |  0.080 |     0.424 |      50 | KEEP     | Score 0.424 ≥ threshold 0.200\n",
      "     10 |      6 |  0.080 |     0.324 |      50 | KEEP     | Score 0.324 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [0, 4, 9, 8, 1, 2, 7, 3, 5, 6])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.662\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        0 | 6957 |   0.757 |  0.419 |  0.122 |   0.241\n",
      "        4 |  200 |   0.752 |  0.012 |  0.121 |   0.077\n",
      "        9 | 4764 |   0.741 |  0.287 |  0.118 |   0.186\n",
      "        8 | 1951 |   0.738 |  0.118 |  0.117 |   0.118\n",
      "        1 | 2013 |   0.730 |  0.121 |  0.116 |   0.118\n",
      "        2 |  200 |   0.725 |  0.012 |  0.114 |   0.073\n",
      "        7 |  200 |   0.716 |  0.012 |  0.112 |   0.072\n",
      "        3 |  200 |   0.710 |  0.012 |  0.111 |   0.071\n",
      "        5 |   50 |   0.424 |  0.003 |  0.046 |   0.029\n",
      "        6 |   50 |   0.324 |  0.003 |  0.023 |   0.015\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.73% accuracy, 3.1873 loss\n",
      "\n",
      "🛡️ ROUND 7/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 6: RICH (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 7: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 2: BROKEN (score: 0.080)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "   Client 3: BROKEN (score: 0.080)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 6 (rich):\n",
      "   Samples: 2013, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5837\n",
      "     Epoch 2: Loss = 1.4636\n",
      "   ✅ Training complete. Final avg loss: 1.5237\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4389\n",
      "     Epoch 2: Loss = 1.3102\n",
      "   ✅ Training complete. Final avg loss: 1.3746\n",
      "🔧 Training Client 7 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6354\n",
      "     Epoch 2: Loss = 2.5863\n",
      "   ✅ Training complete. Final avg loss: 2.6108\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.7398\n",
      "     Epoch 2: Loss = 1.2069\n",
      "   ✅ Training complete. Final avg loss: 1.4734\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6042\n",
      "     Epoch 2: Loss = 1.5203\n",
      "   ✅ Training complete. Final avg loss: 1.5622\n",
      "🔧 Training Client 2 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6562\n",
      "     Epoch 2: Loss = 2.4701\n",
      "   ✅ Training complete. Final avg loss: 2.5632\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.4038\n",
      "     Epoch 2: Loss = 1.3142\n",
      "   ✅ Training complete. Final avg loss: 1.3590\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8560\n",
      "     Epoch 2: Loss = 1.6139\n",
      "   ✅ Training complete. Final avg loss: 1.7350\n",
      "🔧 Training Client 3 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.9999\n",
      "     Epoch 2: Loss = 2.8473\n",
      "   ✅ Training complete. Final avg loss: 2.9236\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8998\n",
      "     Epoch 2: Loss = 1.6101\n",
      "   ✅ Training complete. Final avg loss: 1.7550\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 7\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.514, Loss=1.377, Loss_std=0.929, Entropy=1.500\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.656\n",
      "      Stability: 0.690, Confidence: 0.400\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.743\n",
      "   ✅ Decision: KEEP (Score 0.743 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.526, Loss=1.375, Loss_std=1.120, Entropy=1.320\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.656\n",
      "      Stability: 0.627, Confidence: 0.472\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.742\n",
      "   ✅ Decision: KEEP (Score 0.742 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.040, Loss=2.510, Loss_std=0.832, Entropy=2.048\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.133, Loss: 0.373\n",
      "      Stability: 0.723, Confidence: 0.181\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.276\n",
      "   ✅ Decision: KEEP (Score 0.276 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.685, Loss=1.194, Loss_std=1.665, Entropy=0.701\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.701\n",
      "      Stability: 0.445, Confidence: 0.720\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.756\n",
      "   ✅ Decision: KEEP (Score 0.756 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.423, Loss=1.534, Loss_std=1.071, Entropy=1.450\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.616\n",
      "      Stability: 0.643, Confidence: 0.420\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.727\n",
      "   ✅ Decision: KEEP (Score 0.727 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.120, Loss=2.402, Loss_std=0.752, Entropy=2.043\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.400, Loss: 0.400\n",
      "      Stability: 0.749, Confidence: 0.183\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.348\n",
      "   ✅ Decision: KEEP (Score 0.348 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.546, Loss=1.325, Loss_std=1.094, Entropy=1.367\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.669\n",
      "      Stability: 0.635, Confidence: 0.453\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.743\n",
      "   ✅ Decision: KEEP (Score 0.743 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.550, Loss=1.531, Loss_std=0.893, Entropy=1.781\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.617\n",
      "      Stability: 0.702, Confidence: 0.287\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.717\n",
      "   ✅ Decision: KEEP (Score 0.717 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.060, Loss=2.626, Loss_std=0.700, Entropy=2.062\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.200, Loss: 0.343\n",
      "      Stability: 0.767, Confidence: 0.175\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.293\n",
      "   ✅ Decision: KEEP (Score 0.293 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.505, Loss=1.476, Loss_std=0.841, Entropy=1.708\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.631\n",
      "      Stability: 0.720, Confidence: 0.317\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.729\n",
      "   ✅ Decision: KEEP (Score 0.729 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.756 |     200 | KEEP     | Score 0.756 ≥ threshold 0.200\n",
      "      2 |      6 |  0.980 |     0.743 |    4764 | KEEP     | Score 0.743 ≥ threshold 0.200\n",
      "      3 |      0 |  0.980 |     0.743 |    2013 | KEEP     | Score 0.743 ≥ threshold 0.200\n",
      "      4 |      1 |  0.980 |     0.742 |    6957 | KEEP     | Score 0.742 ≥ threshold 0.200\n",
      "      5 |      9 |  0.980 |     0.729 |     200 | KEEP     | Score 0.729 ≥ threshold 0.200\n",
      "      6 |      4 |  0.980 |     0.727 |    1951 | KEEP     | Score 0.727 ≥ threshold 0.200\n",
      "      7 |      7 |  0.980 |     0.717 |     200 | KEEP     | Score 0.717 ≥ threshold 0.200\n",
      "      8 |      5 |  0.080 |     0.348 |      50 | KEEP     | Score 0.348 ≥ threshold 0.200\n",
      "      9 |      8 |  0.080 |     0.293 |      50 | KEEP     | Score 0.293 ≥ threshold 0.200\n",
      "     10 |      2 |  0.080 |     0.276 |      50 | KEEP     | Score 0.276 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [3, 6, 0, 1, 9, 4, 7, 5, 8, 2])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.607\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 |  200 |   0.756 |  0.012 |  0.134 |   0.085\n",
      "        6 | 4764 |   0.743 |  0.290 |  0.131 |   0.195\n",
      "        0 | 2013 |   0.743 |  0.122 |  0.131 |   0.128\n",
      "        1 | 6957 |   0.742 |  0.423 |  0.131 |   0.248\n",
      "        9 |  200 |   0.729 |  0.012 |  0.128 |   0.082\n",
      "        4 | 1951 |   0.727 |  0.119 |  0.128 |   0.124\n",
      "        7 |  200 |   0.717 |  0.012 |  0.125 |   0.080\n",
      "        5 |   50 |   0.348 |  0.003 |  0.040 |   0.025\n",
      "        8 |   50 |   0.293 |  0.003 |  0.027 |   0.018\n",
      "        2 |   50 |   0.276 |  0.003 |  0.023 |   0.015\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 17.73% accuracy, 3.5212 loss\n",
      "\n",
      "🛡️ ROUND 8/8 - RobustSmartFedAvg\n",
      "======================================================================\n",
      "💀 Selected Clients for EXTREME test:\n",
      "   Client 9: RICH (score: 0.980)\n",
      "   Client 12: POOR (score: 0.980)\n",
      "   Client 1: RICH (score: 0.980)\n",
      "   Client 0: RICH (score: 0.980)\n",
      "   Client 11: BROKEN (score: 0.080)\n",
      "   Client 10: POOR (score: 0.980)\n",
      "   Client 14: POOR (score: 0.980)\n",
      "   Client 4: BROKEN (score: 0.080)\n",
      "   Client 13: POOR (score: 0.980)\n",
      "   Client 5: POOR (score: 0.980)\n",
      "\n",
      "🔧 LOCAL TRAINING PHASE\n",
      "------------------------------\n",
      "🔧 Training Client 9 (rich):\n",
      "   Samples: 1951, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5524\n",
      "     Epoch 2: Loss = 1.4754\n",
      "   ✅ Training complete. Final avg loss: 1.5139\n",
      "🔧 Training Client 12 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.9441\n",
      "     Epoch 2: Loss = 1.7582\n",
      "   ✅ Training complete. Final avg loss: 1.8512\n",
      "🔧 Training Client 1 (rich):\n",
      "   Samples: 4764, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3582\n",
      "     Epoch 2: Loss = 1.2667\n",
      "   ✅ Training complete. Final avg loss: 1.3125\n",
      "🔧 Training Client 0 (rich):\n",
      "   Samples: 6957, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.3604\n",
      "     Epoch 2: Loss = 1.2550\n",
      "   ✅ Training complete. Final avg loss: 1.3077\n",
      "🔧 Training Client 11 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.7421\n",
      "     Epoch 2: Loss = 2.5892\n",
      "   ✅ Training complete. Final avg loss: 2.6656\n",
      "🔧 Training Client 10 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.5804\n",
      "     Epoch 2: Loss = 1.2292\n",
      "   ✅ Training complete. Final avg loss: 1.4048\n",
      "🔧 Training Client 14 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.6973\n",
      "     Epoch 2: Loss = 1.5056\n",
      "   ✅ Training complete. Final avg loss: 1.6014\n",
      "🔧 Training Client 4 (broken):\n",
      "   Samples: 50, Quality: 0.080\n",
      "     Epoch 1: Loss = 2.6954\n",
      "     Epoch 2: Loss = 2.5218\n",
      "   ✅ Training complete. Final avg loss: 2.6086\n",
      "🔧 Training Client 13 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8999\n",
      "     Epoch 2: Loss = 1.5903\n",
      "   ✅ Training complete. Final avg loss: 1.7451\n",
      "🔧 Training Client 5 (poor):\n",
      "   Samples: 200, Quality: 0.980\n",
      "     Epoch 1: Loss = 1.8557\n",
      "     Epoch 2: Loss = 1.6677\n",
      "   ✅ Training complete. Final avg loss: 1.7617\n",
      "\n",
      "🔄 AGGREGATION PHASE\n",
      "------------------------------\n",
      "\n",
      "🛡️  ROBUST Client Selection - Round 8\n",
      "======================================================================\n",
      "\n",
      "🔍 ROBUST Assessment Client 0 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.507, Loss=1.445, Loss_std=0.958, Entropy=1.510\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.639\n",
      "      Stability: 0.681, Confidence: 0.396\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.736\n",
      "   ✅ Decision: KEEP (Score 0.736 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 1 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.385, Loss=1.652, Loss_std=0.774, Entropy=1.821\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.587\n",
      "      Stability: 0.742, Confidence: 0.272\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.716\n",
      "   ✅ Decision: KEEP (Score 0.716 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 2 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.625, Loss=1.138, Loss_std=1.069, Entropy=1.318\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.716\n",
      "      Stability: 0.644, Confidence: 0.473\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.759\n",
      "   ✅ Decision: KEEP (Score 0.759 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 3 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.601, Loss=1.146, Loss_std=0.936, Entropy=1.259\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.713\n",
      "      Stability: 0.688, Confidence: 0.496\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.773\n",
      "   ✅ Decision: KEEP (Score 0.773 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 4 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.080, Loss=2.530, Loss_std=1.005, Entropy=1.898\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.267, Loss: 0.367\n",
      "      Stability: 0.665, Confidence: 0.241\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.304\n",
      "   ✅ Decision: KEEP (Score 0.304 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 5 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.680, Loss=1.120, Loss_std=1.594, Entropy=0.698\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.720\n",
      "      Stability: 0.469, Confidence: 0.721\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.765\n",
      "   ✅ Decision: KEEP (Score 0.765 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 6 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.515, Loss=1.423, Loss_std=1.009, Entropy=1.500\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.644\n",
      "      Stability: 0.664, Confidence: 0.400\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.734\n",
      "   ✅ Decision: KEEP (Score 0.734 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 7 (True Quality: 0.080)\n",
      "   📊 Metrics: Acc=0.180, Loss=2.326, Loss_std=0.871, Entropy=1.843\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 0.600, Loss: 0.419\n",
      "      Stability: 0.710, Confidence: 0.263\n",
      "      Harm penalty: 0.000, Size penalty: 0.150\n",
      "      Final score: 0.402\n",
      "   ✅ Decision: KEEP (Score 0.402 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 8 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.615, Loss=1.405, Loss_std=1.102, Entropy=1.508\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.649\n",
      "      Stability: 0.633, Confidence: 0.397\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.728\n",
      "   ✅ Decision: KEEP (Score 0.728 ≥ threshold 0.200)\n",
      "\n",
      "🔍 ROBUST Assessment Client 9 (True Quality: 0.980)\n",
      "   📊 Metrics: Acc=0.575, Loss=1.501, Loss_std=0.904, Entropy=1.745\n",
      "   🎯 Quality Score Breakdown:\n",
      "      Accuracy: 1.000, Loss: 0.625\n",
      "      Stability: 0.699, Confidence: 0.302\n",
      "      Harm penalty: 0.000, Size penalty: 0.000\n",
      "      Final score: 0.720\n",
      "   ✅ Decision: KEEP (Score 0.720 ≥ threshold 0.200)\n",
      "\n",
      "📊 ROBUST Quality Assessment Ranking:\n",
      "   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\n",
      "   -----|--------|--------|-----------|---------|----------|--------\n",
      "      1 |      3 |  0.980 |     0.773 |    6957 | KEEP     | Score 0.773 ≥ threshold 0.200\n",
      "      2 |      5 |  0.980 |     0.765 |     200 | KEEP     | Score 0.765 ≥ threshold 0.200\n",
      "      3 |      2 |  0.980 |     0.759 |    4764 | KEEP     | Score 0.759 ≥ threshold 0.200\n",
      "      4 |      0 |  0.980 |     0.736 |    1951 | KEEP     | Score 0.736 ≥ threshold 0.200\n",
      "      5 |      6 |  0.980 |     0.734 |     200 | KEEP     | Score 0.734 ≥ threshold 0.200\n",
      "      6 |      8 |  0.980 |     0.728 |     200 | KEEP     | Score 0.728 ≥ threshold 0.200\n",
      "      7 |      9 |  0.980 |     0.720 |     200 | KEEP     | Score 0.720 ≥ threshold 0.200\n",
      "      8 |      1 |  0.980 |     0.716 |     200 | KEEP     | Score 0.716 ≥ threshold 0.200\n",
      "      9 |      7 |  0.080 |     0.402 |      50 | KEEP     | Score 0.402 ≥ threshold 0.200\n",
      "     10 |      4 |  0.080 |     0.304 |      50 | KEEP     | Score 0.304 ≥ threshold 0.200\n",
      "\n",
      "✅ ROBUST Selection Results:\n",
      "   Total clients: 10\n",
      "   Selected clients: 10 (IDs: [3, 5, 2, 0, 6, 8, 9, 1, 7, 4])\n",
      "   Filter rate: 0.0%\n",
      "   Average quality score: 0.664\n",
      "\n",
      "🔄 ADAPTIVE Aggregation for resource\n",
      "--------------------------------------------------\n",
      "📊 ADAPTIVE Weight Calculation:\n",
      "   Scenario: resource\n",
      "   Quality emphasis: 60.0%, Size emphasis: 40.0%\n",
      "\n",
      "   Client | Size | Quality | Size_W | Qual_W | Final_W\n",
      "   -------|------|---------|--------|--------|--------\n",
      "        3 | 6957 |   0.773 |  0.471 |  0.124 |   0.263\n",
      "        5 |  200 |   0.765 |  0.014 |  0.122 |   0.079\n",
      "        2 | 4764 |   0.759 |  0.323 |  0.121 |   0.201\n",
      "        0 | 1951 |   0.736 |  0.132 |  0.116 |   0.122\n",
      "        6 |  200 |   0.734 |  0.014 |  0.115 |   0.075\n",
      "        8 |  200 |   0.728 |  0.014 |  0.114 |   0.074\n",
      "        9 |  200 |   0.720 |  0.014 |  0.112 |   0.073\n",
      "        1 |  200 |   0.716 |  0.014 |  0.111 |   0.072\n",
      "        7 |   50 |   0.402 |  0.003 |  0.043 |   0.027\n",
      "        4 |   50 |   0.304 |  0.003 |  0.022 |   0.014\n",
      "\n",
      "   Final weight sum: 1.000000\n",
      "✅ ROBUST SmartFedAvg aggregation completed\n",
      "\n",
      "📊 EVALUATION PHASE\n",
      "------------------------------\n",
      "🛡️  RobustSmartFedAvg Evaluation: 18.41% accuracy, 4.2736 loss\n",
      "\n",
      "🛡️ ROBUSTSMARTFEDAVG FINAL RESULTS:\n",
      "   Final Accuracy: 18.41%\n",
      "   Best Accuracy: 18.41%\n",
      "   avg_filter_rate: 0.000\n",
      "   max_filter_rate: 0.000\n",
      "\n",
      "✅ EXTREME experiment completed!\n",
      "💀 Total results: 16\n",
      "\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "💀 EXTREME QUALITY EXPERIMENT ANALYSIS\n",
      "💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀💀\n",
      "\n",
      "🏆 DOMINANCE ANALYSIS BY EXTREME SCENARIO:\n",
      "============================================================\n",
      "\n",
      "💀 POISON SCENARIO:\n",
      "  📈 LR 0.005:\n",
      "    FedAvg:            20.59%\n",
      "    RobustSmartFedAvg:  19.24%\n",
      "    💔 DISADVANTAGE:  -1.35%\n",
      "    Filter Rate:        37.5%\n",
      "  📈 LR 0.01:\n",
      "    FedAvg:            25.63%\n",
      "    RobustSmartFedAvg:  23.02%\n",
      "    💔 DISADVANTAGE:  -2.61%\n",
      "    Filter Rate:        36.3%\n",
      "\n",
      "💀 CATASTROPHIC SCENARIO:\n",
      "  📈 LR 0.005:\n",
      "    FedAvg:            15.95%\n",
      "    RobustSmartFedAvg:  19.84%\n",
      "    💚 ADVANTAGE:  +3.89%\n",
      "    Filter Rate:         1.2%\n",
      "  📈 LR 0.01:\n",
      "    FedAvg:            21.51%\n",
      "    RobustSmartFedAvg:  19.12%\n",
      "    💔 DISADVANTAGE:  -2.39%\n",
      "    Filter Rate:         1.2%\n",
      "\n",
      "💀 BYZANTINE SCENARIO:\n",
      "  📈 LR 0.005:\n",
      "    FedAvg:            23.98%\n",
      "    RobustSmartFedAvg:  24.09%\n",
      "    💚 ADVANTAGE:  +0.11%\n",
      "    Filter Rate:         0.0%\n",
      "  📈 LR 0.01:\n",
      "    FedAvg:            26.62%\n",
      "    RobustSmartFedAvg:  25.49%\n",
      "    💔 DISADVANTAGE:  -1.13%\n",
      "    Filter Rate:         0.0%\n",
      "\n",
      "💀 RESOURCE SCENARIO:\n",
      "  📈 LR 0.005:\n",
      "    FedAvg:            20.20%\n",
      "    RobustSmartFedAvg:  18.49%\n",
      "    💔 DISADVANTAGE:  -1.71%\n",
      "    Filter Rate:         0.0%\n",
      "  📈 LR 0.01:\n",
      "    FedAvg:            15.59%\n",
      "    RobustSmartFedAvg:  18.41%\n",
      "    💚 ADVANTAGE:  +2.82%\n",
      "    Filter Rate:         0.0%\n",
      "\n",
      "🎯 OVERALL DOMINANCE SUMMARY:\n",
      "========================================\n",
      "RobustSmartFedAvg WINS: 3/8 (37.5%)\n",
      "⚠️  Need more extreme scenarios for SmartFedAvg dominance\n",
      "\n",
      "💚 SMARTFEDAVG EXCELS IN:\n",
      "💾 Results saved to: extreme_quality_results_20250615_011228.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ExtremeQualityConfig:\n",
    "    \"\"\"Configuration for extreme quality heterogeneity experiments\"\"\"\n",
    "    def __init__(self, lr, extreme_scenario, run_id=1):\n",
    "        # Standard FL settings\n",
    "        self.num_clients = 15  # More clients to create extreme diversity\n",
    "        self.clients_per_round = 10  # 2/3 participation\n",
    "        self.num_rounds = 8  # Keep short for quick experiments\n",
    "        self.local_epochs = 2\n",
    "        self.batch_size = 32\n",
    "        self.lr = lr\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Data distribution\n",
    "        self.alpha_dirichlet = 0.3  # More non-IID for extreme scenarios\n",
    "        self.min_samples_per_client = 100\n",
    "        \n",
    "        # EXTREME quality scenarios\n",
    "        self.extreme_scenario = extreme_scenario\n",
    "        self.setup_extreme_quality_distribution()\n",
    "        \n",
    "        self.seed_base = 42 + run_id * 1000\n",
    "        self.experiment_id = f\"extreme_{extreme_scenario}_lr{lr}_{run_id}\"\n",
    "    \n",
    "    def setup_extreme_quality_distribution(self):\n",
    "        \"\"\"Setup EXTREME quality distributions that should favor SmartFedAvg\"\"\"\n",
    "        \n",
    "        if self.extreme_scenario == \"poison\":\n",
    "            # Poison Attack: Some clients have 90%+ wrong labels\n",
    "            self.pristine_ratio = 0.4      # 40% perfect clients\n",
    "            self.degraded_ratio = 0.2      # 20% moderate degradation  \n",
    "            self.poison_ratio = 0.4        # 40% poisoned clients\n",
    "            self.description = \"40% pristine, 20% degraded, 40% POISONED (90% wrong labels)\"\n",
    "            \n",
    "        elif self.extreme_scenario == \"catastrophic\":\n",
    "            # Catastrophic Corruption: Unrecognizable data\n",
    "            self.pristine_ratio = 0.3      # 30% perfect clients\n",
    "            self.degraded_ratio = 0.2      # 20% moderate degradation\n",
    "            self.catastrophic_ratio = 0.5  # 50% catastrophically corrupted\n",
    "            self.description = \"30% pristine, 20% degraded, 50% CATASTROPHIC (unrecognizable)\"\n",
    "            \n",
    "        elif self.extreme_scenario == \"byzantine\":\n",
    "            # Byzantine Clients: Actively harmful updates\n",
    "            self.pristine_ratio = 0.5      # 50% honest clients\n",
    "            self.degraded_ratio = 0.2      # 20% poor quality\n",
    "            self.byzantine_ratio = 0.3     # 30% byzantine (adversarial)\n",
    "            self.description = \"50% honest, 20% poor quality, 30% BYZANTINE (adversarial)\"\n",
    "            \n",
    "        elif self.extreme_scenario == \"resource\":\n",
    "            # Extreme Resource Disparity: Huge gap in data quantity/quality\n",
    "            self.rich_ratio = 0.3          # 30% resource-rich clients (lots of good data)\n",
    "            self.poor_ratio = 0.4          # 40% resource-poor clients (little data)\n",
    "            self.broken_ratio = 0.3        # 30% broken clients (tiny amounts of bad data)\n",
    "            self.description = \"30% rich (5K+ samples), 40% poor (200 samples), 30% broken (50 bad samples)\"\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown extreme scenario: {self.extreme_scenario}\")\n",
    "        \n",
    "        print(f\"💀 EXTREME SCENARIO '{self.extreme_scenario}':\")\n",
    "        print(f\"   {self.description}\")\n",
    "\n",
    "class SimpleCIFAR10Model(nn.Module):\n",
    "    \"\"\"Simple model for extreme quality experiments\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ExtremeQualityDataset(Dataset):\n",
    "    \"\"\"Dataset with EXTREME quality degradation scenarios\"\"\"\n",
    "    def __init__(self, base_dataset, quality_type='pristine', corruption_seed=42, client_id=0, config=None):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.quality_type = quality_type\n",
    "        self.client_id = client_id\n",
    "        self.config = config\n",
    "        self.corruption_seed = corruption_seed\n",
    "        \n",
    "        np.random.seed(corruption_seed)\n",
    "        torch.manual_seed(corruption_seed)\n",
    "        \n",
    "        self.setup_extreme_corruption()\n",
    "        self.corrupted_labels = {}\n",
    "        self.corrupted_images = {}\n",
    "        self._apply_corruptions()\n",
    "        \n",
    "        print(f\"   💀 Client {client_id} ({quality_type}): {self.description}\")\n",
    "    \n",
    "    def setup_extreme_corruption(self):\n",
    "        \"\"\"Setup extreme corruption parameters\"\"\"\n",
    "        if self.quality_type == 'pristine':\n",
    "            # Perfect data - no corruption\n",
    "            self.label_noise_rate = 0.0\n",
    "            self.image_corruption_rate = 0.0\n",
    "            self.actual_quality_score = 0.98\n",
    "            self.description = \"PRISTINE: No corruption\"\n",
    "            \n",
    "        elif self.quality_type == 'degraded':\n",
    "            # Moderate degradation (like previous \"medium\")\n",
    "            self.label_noise_rate = 0.15\n",
    "            self.image_corruption_rate = 0.3\n",
    "            self.actual_quality_score = 0.45\n",
    "            self.description = \"DEGRADED: 15% label noise, 30% image corruption\"\n",
    "            \n",
    "        elif self.quality_type == 'poison':\n",
    "            # POISON: Deliberately wrong labels\n",
    "            self.label_noise_rate = 0.95  # 95% wrong labels!\n",
    "            self.image_corruption_rate = 0.1  # Keep images recognizable but labels wrong\n",
    "            self.actual_quality_score = 0.05  # Extremely low\n",
    "            self.description = \"POISON: 95% wrong labels (attack simulation)\"\n",
    "            \n",
    "        elif self.quality_type == 'catastrophic':\n",
    "            # CATASTROPHIC: Unrecognizable images + wrong labels\n",
    "            self.label_noise_rate = 0.8   # 80% wrong labels\n",
    "            self.image_corruption_rate = 0.9  # 90% images destroyed\n",
    "            self.blur_intensity = 15  # Extreme blur\n",
    "            self.noise_intensity = 0.5  # Heavy noise\n",
    "            self.actual_quality_score = 0.02  # Almost unusable\n",
    "            self.description = \"CATASTROPHIC: 80% wrong labels, 90% images destroyed\"\n",
    "            \n",
    "        elif self.quality_type == 'byzantine':\n",
    "            # BYZANTINE: Adversarial corruption designed to hurt model\n",
    "            self.label_noise_rate = 0.7   # Strategic label flipping\n",
    "            self.adversarial_noise = True\n",
    "            self.actual_quality_score = 0.01  # Actively harmful\n",
    "            self.description = \"BYZANTINE: Adversarial labels + hostile noise\"\n",
    "            \n",
    "        elif self.quality_type == 'broken':\n",
    "            # BROKEN: Severely resource-constrained + corrupted\n",
    "            self.label_noise_rate = 0.6\n",
    "            self.image_corruption_rate = 0.7\n",
    "            self.actual_quality_score = 0.08\n",
    "            self.description = \"BROKEN: Resource-poor + 60% label noise\"\n",
    "            \n",
    "        else:\n",
    "            # Default to pristine\n",
    "            self.label_noise_rate = 0.0\n",
    "            self.image_corruption_rate = 0.0\n",
    "            self.actual_quality_score = 0.98\n",
    "            self.description = \"DEFAULT: Pristine data\"\n",
    "    \n",
    "    def _apply_corruptions(self):\n",
    "        \"\"\"Apply extreme corruptions to dataset\"\"\"\n",
    "        dataset_size = len(self.base_dataset)\n",
    "        \n",
    "        # Label corruptions\n",
    "        if self.label_noise_rate > 0:\n",
    "            num_corrupt = int(dataset_size * self.label_noise_rate)\n",
    "            corrupt_indices = np.random.choice(dataset_size, num_corrupt, replace=False)\n",
    "            \n",
    "            for idx in corrupt_indices:\n",
    "                original_label = self.base_dataset[idx][1]\n",
    "                \n",
    "                if self.quality_type == 'byzantine':\n",
    "                    # Byzantine: Strategic label flipping (adversarial)\n",
    "                    # Flip to the most confusing class\n",
    "                    wrong_labels = [(original_label + 5) % 10]  # Systematic confusion\n",
    "                else:\n",
    "                    # Random wrong labels\n",
    "                    wrong_labels = [i for i in range(10) if i != original_label]\n",
    "                \n",
    "                self.corrupted_labels[idx] = np.random.choice(wrong_labels)\n",
    "        \n",
    "        # Image corruptions  \n",
    "        if hasattr(self, 'image_corruption_rate') and self.image_corruption_rate > 0:\n",
    "            num_corrupt = int(dataset_size * self.image_corruption_rate)\n",
    "            corrupt_indices = np.random.choice(dataset_size, num_corrupt, replace=False)\n",
    "            \n",
    "            for idx in corrupt_indices:\n",
    "                self.corrupted_images[idx] = True\n",
    "    \n",
    "    def _apply_catastrophic_image_corruption(self, image):\n",
    "        \"\"\"Apply catastrophic image corruption\"\"\"\n",
    "        img_np = image.permute(1, 2, 0).numpy()\n",
    "        img_np = (img_np * 255).astype(np.uint8)\n",
    "        \n",
    "        if self.quality_type == 'catastrophic':\n",
    "            # Extreme blur + noise that makes images unrecognizable\n",
    "            img_np = cv2.GaussianBlur(img_np, (15, 15), 8.0)  # Massive blur\n",
    "            noise = np.random.normal(0, 127, img_np.shape).astype(np.uint8)  # Heavy noise\n",
    "            img_np = np.clip(img_np.astype(float) + noise * 0.8, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        elif self.quality_type == 'byzantine':\n",
    "            # Adversarial noise designed to hurt training\n",
    "            noise = np.random.normal(0, 64, img_np.shape).astype(np.int16)\n",
    "            # Add systematic bias to confuse the model\n",
    "            img_np = np.clip(img_np.astype(float) + noise + 30, 0, 255).astype(np.uint8)\n",
    "            \n",
    "        elif self.quality_type == 'broken':\n",
    "            # Resource-poor corruption (moderate but consistent)\n",
    "            img_np = cv2.GaussianBlur(img_np, (7, 7), 3.0)\n",
    "            noise = np.random.normal(0, 32, img_np.shape).astype(np.uint8)\n",
    "            img_np = np.clip(img_np.astype(float) + noise * 0.6, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        return torch.from_numpy(img_np).permute(2, 0, 1).float() / 255.0\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.base_dataset[idx]\n",
    "        \n",
    "        # Apply label corruption\n",
    "        if idx in self.corrupted_labels:\n",
    "            label = self.corrupted_labels[idx]\n",
    "        \n",
    "        # Convert to tensor\n",
    "        if isinstance(image, Image.Image):\n",
    "            image = transforms.ToTensor()(image)\n",
    "        \n",
    "        # Apply image corruption\n",
    "        if idx in self.corrupted_images:\n",
    "            image = self._apply_catastrophic_image_corruption(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_quality_info(self):\n",
    "        \"\"\"Get quality information for this client\"\"\"\n",
    "        return {\n",
    "            'quality_type': self.quality_type,\n",
    "            'actual_quality_score': self.actual_quality_score,\n",
    "            'description': self.description,\n",
    "            'label_corruptions': len(self.corrupted_labels),\n",
    "            'image_corruptions': len(self.corrupted_images),\n",
    "            'dataset_size': len(self.base_dataset)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "def create_extreme_resource_disparity(base_dataset, client_id, quality_type, config):\n",
    "    \"\"\"Create extreme resource disparity for resource scenario\"\"\"\n",
    "    if config.extreme_scenario == 'resource':\n",
    "        if quality_type == 'rich':\n",
    "            # Rich clients: Lots of good data (use full subset)\n",
    "            return base_dataset\n",
    "        elif quality_type == 'poor':\n",
    "            # Poor clients: Limited data (subsample to 200)\n",
    "            if len(base_dataset) > 200:\n",
    "                indices = np.random.choice(len(base_dataset), 200, replace=False)\n",
    "                return Subset(base_dataset, indices)\n",
    "            return base_dataset\n",
    "        elif quality_type == 'broken':\n",
    "            # Broken clients: Tiny amount of bad data (subsample to 50)\n",
    "            if len(base_dataset) > 50:\n",
    "                indices = np.random.choice(len(base_dataset), 50, replace=False)\n",
    "                return Subset(base_dataset, indices)\n",
    "            return base_dataset\n",
    "    \n",
    "    return base_dataset\n",
    "\n",
    "def load_extreme_quality_cifar10(config):\n",
    "    \"\"\"Load CIFAR-10 with extreme quality heterogeneity\"\"\"\n",
    "    print(f\"\\n💀 LOADING EXTREME QUALITY DATA - {config.experiment_id}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # REAL CIFAR-10 transforms - aligned with previous experiments\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    # Load REAL CIFAR-10 dataset (50k train, 10k test)\n",
    "    print(\"📁 Loading REAL CIFAR-10 dataset...\")\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                               download=True, transform=None)  # Apply transforms later\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                              download=True, transform=transform_test)\n",
    "    \n",
    "    print(f\"✅ REAL CIFAR-10 loaded: {len(train_dataset)} train, {len(test_dataset)} test images\")\n",
    "    print(f\"   Classes: {train_dataset.classes}\")\n",
    "    print(f\"   Image shape: 32x32x3 RGB\")\n",
    "    \n",
    "    # Create extreme federated splits\n",
    "    print(f\"Creating EXTREME federated splits for {config.num_clients} clients...\")\n",
    "    \n",
    "    num_classes = 10\n",
    "    class_indices = {i: [] for i in range(num_classes)}\n",
    "    for idx, (_, label) in enumerate(train_dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    client_indices = [[] for _ in range(config.num_clients)]\n",
    "    \n",
    "    # Create more extreme non-IID distribution\n",
    "    for class_id in range(num_classes):\n",
    "        indices = class_indices[class_id]\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # More extreme Dirichlet for heterogeneity\n",
    "        proportions = np.random.dirichlet(np.repeat(config.alpha_dirichlet, config.num_clients))\n",
    "        proportions = np.maximum(proportions, 0.005)  # Very small minimum\n",
    "        proportions = proportions / proportions.sum()\n",
    "        \n",
    "        split_points = (np.cumsum(proportions) * len(indices)).astype(int)[:-1]\n",
    "        splits = np.split(indices, split_points)\n",
    "        \n",
    "        for client_id, split in enumerate(splits):\n",
    "            client_indices[client_id].extend(split)\n",
    "    \n",
    "    # Assign extreme quality types based on scenario\n",
    "    client_loaders = []\n",
    "    quality_assignments = []\n",
    "    actual_quality_scores = []\n",
    "    \n",
    "    if config.extreme_scenario == \"poison\":\n",
    "        pristine_count = int(config.num_clients * config.pristine_ratio)\n",
    "        degraded_count = int(config.num_clients * config.degraded_ratio)\n",
    "        quality_types = (['pristine'] * pristine_count + \n",
    "                        ['degraded'] * degraded_count + \n",
    "                        ['poison'] * (config.num_clients - pristine_count - degraded_count))\n",
    "        \n",
    "    elif config.extreme_scenario == \"catastrophic\":\n",
    "        pristine_count = int(config.num_clients * config.pristine_ratio)\n",
    "        degraded_count = int(config.num_clients * config.degraded_ratio)\n",
    "        quality_types = (['pristine'] * pristine_count + \n",
    "                        ['degraded'] * degraded_count + \n",
    "                        ['catastrophic'] * (config.num_clients - pristine_count - degraded_count))\n",
    "        \n",
    "    elif config.extreme_scenario == \"byzantine\":\n",
    "        pristine_count = int(config.num_clients * config.pristine_ratio)\n",
    "        degraded_count = int(config.num_clients * config.degraded_ratio)\n",
    "        quality_types = (['pristine'] * pristine_count + \n",
    "                        ['degraded'] * degraded_count + \n",
    "                        ['byzantine'] * (config.num_clients - pristine_count - degraded_count))\n",
    "        \n",
    "    elif config.extreme_scenario == \"resource\":\n",
    "        rich_count = int(config.num_clients * config.rich_ratio)\n",
    "        poor_count = int(config.num_clients * config.poor_ratio)\n",
    "        quality_types = (['rich'] * rich_count + \n",
    "                        ['poor'] * poor_count + \n",
    "                        ['broken'] * (config.num_clients - rich_count - poor_count))\n",
    "    \n",
    "    # Shuffle quality assignments for randomness\n",
    "    np.random.shuffle(quality_types)\n",
    "    \n",
    "    print(f\"\\n💀 EXTREME Quality Distribution:\")\n",
    "    quality_counts = {qt: quality_types.count(qt) for qt in set(quality_types)}\n",
    "    for qt, count in quality_counts.items():\n",
    "        print(f\"  {qt.upper()}: {count} clients\")\n",
    "    \n",
    "    # Create client datasets with extreme quality\n",
    "    for client_id, indices in enumerate(client_indices):\n",
    "        if len(indices) >= config.min_samples_per_client:\n",
    "            subset = Subset(train_dataset, indices)\n",
    "            quality_type = quality_types[client_id]\n",
    "            \n",
    "            # Apply resource disparity if needed\n",
    "            subset = create_extreme_resource_disparity(subset, client_id, quality_type, config)\n",
    "            \n",
    "            quality_assignments.append(quality_type)\n",
    "            \n",
    "            # Create extreme quality dataset\n",
    "            extreme_dataset = ExtremeQualityDataset(\n",
    "                subset, quality_type=quality_type, \n",
    "                corruption_seed=42 + client_id, client_id=client_id, config=config)\n",
    "            \n",
    "            actual_quality_scores.append(extreme_dataset.get_quality_info()['actual_quality_score'])\n",
    "            \n",
    "            loader = DataLoader(extreme_dataset, batch_size=config.batch_size, \n",
    "                              shuffle=True, num_workers=0)\n",
    "            client_loaders.append(loader)\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"\\n✅ EXTREME data loaded: {len(client_loaders)} clients\")\n",
    "    print(f\"   Quality score range: {min(actual_quality_scores):.3f} - {max(actual_quality_scores):.3f}\")\n",
    "    \n",
    "    return client_loaders, test_loader, quality_assignments, actual_quality_scores\n",
    "\n",
    "class RobustSmartFedAvgServer:\n",
    "    \"\"\"Robust SmartFedAvg designed for extreme quality heterogeneity\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = SimpleCIFAR10Model().to(config.device)\n",
    "        self.metrics = {\n",
    "            'accuracy': [], 'loss': [], 'aggregation_weights': [],\n",
    "            'quality_assessments': [], 'filtering_decisions': []\n",
    "        }\n",
    "        self.round_number = 0\n",
    "        \n",
    "        # ROBUST quality thresholds for extreme scenarios\n",
    "        self.setup_robust_thresholds()\n",
    "        \n",
    "    def setup_robust_thresholds(self):\n",
    "        \"\"\"Setup robust thresholds that can handle extreme quality heterogeneity\"\"\"\n",
    "        if self.config.extreme_scenario in ['poison', 'byzantine']:\n",
    "            # Very aggressive filtering for adversarial scenarios\n",
    "            self.quality_threshold = 0.4   # High bar to filter poison/byzantine\n",
    "            self.min_clients_ratio = 0.3   # Can work with just 30% of clients\n",
    "            self.harm_detection_threshold = 0.1  # Detect actively harmful clients\n",
    "            \n",
    "        elif self.config.extreme_scenario == 'catastrophic':\n",
    "            # Moderate filtering but detect catastrophic failures\n",
    "            self.quality_threshold = 0.25  # Lower bar since some degradation is expected\n",
    "            self.min_clients_ratio = 0.4   # Need more clients due to data quality\n",
    "            self.harm_detection_threshold = 0.05  # Very low threshold for catastrophic\n",
    "            \n",
    "        elif self.config.extreme_scenario == 'resource':\n",
    "            # Size-aware filtering for resource disparity\n",
    "            self.quality_threshold = 0.2   # Account for resource constraints\n",
    "            self.min_clients_ratio = 0.5   # Need more clients due to size disparity\n",
    "            self.size_threshold = 100      # Minimum viable dataset size\n",
    "            \n",
    "        print(f\"🛡️  ROBUST SmartFedAvg Thresholds for '{self.config.extreme_scenario}':\")\n",
    "        print(f\"   Quality threshold: {self.quality_threshold:.3f}\")\n",
    "        print(f\"   Minimum clients ratio: {self.min_clients_ratio:.1%}\")\n",
    "        if hasattr(self, 'harm_detection_threshold'):\n",
    "            print(f\"   Harm detection threshold: {self.harm_detection_threshold:.3f}\")\n",
    "    \n",
    "    def robust_quality_assessment(self, client_model, client_loader, client_id, actual_quality_score):\n",
    "        \"\"\"Robust quality assessment designed for extreme scenarios\"\"\"\n",
    "        client_model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        sample_count = 0\n",
    "        loss_values = []\n",
    "        prediction_entropy = []\n",
    "        \n",
    "        print(f\"\\n🔍 ROBUST Assessment Client {client_id} (True Quality: {actual_quality_score:.3f})\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(client_loader):\n",
    "                if sample_count >= 400:  # More samples for robust assessment\n",
    "                    break\n",
    "                \n",
    "                data, target = data.to(self.config.device), target.to(self.config.device)\n",
    "                output = client_model(data)\n",
    "                \n",
    "                # Calculate losses\n",
    "                individual_losses = F.cross_entropy(output, target, reduction='none')\n",
    "                loss_values.extend(individual_losses.cpu().numpy())\n",
    "                \n",
    "                loss = individual_losses.mean()\n",
    "                total_loss += loss.item() * data.size(0)\n",
    "                \n",
    "                # Prediction quality metrics\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                \n",
    "                # Prediction entropy (confidence measure)\n",
    "                probs = F.softmax(output, dim=1)\n",
    "                entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)\n",
    "                prediction_entropy.extend(entropy.cpu().numpy())\n",
    "                \n",
    "                total += data.size(0)\n",
    "                sample_count += data.size(0)\n",
    "        \n",
    "        if total == 0:\n",
    "            print(f\"   ❌ No data to evaluate\")\n",
    "            return 0.0, False, {'reason': 'No data'}\n",
    "        \n",
    "        # Basic metrics\n",
    "        avg_loss = total_loss / total\n",
    "        accuracy = correct / total\n",
    "        loss_std = np.std(loss_values) if len(loss_values) > 10 else 0.0\n",
    "        avg_entropy = np.mean(prediction_entropy) if prediction_entropy else 5.0\n",
    "        \n",
    "        print(f\"   📊 Metrics: Acc={accuracy:.3f}, Loss={avg_loss:.3f}, Loss_std={loss_std:.3f}, Entropy={avg_entropy:.3f}\")\n",
    "        \n",
    "        # ROBUST multi-factor quality assessment\n",
    "        \n",
    "        # 1. Basic performance component\n",
    "        accuracy_component = min(accuracy / 0.3, 1.0)  # Lower expectation for extreme scenarios\n",
    "        loss_component = max(0.0, 1.0 - (avg_loss / 4.0))  # More lenient loss threshold\n",
    "        \n",
    "        # 2. Stability component (crucial for extreme scenarios)\n",
    "        stability_component = max(0.0, 1.0 - (loss_std / 3.0))\n",
    "        \n",
    "        # 3. Confidence component (detect confused models)\n",
    "        confidence_component = max(0.0, 1.0 - (avg_entropy / 2.5))  # Lower entropy = more confident\n",
    "        \n",
    "        # 4. HARM DETECTION - Check for actively harmful clients\n",
    "        harm_penalty = 0.0\n",
    "        if hasattr(self, 'harm_detection_threshold'):\n",
    "            if accuracy < 0.05:  # Worse than random chance - likely harmful\n",
    "                harm_penalty = 0.8\n",
    "            elif avg_loss > 5.0:  # Extremely high loss - unstable\n",
    "                harm_penalty = 0.6\n",
    "            elif avg_entropy > 2.2:  # Extremely confused predictions\n",
    "                harm_penalty = 0.4\n",
    "        \n",
    "        # 5. Size penalty for resource scenario\n",
    "        size_penalty = 0.0\n",
    "        if self.config.extreme_scenario == 'resource':\n",
    "            dataset_size = len(client_loader.dataset)\n",
    "            if dataset_size < self.size_threshold:\n",
    "                size_penalty = 0.3 * (1.0 - dataset_size / self.size_threshold)\n",
    "        \n",
    "        # Weighted combination with harm detection\n",
    "        base_quality_score = (0.3 * accuracy_component + \n",
    "                             0.25 * loss_component + \n",
    "                             0.25 * stability_component + \n",
    "                             0.2 * confidence_component)\n",
    "        \n",
    "        # Apply penalties\n",
    "        quality_score = base_quality_score * (1.0 - harm_penalty) * (1.0 - size_penalty)\n",
    "        \n",
    "        # Correlation with actual quality (helps calibration)\n",
    "        actual_quality_boost = 0.1 * actual_quality_score\n",
    "        quality_score = 0.9 * quality_score + actual_quality_boost\n",
    "        \n",
    "        print(f\"   🎯 Quality Score Breakdown:\")\n",
    "        print(f\"      Accuracy: {accuracy_component:.3f}, Loss: {loss_component:.3f}\")\n",
    "        print(f\"      Stability: {stability_component:.3f}, Confidence: {confidence_component:.3f}\")\n",
    "        print(f\"      Harm penalty: {harm_penalty:.3f}, Size penalty: {size_penalty:.3f}\")\n",
    "        print(f\"      Final score: {quality_score:.3f}\")\n",
    "        \n",
    "        # Robust filtering decision\n",
    "        should_keep = quality_score >= self.quality_threshold\n",
    "        \n",
    "        # Override for extremely harmful clients\n",
    "        if hasattr(self, 'harm_detection_threshold') and quality_score < self.harm_detection_threshold:\n",
    "            should_keep = False\n",
    "            reason = f\"HARMFUL CLIENT DETECTED: Score {quality_score:.3f} < harm threshold {self.harm_detection_threshold:.3f}\"\n",
    "        else:\n",
    "            reason = f\"Score {quality_score:.3f} {'≥' if should_keep else '<'} threshold {self.quality_threshold:.3f}\"\n",
    "        \n",
    "        print(f\"   {'✅' if should_keep else '❌'} Decision: {'KEEP' if should_keep else 'FILTER'} ({reason})\")\n",
    "        \n",
    "        quality_info = {\n",
    "            'client_id': client_id,\n",
    "            'quality_score': quality_score,\n",
    "            'accuracy': accuracy,\n",
    "            'loss': avg_loss,\n",
    "            'loss_std': loss_std,\n",
    "            'avg_entropy': avg_entropy,\n",
    "            'actual_quality': actual_quality_score,\n",
    "            'should_keep': should_keep,\n",
    "            'reason': reason,\n",
    "            'harm_penalty': harm_penalty,\n",
    "            'size_penalty': size_penalty,\n",
    "            'dataset_size': len(client_loader.dataset)\n",
    "        }\n",
    "        \n",
    "        return quality_score, should_keep, quality_info\n",
    "    \n",
    "    def robust_client_selection(self, client_models, client_loaders, client_sizes, actual_quality_scores):\n",
    "        \"\"\"Robust client selection for extreme scenarios\"\"\"\n",
    "        print(f\"\\n🛡️  ROBUST Client Selection - Round {self.round_number}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        quality_assessments = []\n",
    "        \n",
    "        # Assess each client with robust metrics\n",
    "        for i, (model, loader, actual_quality) in enumerate(zip(client_models, client_loaders, actual_quality_scores)):\n",
    "            quality_score, should_keep, quality_info = self.robust_quality_assessment(\n",
    "                model, loader, i, actual_quality)\n",
    "            quality_assessments.append((i, quality_score, should_keep, quality_info))\n",
    "        \n",
    "        # Sort by quality score\n",
    "        quality_assessments.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\n📊 ROBUST Quality Assessment Ranking:\")\n",
    "        print(\"   Rank | Client | Actual | Predicted | Dataset | Decision | Reason\")\n",
    "        print(\"   -----|--------|--------|-----------|---------|----------|--------\")\n",
    "        for rank, (client_id, pred_quality, should_keep, info) in enumerate(quality_assessments):\n",
    "            actual_quality = info['actual_quality']\n",
    "            dataset_size = info['dataset_size']\n",
    "            decision = \"KEEP\" if should_keep else \"FILTER\"\n",
    "            reason_short = info['reason'][:30] + \"...\" if len(info['reason']) > 30 else info['reason']\n",
    "            print(f\"   {rank+1:4d} | {client_id:6d} | {actual_quality:6.3f} | {pred_quality:9.3f} | {dataset_size:7d} | {decision:8s} | {reason_short}\")\n",
    "        \n",
    "        # Apply robust filtering with guarantees\n",
    "        selected_indices = [idx for idx, _, should_keep, _ in quality_assessments if should_keep]\n",
    "        min_clients = max(1, int(len(client_models) * self.min_clients_ratio))\n",
    "        \n",
    "        # Emergency fallback: if too few clients, take the best available\n",
    "        if len(selected_indices) < min_clients:\n",
    "            print(f\"\\n⚠️  EMERGENCY: Only {len(selected_indices)} clients passed, need minimum {min_clients}\")\n",
    "            \n",
    "            # Filter out truly harmful clients first\n",
    "            non_harmful = [(idx, score, info) for idx, score, _, info in quality_assessments \n",
    "                          if not (hasattr(self, 'harm_detection_threshold') and score < self.harm_detection_threshold)]\n",
    "            \n",
    "            if len(non_harmful) >= min_clients:\n",
    "                print(f\"   Taking top {min_clients} non-harmful clients\")\n",
    "                selected_indices = [idx for idx, _, _ in non_harmful[:min_clients]]\n",
    "            else:\n",
    "                print(f\"   CRISIS: Taking top {min_clients} clients regardless (may include harmful)\")\n",
    "                selected_indices = [idx for idx, _, _, _ in quality_assessments[:min_clients]]\n",
    "        \n",
    "        # Extract selected clients\n",
    "        selected_models = [client_models[i] for i in selected_indices]\n",
    "        selected_loaders = [client_loaders[i] for i in selected_indices]\n",
    "        selected_sizes = [client_sizes[i] for i in selected_indices]\n",
    "        selected_quality_scores = [quality_assessments[i][1] for i in range(len(quality_assessments)) \n",
    "                                 if quality_assessments[i][0] in selected_indices]\n",
    "        \n",
    "        # Calculate filtering metrics\n",
    "        filter_rate = 1.0 - (len(selected_models) / len(client_models))\n",
    "        avg_quality_score = np.mean(selected_quality_scores) if selected_quality_scores else 0.0\n",
    "        \n",
    "        print(f\"\\n✅ ROBUST Selection Results:\")\n",
    "        print(f\"   Total clients: {len(client_models)}\")\n",
    "        print(f\"   Selected clients: {len(selected_models)} (IDs: {selected_indices})\")\n",
    "        print(f\"   Filter rate: {filter_rate:.1%}\")\n",
    "        print(f\"   Average quality score: {avg_quality_score:.3f}\")\n",
    "        \n",
    "        # Store detailed information\n",
    "        filtering_info = {\n",
    "            'round': self.round_number,\n",
    "            'total_clients': len(client_models),\n",
    "            'selected_clients': len(selected_models),\n",
    "            'selected_indices': selected_indices,\n",
    "            'filter_rate': filter_rate,\n",
    "            'avg_quality_score': avg_quality_score,\n",
    "            'quality_assessments': quality_assessments,\n",
    "            'threshold_used': self.quality_threshold,\n",
    "            'scenario': self.config.extreme_scenario\n",
    "        }\n",
    "        \n",
    "        self.metrics['filtering_decisions'].append(filtering_info)\n",
    "        \n",
    "        return selected_models, selected_loaders, selected_sizes, selected_quality_scores, filtering_info\n",
    "    \n",
    "    def adaptive_weighted_aggregation(self, models, sizes, quality_scores, filtering_info):\n",
    "        \"\"\"Adaptive aggregation that adjusts to extreme scenarios\"\"\"\n",
    "        print(f\"\\n🔄 ADAPTIVE Aggregation for {self.config.extreme_scenario}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Calculate base weights\n",
    "        total_size = sum(sizes)\n",
    "        size_weights = np.array([size / total_size for size in sizes])\n",
    "        \n",
    "        # Normalize quality weights\n",
    "        quality_weights = np.array(quality_scores)\n",
    "        quality_weights = (quality_weights - quality_weights.min() + 0.1)\n",
    "        quality_weights = quality_weights / quality_weights.sum()\n",
    "        \n",
    "        # ADAPTIVE emphasis based on scenario\n",
    "        if self.config.extreme_scenario in ['poison', 'byzantine']:\n",
    "            # Heavy emphasis on quality for adversarial scenarios\n",
    "            quality_emphasis = 0.9\n",
    "        elif self.config.extreme_scenario == 'catastrophic':\n",
    "            # Moderate quality emphasis\n",
    "            quality_emphasis = 0.7\n",
    "        elif self.config.extreme_scenario == 'resource':\n",
    "            # Balanced for resource disparity\n",
    "            quality_emphasis = 0.6\n",
    "        else:\n",
    "            quality_emphasis = 0.5\n",
    "        \n",
    "        size_emphasis = 1.0 - quality_emphasis\n",
    "        \n",
    "        # Combine weights adaptively\n",
    "        combined_weights = quality_emphasis * quality_weights + size_emphasis * size_weights\n",
    "        combined_weights = combined_weights / combined_weights.sum()\n",
    "        \n",
    "        print(f\"📊 ADAPTIVE Weight Calculation:\")\n",
    "        print(f\"   Scenario: {self.config.extreme_scenario}\")\n",
    "        print(f\"   Quality emphasis: {quality_emphasis:.1%}, Size emphasis: {size_emphasis:.1%}\")\n",
    "        print()\n",
    "        print(\"   Client | Size | Quality | Size_W | Qual_W | Final_W\")\n",
    "        print(\"   -------|------|---------|--------|--------|--------\")\n",
    "        \n",
    "        for i, (client_idx, size, quality, size_w, qual_w, final_w) in enumerate(\n",
    "            zip(filtering_info['selected_indices'], sizes, quality_scores, \n",
    "                size_weights, quality_weights, combined_weights)):\n",
    "            print(f\"   {client_idx:6d} | {size:4d} | {quality:7.3f} | {size_w:6.3f} | {qual_w:6.3f} | {final_w:7.3f}\")\n",
    "        \n",
    "        print(f\"\\n   Final weight sum: {combined_weights.sum():.6f}\")\n",
    "        \n",
    "        # Store weights for analysis\n",
    "        self.metrics['aggregation_weights'].append({\n",
    "            'round': self.round_number,\n",
    "            'method': 'RobustSmartFedAvg',\n",
    "            'scenario': self.config.extreme_scenario,\n",
    "            'selected_clients': filtering_info['selected_indices'],\n",
    "            'sizes': sizes,\n",
    "            'quality_scores': quality_scores,\n",
    "            'size_weights': size_weights.tolist(),\n",
    "            'quality_weights': quality_weights.tolist(),\n",
    "            'final_weights': combined_weights.tolist(),\n",
    "            'quality_emphasis': quality_emphasis,\n",
    "            'size_emphasis': size_emphasis\n",
    "        })\n",
    "        \n",
    "        return combined_weights.tolist()\n",
    "    \n",
    "    def aggregate(self, client_models, client_loaders, client_sizes, actual_quality_scores):\n",
    "        \"\"\"Main aggregation with robust extreme scenario handling\"\"\"\n",
    "        self.round_number += 1\n",
    "        \n",
    "        # Robust client selection\n",
    "        selected_models, selected_loaders, selected_sizes, selected_quality_scores, filtering_info = \\\n",
    "            self.robust_client_selection(client_models, client_loaders, client_sizes, actual_quality_scores)\n",
    "        \n",
    "        if not selected_models:\n",
    "            print(\"❌ CRISIS: No clients selected, using emergency fallback\")\n",
    "            return self.emergency_aggregate(client_models, client_sizes)\n",
    "        \n",
    "        # Adaptive weighted aggregation\n",
    "        weights = self.adaptive_weighted_aggregation(\n",
    "            selected_models, selected_sizes, selected_quality_scores, filtering_info)\n",
    "        \n",
    "        # Aggregate model parameters\n",
    "        global_dict = self.model.state_dict()\n",
    "        aggregated_dict = {}\n",
    "        \n",
    "        for key in global_dict.keys():\n",
    "            aggregated_dict[key] = torch.zeros_like(global_dict[key], dtype=torch.float32)\n",
    "            for model, weight in zip(selected_models, weights):\n",
    "                model_dict = model.state_dict()\n",
    "                aggregated_dict[key] += weight * model_dict[key].float()\n",
    "        \n",
    "        self.model.load_state_dict(aggregated_dict)\n",
    "        \n",
    "        print(f\"✅ ROBUST SmartFedAvg aggregation completed\")\n",
    "        \n",
    "        return copy.deepcopy(self.model)\n",
    "    \n",
    "    def emergency_aggregate(self, client_models, client_sizes):\n",
    "        \"\"\"Emergency aggregation when all else fails\"\"\"\n",
    "        print(\"🚨 EMERGENCY: Using size-based aggregation as last resort\")\n",
    "        \n",
    "        total_size = sum(client_sizes)\n",
    "        weights = [size / total_size for size in client_sizes]\n",
    "        \n",
    "        global_dict = self.model.state_dict()\n",
    "        aggregated_dict = {}\n",
    "        \n",
    "        for key in global_dict.keys():\n",
    "            aggregated_dict[key] = torch.zeros_like(global_dict[key], dtype=torch.float32)\n",
    "            for model, weight in zip(client_models, weights):\n",
    "                model_dict = model.state_dict()\n",
    "                aggregated_dict[key] += weight * model_dict[key].float()\n",
    "        \n",
    "        self.model.load_state_dict(aggregated_dict)\n",
    "        return copy.deepcopy(self.model)\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.config.device), target.to(self.config.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "        \n",
    "        accuracy = 100. * correct / total\n",
    "        loss = test_loss / total\n",
    "        \n",
    "        self.metrics['accuracy'].append(accuracy)\n",
    "        self.metrics['loss'].append(loss)\n",
    "        \n",
    "        print(f\"🛡️  RobustSmartFedAvg Evaluation: {accuracy:.2f}% accuracy, {loss:.4f} loss\")\n",
    "        \n",
    "        return accuracy, loss\n",
    "\n",
    "class StandardFedAvgServer:\n",
    "    \"\"\"Standard FedAvg for comparison in extreme scenarios\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = SimpleCIFAR10Model().to(config.device)\n",
    "        self.metrics = {'accuracy': [], 'loss': [], 'aggregation_weights': []}\n",
    "        self.round_number = 0\n",
    "        \n",
    "    def aggregate(self, client_models, client_sizes, client_quality_info=None):\n",
    "        \"\"\"Standard FedAvg aggregation (vulnerable to extreme quality issues)\"\"\"\n",
    "        self.round_number += 1\n",
    "        \n",
    "        print(f\"\\n🔵 Standard FedAvg Aggregation - Round {self.round_number}\")\n",
    "        print(f\"   {self.config.extreme_scenario} scenario\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Simple size-based weights (no quality filtering)\n",
    "        total_size = sum(client_sizes)\n",
    "        weights = [size / total_size for size in client_sizes]\n",
    "        \n",
    "        print(f\"📊 Simple Size-Based Weights:\")\n",
    "        for i, (size, weight) in enumerate(zip(client_sizes, weights)):\n",
    "            quality_info = client_quality_info[i] if client_quality_info else \"Unknown\"\n",
    "            print(f\"  Client {i}: Size={size:4d}, Weight={weight:.4f}, Quality={quality_info}\")\n",
    "        \n",
    "        print(f\"⚠️  WARNING: Including ALL clients regardless of quality!\")\n",
    "        \n",
    "        # Store weights\n",
    "        self.metrics['aggregation_weights'].append({\n",
    "            'round': self.round_number,\n",
    "            'method': 'FedAvg',\n",
    "            'weights': weights.copy(),\n",
    "            'client_sizes': client_sizes.copy(),\n",
    "            'scenario': self.config.extreme_scenario\n",
    "        })\n",
    "        \n",
    "        # Aggregate (potentially including harmful clients)\n",
    "        global_dict = self.model.state_dict()\n",
    "        aggregated_dict = {}\n",
    "        \n",
    "        for key in global_dict.keys():\n",
    "            aggregated_dict[key] = torch.zeros_like(global_dict[key], dtype=torch.float32)\n",
    "            for model, weight in zip(client_models, weights):\n",
    "                model_dict = model.state_dict()\n",
    "                aggregated_dict[key] += weight * model_dict[key].float()\n",
    "        \n",
    "        self.model.load_state_dict(aggregated_dict)\n",
    "        print(f\"🔄 Standard FedAvg: Aggregated {len(client_models)} clients\")\n",
    "        \n",
    "        return copy.deepcopy(self.model)\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"Evaluate standard FedAvg\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.config.device), target.to(self.config.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "        \n",
    "        accuracy = 100. * correct / total\n",
    "        loss = test_loss / total\n",
    "        \n",
    "        self.metrics['accuracy'].append(accuracy)\n",
    "        self.metrics['loss'].append(loss)\n",
    "        \n",
    "        print(f\"🔵 Standard FedAvg Evaluation: {accuracy:.2f}% accuracy, {loss:.4f} loss\")\n",
    "        \n",
    "        return accuracy, loss\n",
    "\n",
    "class ExtremeQualityClient:\n",
    "    \"\"\"Client for extreme quality experiments\"\"\"\n",
    "    def __init__(self, client_id, data_loader, config):\n",
    "        self.client_id = client_id\n",
    "        self.data_loader = data_loader\n",
    "        self.config = config\n",
    "        \n",
    "    def train(self, global_model):\n",
    "        \"\"\"Local training that may be affected by extreme quality issues\"\"\"\n",
    "        model = copy.deepcopy(global_model)\n",
    "        model.train()\n",
    "        \n",
    "        # Get quality info\n",
    "        quality_info = self.data_loader.dataset.get_quality_info()\n",
    "        \n",
    "        print(f\"🔧 Training Client {self.client_id} ({quality_info['quality_type']}):\")\n",
    "        print(f\"   Samples: {quality_info['dataset_size']}, Quality: {quality_info['actual_quality_score']:.3f}\")\n",
    "        \n",
    "        # Adaptive learning rate based on quality\n",
    "        adaptive_lr = self.config.lr\n",
    "        if quality_info['quality_type'] in ['poison', 'byzantine', 'catastrophic']:\n",
    "            adaptive_lr *= 0.5  # More conservative for problematic clients\n",
    "        \n",
    "        optimizer = optim.SGD(model.parameters(), lr=adaptive_lr, \n",
    "                             momentum=0.9, weight_decay=1e-4)\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for epoch in range(self.config.local_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            epoch_batches = 0\n",
    "            \n",
    "            for data, target in self.data_loader:\n",
    "                data, target = data.to(self.config.device), target.to(self.config.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                \n",
    "                # Check for extreme values that could indicate problems\n",
    "                if torch.isnan(loss) or torch.isinf(loss) or loss > 10.0:\n",
    "                    print(f\"   ⚠️  Extreme loss detected: {loss.item():.4f}\")\n",
    "                    continue\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                # More aggressive gradient clipping for extreme scenarios\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                epoch_batches += 1\n",
    "                batch_count += 1\n",
    "            \n",
    "            if epoch_batches > 0:\n",
    "                avg_epoch_loss = epoch_loss / epoch_batches\n",
    "                total_loss += avg_epoch_loss\n",
    "                print(f\"     Epoch {epoch+1}: Loss = {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        final_avg_loss = total_loss / self.config.local_epochs if batch_count > 0 else float('inf')\n",
    "        print(f\"   ✅ Training complete. Final avg loss: {final_avg_loss:.4f}\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "def run_extreme_quality_experiment():\n",
    "    \"\"\"Run experiment designed to show SmartFedAvg dominance in extreme scenarios\"\"\"\n",
    "    print(\"💀 EXTREME QUALITY HETEROGENEITY EXPERIMENT\")\n",
    "    print(\"🎯 Goal: Scenarios where RobustSmartFedAvg DOMINATES FedAvg\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Test extreme scenarios\n",
    "    learning_rates = [0.005, 0.01]\n",
    "    extreme_scenarios = ['poison', 'catastrophic', 'byzantine', 'resource']\n",
    "    \n",
    "    methods = [\n",
    "        (\"FedAvg\", StandardFedAvgServer),\n",
    "        (\"RobustSmartFedAvg\", RobustSmartFedAvgServer),\n",
    "    ]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"💀 Experiment Parameters:\")\n",
    "    print(f\"   🎯 Learning Rates: {learning_rates}\")\n",
    "    print(f\"   💀 Extreme Scenarios: {extreme_scenarios}\")\n",
    "    print(f\"   🤖 Methods: {[m[0] for m in methods]}\")\n",
    "    \n",
    "    scenario_count = 0\n",
    "    total_scenarios = len(learning_rates) * len(extreme_scenarios)\n",
    "    \n",
    "    for lr, extreme_scenario in product(learning_rates, extreme_scenarios):\n",
    "        scenario_count += 1\n",
    "        print(f\"\\n\" + \"💀\"*80)\n",
    "        print(f\"💀 EXTREME SCENARIO {scenario_count}/{total_scenarios}\")\n",
    "        print(f\"   Learning Rate: {lr}\")\n",
    "        print(f\"   Extreme Type: {extreme_scenario}\")\n",
    "        print(\"💀\"*80)\n",
    "        \n",
    "        # Create extreme configuration\n",
    "        config = ExtremeQualityConfig(lr, extreme_scenario)\n",
    "        \n",
    "        try:\n",
    "            # Load extreme quality data\n",
    "            client_loaders, test_loader, quality_assignments, actual_quality_scores = \\\n",
    "                load_extreme_quality_cifar10(config)\n",
    "            \n",
    "            print(f\"\\n📊 Extreme Quality Summary:\")\n",
    "            quality_counts = {}\n",
    "            for qa in quality_assignments:\n",
    "                quality_counts[qa] = quality_counts.get(qa, 0) + 1\n",
    "            \n",
    "            for quality_type, count in quality_counts.items():\n",
    "                avg_score = np.mean([aqs for aqs, qa in zip(actual_quality_scores, quality_assignments) if qa == quality_type])\n",
    "                print(f\"   {quality_type.upper()}: {count} clients (avg score: {avg_score:.3f})\")\n",
    "            \n",
    "            # Test each method\n",
    "            for method_name, server_class in methods:\n",
    "                print(f\"\\n\" + (\"🔵\" if method_name == \"FedAvg\" else \"🛡️\")*30)\n",
    "                print(f\"💀 TESTING {method_name.upper()} vs {extreme_scenario.upper()}\")\n",
    "                print((\"🔵\" if method_name == \"FedAvg\" else \"🛡️\")*30)\n",
    "                \n",
    "                try:\n",
    "                    # Set seeds\n",
    "                    torch.manual_seed(config.seed_base)\n",
    "                    np.random.seed(config.seed_base)\n",
    "                    \n",
    "                    # Initialize server and clients\n",
    "                    server = server_class(config)\n",
    "                    clients = [ExtremeQualityClient(i, loader, config) \n",
    "                             for i, loader in enumerate(client_loaders)]\n",
    "                    client_sizes = [len(loader.dataset) for loader in client_loaders]\n",
    "                    \n",
    "                    results = []\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Training loop\n",
    "                    for round_num in range(config.num_rounds):\n",
    "                        print(f\"\\n{'🔵' if method_name == 'FedAvg' else '🛡️'} ROUND {round_num + 1}/{config.num_rounds} - {method_name}\")\n",
    "                        print(\"=\" * 70)\n",
    "                        \n",
    "                        # Select random clients\n",
    "                        selected_indices = np.random.choice(\n",
    "                            len(clients), config.clients_per_round, replace=False)\n",
    "                        selected_clients = [clients[i] for i in selected_indices]\n",
    "                        selected_loaders = [client_loaders[i] for i in selected_indices]\n",
    "                        selected_sizes = [client_sizes[i] for i in selected_indices]\n",
    "                        selected_actual_scores = [actual_quality_scores[i] for i in selected_indices]\n",
    "                        selected_quality_assignments = [quality_assignments[i] for i in selected_indices]\n",
    "                        \n",
    "                        print(f\"💀 Selected Clients for EXTREME test:\")\n",
    "                        for i, (idx, qa) in enumerate(zip(selected_indices, selected_quality_assignments)):\n",
    "                            score = selected_actual_scores[i]\n",
    "                            print(f\"   Client {idx}: {qa.upper()} (score: {score:.3f})\")\n",
    "                        \n",
    "                        # Local training\n",
    "                        print(f\"\\n🔧 LOCAL TRAINING PHASE\")\n",
    "                        print(\"-\" * 30)\n",
    "                        \n",
    "                        client_models = []\n",
    "                        successful_loaders = []\n",
    "                        successful_sizes = []\n",
    "                        successful_actual_scores = []\n",
    "                        successful_quality_assignments = []\n",
    "                        \n",
    "                        for i, client in enumerate(selected_clients):\n",
    "                            try:\n",
    "                                model = client.train(server.model)\n",
    "                                client_models.append(model)\n",
    "                                successful_loaders.append(selected_loaders[i])\n",
    "                                successful_sizes.append(selected_sizes[i])\n",
    "                                successful_actual_scores.append(selected_actual_scores[i])\n",
    "                                successful_quality_assignments.append(selected_quality_assignments[i])\n",
    "                            except Exception as e:\n",
    "                                print(f\"❌ Client {selected_indices[i]} training failed: {e}\")\n",
    "                                continue\n",
    "                        \n",
    "                        if not client_models:\n",
    "                            print(f\"❌ Round {round_num + 1}: No successful clients\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Aggregation\n",
    "                        print(f\"\\n🔄 AGGREGATION PHASE\")\n",
    "                        print(\"-\" * 30)\n",
    "                        \n",
    "                        try:\n",
    "                            if method_name == \"RobustSmartFedAvg\":\n",
    "                                server.aggregate(client_models, successful_loaders, \n",
    "                                               successful_sizes, successful_actual_scores)\n",
    "                            else:\n",
    "                                server.aggregate(client_models, successful_sizes, \n",
    "                                               successful_quality_assignments)\n",
    "                        except Exception as e:\n",
    "                            print(f\"❌ Aggregation failed: {e}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Evaluation\n",
    "                        print(f\"\\n📊 EVALUATION PHASE\")\n",
    "                        print(\"-\" * 30)\n",
    "                        \n",
    "                        try:\n",
    "                            accuracy, loss = server.evaluate(test_loader)\n",
    "                            results.append({\n",
    "                                'round': round_num + 1,\n",
    "                                'accuracy': accuracy,\n",
    "                                'loss': loss\n",
    "                            })\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"❌ Evaluation failed: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Calculate final metrics\n",
    "                    if results:\n",
    "                        final_accuracy = results[-1]['accuracy']\n",
    "                        best_accuracy = max(r['accuracy'] for r in results)\n",
    "                        \n",
    "                        # Get method-specific metrics\n",
    "                        method_metrics = {}\n",
    "                        if hasattr(server, 'metrics') and 'filtering_decisions' in server.metrics:\n",
    "                            filter_rates = [fd['filter_rate'] for fd in server.metrics['filtering_decisions']]\n",
    "                            if filter_rates:\n",
    "                                method_metrics['avg_filter_rate'] = np.mean(filter_rates)\n",
    "                                method_metrics['max_filter_rate'] = np.max(filter_rates)\n",
    "                        \n",
    "                        result = {\n",
    "                            'lr': lr,\n",
    "                            'extreme_scenario': extreme_scenario,\n",
    "                            'method': method_name,\n",
    "                            'final_accuracy': final_accuracy,\n",
    "                            'best_accuracy': best_accuracy,\n",
    "                            'rounds_completed': len(results),\n",
    "                            'method_metrics': method_metrics,\n",
    "                            'scenario_description': config.description\n",
    "                        }\n",
    "                        \n",
    "                        all_results.append(result)\n",
    "                        \n",
    "                        print(f\"\\n{'🔵' if method_name == 'FedAvg' else '🛡️'} {method_name.upper()} FINAL RESULTS:\")\n",
    "                        print(f\"   Final Accuracy: {final_accuracy:.2f}%\")\n",
    "                        print(f\"   Best Accuracy: {best_accuracy:.2f}%\")\n",
    "                        \n",
    "                        if method_metrics:\n",
    "                            for key, value in method_metrics.items():\n",
    "                                if isinstance(value, float):\n",
    "                                    print(f\"   {key}: {value:.3f}\")\n",
    "                    \n",
    "                    else:\n",
    "                        print(f\"❌ {method_name}: No successful rounds\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {method_name} failed: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Scenario failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def analyze_extreme_results(results):\n",
    "    \"\"\"Analyze results from extreme quality experiments\"\"\"\n",
    "    if not results:\n",
    "        print(\"❌ No results to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n\" + \"💀\"*80)\n",
    "    print(f\"💀 EXTREME QUALITY EXPERIMENT ANALYSIS\")\n",
    "    print(\"💀\"*80)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Performance by extreme scenario\n",
    "    print(f\"\\n🏆 DOMINANCE ANALYSIS BY EXTREME SCENARIO:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    scenarios = df['extreme_scenario'].unique()\n",
    "    lrs = df['lr'].unique()\n",
    "    \n",
    "    smartfedavg_wins = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(f\"\\n💀 {scenario.upper()} SCENARIO:\")\n",
    "        for lr in lrs:\n",
    "            fedavg = df[(df['lr'] == lr) & (df['extreme_scenario'] == scenario) & (df['method'] == 'FedAvg')]\n",
    "            smart = df[(df['lr'] == lr) & (df['extreme_scenario'] == scenario) & (df['method'] == 'RobustSmartFedAvg')]\n",
    "            \n",
    "            if not fedavg.empty and not smart.empty:\n",
    "                total_comparisons += 1\n",
    "                fed_acc = fedavg['final_accuracy'].iloc[0]\n",
    "                smart_acc = smart['final_accuracy'].iloc[0]\n",
    "                advantage = smart_acc - fed_acc\n",
    "                \n",
    "                if advantage > 0:\n",
    "                    smartfedavg_wins += 1\n",
    "                    \n",
    "                print(f\"  📈 LR {lr}:\")\n",
    "                print(f\"    FedAvg:           {fed_acc:6.2f}%\")\n",
    "                print(f\"    RobustSmartFedAvg: {smart_acc:6.2f}%\")\n",
    "                print(f\"    {'💚 ADVANTAGE' if advantage > 0 else '💔 DISADVANTAGE'}: {advantage:+6.2f}%\")\n",
    "                \n",
    "                # Show filtering info\n",
    "                smart_metrics = smart['method_metrics'].iloc[0]\n",
    "                if smart_metrics and 'avg_filter_rate' in smart_metrics:\n",
    "                    filter_rate = smart_metrics['avg_filter_rate'] * 100\n",
    "                    print(f\"    Filter Rate:      {filter_rate:6.1f}%\")\n",
    "    \n",
    "    # Overall dominance summary\n",
    "    print(f\"\\n🎯 OVERALL DOMINANCE SUMMARY:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"RobustSmartFedAvg WINS: {smartfedavg_wins}/{total_comparisons} ({smartfedavg_wins/total_comparisons*100:.1f}%)\")\n",
    "    \n",
    "    if smartfedavg_wins/total_comparisons >= 0.75:\n",
    "        print(\"🎉 SUCCESS! RobustSmartFedAvg DOMINATES in extreme scenarios!\")\n",
    "    elif smartfedavg_wins/total_comparisons >= 0.5:\n",
    "        print(\"✅ Good! RobustSmartFedAvg shows clear advantages\")\n",
    "    else:\n",
    "        print(\"⚠️  Need more extreme scenarios for SmartFedAvg dominance\")\n",
    "    \n",
    "    # Best performing scenarios for SmartFedAvg\n",
    "    print(f\"\\n💚 SMARTFEDAVG EXCELS IN:\")\n",
    "    for _, row in df.iterrows():\n",
    "        if row['method'] == 'RobustSmartFedAvg':\n",
    "            fedavg_row = df[(df['lr'] == row['lr']) & \n",
    "                           (df['extreme_scenario'] == row['extreme_scenario']) & \n",
    "                           (df['method'] == 'FedAvg')]\n",
    "            if not fedavg_row.empty:\n",
    "                advantage = row['final_accuracy'] - fedavg_row['final_accuracy'].iloc[0]\n",
    "                if advantage > 5.0:  # Significant advantage\n",
    "                    print(f\"  {row['extreme_scenario']} (LR={row['lr']}): +{advantage:.1f}% advantage\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution for extreme quality experiments\"\"\"\n",
    "    print(\"💀 STARTING EXTREME QUALITY HETEROGENEITY EXPERIMENT\")\n",
    "    print(\"🎯 Goal: Create scenarios where RobustSmartFedAvg ALWAYS wins\")\n",
    "    print(\"🛡️ Method: Extreme quality degradation that breaks simple averaging\")\n",
    "    \n",
    "    try:\n",
    "        # Run extreme experiments\n",
    "        results = run_extreme_quality_experiment()\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\n✅ EXTREME experiment completed!\")\n",
    "            print(f\"💀 Total results: {len(results)}\")\n",
    "            \n",
    "            # Analyze results\n",
    "            analysis_df = analyze_extreme_results(results)\n",
    "            \n",
    "            # Save results\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            csv_filename = f\"extreme_quality_results_{timestamp}.csv\"\n",
    "            analysis_df.to_csv(csv_filename, index=False)\n",
    "            print(f\"💾 Results saved to: {csv_filename}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ No results collected\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Experiment failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638363e",
   "metadata": {
    "papermill": {
     "duration": 0.20277,
     "end_time": "2025-06-15T01:12:28.989034",
     "exception": false,
     "start_time": "2025-06-15T01:12:28.786264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3320.528152,
   "end_time": "2025-06-15T01:12:32.135052",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-15T00:17:11.606900",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
